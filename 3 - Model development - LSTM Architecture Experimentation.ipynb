{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cd47ebb2-55f5-4bc8-b6b9-311dedff58ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The watermark extension is already loaded. To reload it, use:\n",
      "  %reload_ext watermark\n",
      "Author: Siqi He\n",
      "\n",
      "Last updated: 2024-01-10\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.8.18\n",
      "IPython version      : 8.12.2\n",
      "\n",
      "Compiler    : Clang 16.0.6 \n",
      "OS          : Darwin\n",
      "Release     : 23.0.0\n",
      "Machine     : arm64\n",
      "Processor   : arm\n",
      "CPU cores   : 8\n",
      "Architecture: 64bit\n",
      "\n",
      "yfinance   : 0.2.33\n",
      "numpy      : 1.22.4\n",
      "pandas_ta  : 0.3.14b0\n",
      "matplotlib : 3.7.2\n",
      "pandas     : 1.5.3\n",
      "tensorflow : 2.13.1\n",
      "seaborn    : 0.13.0\n",
      "keras_tuner: 1.3.5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# basic imports\n",
    "import os, random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import pandas_ta as ta\n",
    "from pathlib import Path\n",
    "import yfinance as yf\n",
    "import math\n",
    "import inspect\n",
    "\n",
    "# import boruta\n",
    "from boruta import BorutaPy\n",
    "\n",
    "# import minisom\n",
    "from minisom import MiniSom\n",
    "\n",
    "# warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# plotting & outputs\n",
    "from pprint import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('seaborn')\n",
    "\n",
    "# sklearn imports\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import TimeSeriesSplit, cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# XGBoost\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# metrics\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import confusion_matrix, auc, roc_curve, roc_curve\n",
    "\n",
    "# import classifiers\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, StackingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator \n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "\n",
    "#from tensorflow.keras.optimizers import Adam, RMSprop \n",
    "from tensorflow.keras.optimizers.legacy import Adam, RMSprop \n",
    "from tensorflow.keras.losses import BinaryCrossentropy \n",
    "from tensorflow.keras.metrics import BinaryAccuracy, Accuracy, AUC, Precision, Recall, F1Score\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "from tensorflow.keras.layers import Dropout, Dense, Flatten\n",
    "from tensorflow.keras.layers import LSTM, BatchNormalization, Bidirectional, GRU\n",
    "\n",
    "# kerastuner \n",
    "import keras_tuner as kt\n",
    "from keras_tuner import HyperParameters\n",
    "from keras_tuner.tuners import RandomSearch, BayesianOptimization, Hyperband\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', 30)\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# # Machine info & package version\n",
    "from watermark import watermark\n",
    "%load_ext watermark\n",
    "%watermark -a \"Siqi He\" -u -d -v -m -iv  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29d8ea1-44ad-4e2e-87bf-ad2ac5558698",
   "metadata": {},
   "source": [
    "### Set up: Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4184632-232c-472e-a047-8dcaf2ea789e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WILLR_14</th>\n",
       "      <th>BBP_5_2.0</th>\n",
       "      <th>VCHG_2</th>\n",
       "      <th>STD_63</th>\n",
       "      <th>GAP_3</th>\n",
       "      <th>PCHG_2</th>\n",
       "      <th>CKSPl_10_3_20</th>\n",
       "      <th>STD_3</th>\n",
       "      <th>Mkt-RF</th>\n",
       "      <th>VHF_28</th>\n",
       "      <th>MACDh_12_26_9</th>\n",
       "      <th>VCHG_63</th>\n",
       "      <th>GAP_4</th>\n",
       "      <th>THERMO_20_2_0.5</th>\n",
       "      <th>PVO_12_26_9</th>\n",
       "      <th>...</th>\n",
       "      <th>PPOh_12_26_9</th>\n",
       "      <th>PVOh_12_26_9</th>\n",
       "      <th>GBPUSD=X_Close</th>\n",
       "      <th>GAP_2</th>\n",
       "      <th>SMB</th>\n",
       "      <th>VCHG_1</th>\n",
       "      <th>DMP_14</th>\n",
       "      <th>^FTSE_Close</th>\n",
       "      <th>VTXM_14</th>\n",
       "      <th>dsin</th>\n",
       "      <th>BBB_5_2.0</th>\n",
       "      <th>HML</th>\n",
       "      <th>ER_10</th>\n",
       "      <th>AD</th>\n",
       "      <th>MASSI_9_25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.076734</td>\n",
       "      <td>-0.390621</td>\n",
       "      <td>-0.170862</td>\n",
       "      <td>-0.090478</td>\n",
       "      <td>-0.273369</td>\n",
       "      <td>-1.031079</td>\n",
       "      <td>1.623661</td>\n",
       "      <td>0.072627</td>\n",
       "      <td>0.486486</td>\n",
       "      <td>0.613907</td>\n",
       "      <td>1.290233</td>\n",
       "      <td>0.219413</td>\n",
       "      <td>-0.221454</td>\n",
       "      <td>0.430629</td>\n",
       "      <td>-0.479601</td>\n",
       "      <td>...</td>\n",
       "      <td>0.374750</td>\n",
       "      <td>0.140792</td>\n",
       "      <td>0.228313</td>\n",
       "      <td>-0.677519</td>\n",
       "      <td>-0.020408</td>\n",
       "      <td>-0.139776</td>\n",
       "      <td>2.283319</td>\n",
       "      <td>0.259824</td>\n",
       "      <td>-0.277996</td>\n",
       "      <td>0.433884</td>\n",
       "      <td>0.177006</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.482508</td>\n",
       "      <td>1.509226</td>\n",
       "      <td>1.102748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.059680</td>\n",
       "      <td>-0.485234</td>\n",
       "      <td>-0.415944</td>\n",
       "      <td>-0.115661</td>\n",
       "      <td>-0.728628</td>\n",
       "      <td>-0.344201</td>\n",
       "      <td>1.639169</td>\n",
       "      <td>-0.198157</td>\n",
       "      <td>-0.054054</td>\n",
       "      <td>0.713555</td>\n",
       "      <td>0.971918</td>\n",
       "      <td>-0.522727</td>\n",
       "      <td>-0.379045</td>\n",
       "      <td>0.897359</td>\n",
       "      <td>-0.624051</td>\n",
       "      <td>...</td>\n",
       "      <td>0.322398</td>\n",
       "      <td>-0.099869</td>\n",
       "      <td>0.608384</td>\n",
       "      <td>-0.179615</td>\n",
       "      <td>0.489796</td>\n",
       "      <td>-0.279575</td>\n",
       "      <td>2.001703</td>\n",
       "      <td>-0.053300</td>\n",
       "      <td>-0.330060</td>\n",
       "      <td>-0.433884</td>\n",
       "      <td>0.104483</td>\n",
       "      <td>-0.282609</td>\n",
       "      <td>-0.049717</td>\n",
       "      <td>1.512624</td>\n",
       "      <td>1.025024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.092805</td>\n",
       "      <td>-0.246218</td>\n",
       "      <td>-0.609040</td>\n",
       "      <td>-0.115434</td>\n",
       "      <td>-0.283141</td>\n",
       "      <td>0.025803</td>\n",
       "      <td>1.657413</td>\n",
       "      <td>-0.598468</td>\n",
       "      <td>0.032432</td>\n",
       "      <td>0.696304</td>\n",
       "      <td>0.731593</td>\n",
       "      <td>-0.448552</td>\n",
       "      <td>-0.713536</td>\n",
       "      <td>-0.595914</td>\n",
       "      <td>-0.868236</td>\n",
       "      <td>...</td>\n",
       "      <td>0.385694</td>\n",
       "      <td>-0.447878</td>\n",
       "      <td>-0.254330</td>\n",
       "      <td>-0.437854</td>\n",
       "      <td>0.244898</td>\n",
       "      <td>-0.403336</td>\n",
       "      <td>1.838463</td>\n",
       "      <td>-0.124135</td>\n",
       "      <td>-0.473537</td>\n",
       "      <td>-0.974928</td>\n",
       "      <td>0.006146</td>\n",
       "      <td>1.847826</td>\n",
       "      <td>-0.135956</td>\n",
       "      <td>1.515244</td>\n",
       "      <td>0.912759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.028021</td>\n",
       "      <td>-0.520160</td>\n",
       "      <td>-0.399661</td>\n",
       "      <td>-0.115259</td>\n",
       "      <td>0.302931</td>\n",
       "      <td>-0.098843</td>\n",
       "      <td>1.670525</td>\n",
       "      <td>-0.743685</td>\n",
       "      <td>0.129730</td>\n",
       "      <td>0.366477</td>\n",
       "      <td>0.461385</td>\n",
       "      <td>-0.427586</td>\n",
       "      <td>0.295895</td>\n",
       "      <td>-0.726579</td>\n",
       "      <td>-1.068856</td>\n",
       "      <td>...</td>\n",
       "      <td>0.239335</td>\n",
       "      <td>-0.658370</td>\n",
       "      <td>0.124259</td>\n",
       "      <td>0.603449</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.032720</td>\n",
       "      <td>1.646422</td>\n",
       "      <td>0.421903</td>\n",
       "      <td>-0.796591</td>\n",
       "      <td>0.974928</td>\n",
       "      <td>-0.730399</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.071471</td>\n",
       "      <td>1.503808</td>\n",
       "      <td>0.686135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.045053</td>\n",
       "      <td>-0.826751</td>\n",
       "      <td>0.806589</td>\n",
       "      <td>-0.115410</td>\n",
       "      <td>0.839802</td>\n",
       "      <td>-0.375475</td>\n",
       "      <td>1.682877</td>\n",
       "      <td>-0.679642</td>\n",
       "      <td>-0.378378</td>\n",
       "      <td>0.570205</td>\n",
       "      <td>0.178100</td>\n",
       "      <td>-0.246017</td>\n",
       "      <td>0.527492</td>\n",
       "      <td>0.020029</td>\n",
       "      <td>-1.005650</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136767</td>\n",
       "      <td>-0.415475</td>\n",
       "      <td>-0.275278</td>\n",
       "      <td>1.214832</td>\n",
       "      <td>0.510204</td>\n",
       "      <td>0.952643</td>\n",
       "      <td>1.410299</td>\n",
       "      <td>0.054196</td>\n",
       "      <td>-0.641540</td>\n",
       "      <td>0.433884</td>\n",
       "      <td>-0.762788</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>-0.273531</td>\n",
       "      <td>1.499302</td>\n",
       "      <td>0.440891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1426</th>\n",
       "      <td>0.687365</td>\n",
       "      <td>-0.081214</td>\n",
       "      <td>-0.181734</td>\n",
       "      <td>0.031710</td>\n",
       "      <td>-0.428149</td>\n",
       "      <td>-0.198224</td>\n",
       "      <td>0.852888</td>\n",
       "      <td>0.038799</td>\n",
       "      <td>0.281081</td>\n",
       "      <td>0.550486</td>\n",
       "      <td>-0.382766</td>\n",
       "      <td>0.181716</td>\n",
       "      <td>-0.936902</td>\n",
       "      <td>0.955415</td>\n",
       "      <td>-0.233002</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.359198</td>\n",
       "      <td>0.308251</td>\n",
       "      <td>-0.075513</td>\n",
       "      <td>-0.570349</td>\n",
       "      <td>0.183673</td>\n",
       "      <td>-0.013083</td>\n",
       "      <td>1.163784</td>\n",
       "      <td>0.289411</td>\n",
       "      <td>-0.082615</td>\n",
       "      <td>-0.433884</td>\n",
       "      <td>-0.514799</td>\n",
       "      <td>-0.956522</td>\n",
       "      <td>-0.797456</td>\n",
       "      <td>-1.122057</td>\n",
       "      <td>0.486153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1427</th>\n",
       "      <td>-0.807432</td>\n",
       "      <td>-0.721870</td>\n",
       "      <td>0.345706</td>\n",
       "      <td>0.043626</td>\n",
       "      <td>-0.428012</td>\n",
       "      <td>-0.262307</td>\n",
       "      <td>0.852888</td>\n",
       "      <td>0.225531</td>\n",
       "      <td>-0.086486</td>\n",
       "      <td>0.515266</td>\n",
       "      <td>-0.627028</td>\n",
       "      <td>0.246060</td>\n",
       "      <td>-0.330564</td>\n",
       "      <td>0.540587</td>\n",
       "      <td>0.064174</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.507885</td>\n",
       "      <td>0.722566</td>\n",
       "      <td>-0.402738</td>\n",
       "      <td>0.620943</td>\n",
       "      <td>0.061224</td>\n",
       "      <td>0.492244</td>\n",
       "      <td>0.962135</td>\n",
       "      <td>-0.194257</td>\n",
       "      <td>-0.138207</td>\n",
       "      <td>-0.974928</td>\n",
       "      <td>-0.291017</td>\n",
       "      <td>-0.260870</td>\n",
       "      <td>-0.109200</td>\n",
       "      <td>-1.173370</td>\n",
       "      <td>0.341962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1428</th>\n",
       "      <td>-0.661451</td>\n",
       "      <td>-0.562555</td>\n",
       "      <td>-0.507586</td>\n",
       "      <td>-0.219410</td>\n",
       "      <td>0.604362</td>\n",
       "      <td>-0.732682</td>\n",
       "      <td>0.852888</td>\n",
       "      <td>0.091204</td>\n",
       "      <td>0.021622</td>\n",
       "      <td>0.790326</td>\n",
       "      <td>-0.811064</td>\n",
       "      <td>-0.819929</td>\n",
       "      <td>-0.270979</td>\n",
       "      <td>-0.198148</td>\n",
       "      <td>-0.122326</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.709189</td>\n",
       "      <td>0.299998</td>\n",
       "      <td>-0.274547</td>\n",
       "      <td>0.129799</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>-0.774613</td>\n",
       "      <td>0.774889</td>\n",
       "      <td>0.382888</td>\n",
       "      <td>-0.101190</td>\n",
       "      <td>0.781831</td>\n",
       "      <td>-0.154240</td>\n",
       "      <td>-0.130435</td>\n",
       "      <td>0.716448</td>\n",
       "      <td>-1.193657</td>\n",
       "      <td>0.315068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1429</th>\n",
       "      <td>-0.422076</td>\n",
       "      <td>-0.098798</td>\n",
       "      <td>-0.765551</td>\n",
       "      <td>-0.230603</td>\n",
       "      <td>0.281931</td>\n",
       "      <td>0.092260</td>\n",
       "      <td>0.859820</td>\n",
       "      <td>-0.049326</td>\n",
       "      <td>0.118919</td>\n",
       "      <td>0.815707</td>\n",
       "      <td>-0.836908</td>\n",
       "      <td>0.028405</td>\n",
       "      <td>0.629279</td>\n",
       "      <td>0.693120</td>\n",
       "      <td>-0.296110</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.861694</td>\n",
       "      <td>-0.018233</td>\n",
       "      <td>-0.685270</td>\n",
       "      <td>0.311243</td>\n",
       "      <td>-0.326531</td>\n",
       "      <td>-0.040872</td>\n",
       "      <td>0.601019</td>\n",
       "      <td>0.022318</td>\n",
       "      <td>0.142316</td>\n",
       "      <td>0.974928</td>\n",
       "      <td>-0.422076</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>0.211338</td>\n",
       "      <td>-1.175907</td>\n",
       "      <td>0.272505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1430</th>\n",
       "      <td>-0.682316</td>\n",
       "      <td>-0.518732</td>\n",
       "      <td>0.788582</td>\n",
       "      <td>-0.254220</td>\n",
       "      <td>0.390789</td>\n",
       "      <td>-0.171477</td>\n",
       "      <td>0.862802</td>\n",
       "      <td>-0.303438</td>\n",
       "      <td>0.216216</td>\n",
       "      <td>0.935327</td>\n",
       "      <td>-0.949416</td>\n",
       "      <td>-0.588184</td>\n",
       "      <td>0.336358</td>\n",
       "      <td>-0.094661</td>\n",
       "      <td>-0.146637</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.054939</td>\n",
       "      <td>0.231120</td>\n",
       "      <td>0.461167</td>\n",
       "      <td>0.355733</td>\n",
       "      <td>-0.040816</td>\n",
       "      <td>1.048208</td>\n",
       "      <td>0.439567</td>\n",
       "      <td>0.246980</td>\n",
       "      <td>0.101074</td>\n",
       "      <td>0.433884</td>\n",
       "      <td>-0.281191</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>0.459589</td>\n",
       "      <td>-1.196605</td>\n",
       "      <td>0.210396</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1431 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      WILLR_14  BBP_5_2.0    VCHG_2    STD_63     GAP_3    PCHG_2  \\\n",
       "0     0.076734  -0.390621 -0.170862 -0.090478 -0.273369 -1.031079   \n",
       "1     0.059680  -0.485234 -0.415944 -0.115661 -0.728628 -0.344201   \n",
       "2     0.092805  -0.246218 -0.609040 -0.115434 -0.283141  0.025803   \n",
       "3     0.028021  -0.520160 -0.399661 -0.115259  0.302931 -0.098843   \n",
       "4    -0.045053  -0.826751  0.806589 -0.115410  0.839802 -0.375475   \n",
       "...        ...        ...       ...       ...       ...       ...   \n",
       "1426  0.687365  -0.081214 -0.181734  0.031710 -0.428149 -0.198224   \n",
       "1427 -0.807432  -0.721870  0.345706  0.043626 -0.428012 -0.262307   \n",
       "1428 -0.661451  -0.562555 -0.507586 -0.219410  0.604362 -0.732682   \n",
       "1429 -0.422076  -0.098798 -0.765551 -0.230603  0.281931  0.092260   \n",
       "1430 -0.682316  -0.518732  0.788582 -0.254220  0.390789 -0.171477   \n",
       "\n",
       "      CKSPl_10_3_20     STD_3    Mkt-RF    VHF_28  MACDh_12_26_9   VCHG_63  \\\n",
       "0          1.623661  0.072627  0.486486  0.613907       1.290233  0.219413   \n",
       "1          1.639169 -0.198157 -0.054054  0.713555       0.971918 -0.522727   \n",
       "2          1.657413 -0.598468  0.032432  0.696304       0.731593 -0.448552   \n",
       "3          1.670525 -0.743685  0.129730  0.366477       0.461385 -0.427586   \n",
       "4          1.682877 -0.679642 -0.378378  0.570205       0.178100 -0.246017   \n",
       "...             ...       ...       ...       ...            ...       ...   \n",
       "1426       0.852888  0.038799  0.281081  0.550486      -0.382766  0.181716   \n",
       "1427       0.852888  0.225531 -0.086486  0.515266      -0.627028  0.246060   \n",
       "1428       0.852888  0.091204  0.021622  0.790326      -0.811064 -0.819929   \n",
       "1429       0.859820 -0.049326  0.118919  0.815707      -0.836908  0.028405   \n",
       "1430       0.862802 -0.303438  0.216216  0.935327      -0.949416 -0.588184   \n",
       "\n",
       "         GAP_4  THERMO_20_2_0.5  PVO_12_26_9  ...  PPOh_12_26_9  PVOh_12_26_9  \\\n",
       "0    -0.221454         0.430629    -0.479601  ...      0.374750      0.140792   \n",
       "1    -0.379045         0.897359    -0.624051  ...      0.322398     -0.099869   \n",
       "2    -0.713536        -0.595914    -0.868236  ...      0.385694     -0.447878   \n",
       "3     0.295895        -0.726579    -1.068856  ...      0.239335     -0.658370   \n",
       "4     0.527492         0.020029    -1.005650  ...      0.136767     -0.415475   \n",
       "...        ...              ...          ...  ...           ...           ...   \n",
       "1426 -0.936902         0.955415    -0.233002  ...     -0.359198      0.308251   \n",
       "1427 -0.330564         0.540587     0.064174  ...     -0.507885      0.722566   \n",
       "1428 -0.270979        -0.198148    -0.122326  ...     -0.709189      0.299998   \n",
       "1429  0.629279         0.693120    -0.296110  ...     -0.861694     -0.018233   \n",
       "1430  0.336358        -0.094661    -0.146637  ...     -1.054939      0.231120   \n",
       "\n",
       "      GBPUSD=X_Close     GAP_2       SMB    VCHG_1    DMP_14  ^FTSE_Close  \\\n",
       "0           0.228313 -0.677519 -0.020408 -0.139776  2.283319     0.259824   \n",
       "1           0.608384 -0.179615  0.489796 -0.279575  2.001703    -0.053300   \n",
       "2          -0.254330 -0.437854  0.244898 -0.403336  1.838463    -0.124135   \n",
       "3           0.124259  0.603449  0.714286  0.032720  1.646422     0.421903   \n",
       "4          -0.275278  1.214832  0.510204  0.952643  1.410299     0.054196   \n",
       "...              ...       ...       ...       ...       ...          ...   \n",
       "1426       -0.075513 -0.570349  0.183673 -0.013083  1.163784     0.289411   \n",
       "1427       -0.402738  0.620943  0.061224  0.492244  0.962135    -0.194257   \n",
       "1428       -0.274547  0.129799  0.428571 -0.774613  0.774889     0.382888   \n",
       "1429       -0.685270  0.311243 -0.326531 -0.040872  0.601019     0.022318   \n",
       "1430        0.461167  0.355733 -0.040816  1.048208  0.439567     0.246980   \n",
       "\n",
       "       VTXM_14      dsin  BBB_5_2.0       HML     ER_10        AD  MASSI_9_25  \n",
       "0    -0.277996  0.433884   0.177006  0.043478  0.482508  1.509226    1.102748  \n",
       "1    -0.330060 -0.433884   0.104483 -0.282609 -0.049717  1.512624    1.025024  \n",
       "2    -0.473537 -0.974928   0.006146  1.847826 -0.135956  1.515244    0.912759  \n",
       "3    -0.796591  0.974928  -0.730399  0.043478  0.071471  1.503808    0.686135  \n",
       "4    -0.641540  0.433884  -0.762788  0.695652 -0.273531  1.499302    0.440891  \n",
       "...        ...       ...        ...       ...       ...       ...         ...  \n",
       "1426 -0.082615 -0.433884  -0.514799 -0.956522 -0.797456 -1.122057    0.486153  \n",
       "1427 -0.138207 -0.974928  -0.291017 -0.260870 -0.109200 -1.173370    0.341962  \n",
       "1428 -0.101190  0.781831  -0.154240 -0.130435  0.716448 -1.193657    0.315068  \n",
       "1429  0.142316  0.974928  -0.422076 -0.500000  0.211338 -1.175907    0.272505  \n",
       "1430  0.101074  0.433884  -0.281191 -2.000000  0.459589 -1.196605    0.210396  \n",
       "\n",
       "[1431 rows x 37 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data preparation: Load scaled dataframes for Train, Validation, Test\n",
    "    ## NOTE: get raw set for Y - and write new function for different thresholds\n",
    "\n",
    "# LOAD CSV: raw Y values \n",
    "Y_train_df_raw = pd.read_csv(\"data/Y_train_df_raw.csv\",index_col=0)\n",
    "Y_dev_df_raw = pd.read_csv(\"data/Y_dev_df_raw.csv\",index_col=0)\n",
    "Y_test_df_raw = pd.read_csv(\"data/Y_test_df_raw.csv\",index_col=0)\n",
    "\n",
    "# LOAD CSV: Filtered - after removing high-corr\n",
    "X_train_df_scaled_corr_filtered = pd.read_csv(\"data/X_train_df_scaled_corr_filtered.csv\",index_col=0).to_numpy()\n",
    "X_dev_df_scaled_corr_filtered = pd.read_csv(\"data/X_dev_df_scaled_corr_filtered.csv\",index_col=0)\n",
    "X_test_df_scaled_corr_filtered = pd.read_csv(\"data/X_test_df_scaled_corr_filtered.csv\",index_col=0)\n",
    "\n",
    "# LOAD CSV: Reduced dimension - after Kmeans and SOM\n",
    "X_train_df_scaled_kmeans_som = pd.read_csv(\"data/X_train_df_scaled_kmeans_som.csv\",index_col=0)\n",
    "X_dev_df_scaled_kmeans_som = pd.read_csv(\"data/X_dev_df_scaled_kmeans_som.csv\",index_col=0)\n",
    "X_test_df_scaled_kmeans_som = pd.read_csv(\"data/X_test_df_scaled_kmeans_som.csv\",index_col=0)\n",
    "\n",
    "# LOAD CSV: Further reduced by XGBoost\n",
    "X_train_df_scaled_xg = pd.read_csv(\"data/X_train_df_scaled_xg.csv\",index_col=0)\n",
    "X_dev_df_scaled_xg = pd.read_csv(\"data/X_dev_df_scaled_xg.csv\",index_col=0)\n",
    "X_test_df_scaled_xg = pd.read_csv(\"data/X_test_df_scaled_xg.csv\",index_col=0)\n",
    "\n",
    "# view sample feature set\n",
    "X_train_df_scaled_xg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b2f4ea-fd3a-41a9-bc18-10942adcc24a",
   "metadata": {},
   "source": [
    "### Set up: Class weights and sequential data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ddd2428d-84c1-4919-9722-2b693940c621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential data after filtering high-correlation: \n",
      "(128, 21, 199) (128,)\n",
      "(128, 21, 199) (128,)\n",
      "(128, 21, 199) (128,)\n",
      "(128, 21, 199) (128,)\n",
      "(128, 21, 199) (128,)\n",
      "(128, 21, 199) (128,)\n",
      "(128, 21, 199) (128,)\n",
      "(128, 21, 199) (128,)\n",
      "(128, 21, 199) (128,)\n",
      "(128, 21, 199) (128,)\n",
      "(128, 21, 199) (128,)\n",
      "(2, 21, 199) (2,)\n",
      "\n",
      "Sequential data from K-means clustering and SOM selection: \n",
      "(128, 21, 96) (128,)\n",
      "(128, 21, 96) (128,)\n",
      "(128, 21, 96) (128,)\n",
      "(128, 21, 96) (128,)\n",
      "(128, 21, 96) (128,)\n",
      "(128, 21, 96) (128,)\n",
      "(128, 21, 96) (128,)\n",
      "(128, 21, 96) (128,)\n",
      "(128, 21, 96) (128,)\n",
      "(128, 21, 96) (128,)\n",
      "(128, 21, 96) (128,)\n",
      "(2, 21, 96) (2,)\n",
      "\n",
      "Sequential data from XGBoost selection: \n",
      "(128, 21, 37) (128,)\n",
      "(128, 21, 37) (128,)\n",
      "(128, 21, 37) (128,)\n",
      "(128, 21, 37) (128,)\n",
      "(128, 21, 37) (128,)\n",
      "(128, 21, 37) (128,)\n",
      "(128, 21, 37) (128,)\n",
      "(128, 21, 37) (128,)\n",
      "(128, 21, 37) (128,)\n",
      "(128, 21, 37) (128,)\n",
      "(128, 21, 37) (128,)\n",
      "(2, 21, 37) (2,)\n"
     ]
    }
   ],
   "source": [
    "# set class weights\n",
    "\n",
    "def cwts(dfs):\n",
    "    '''\n",
    "    Calculates class weights based on target value counts in a numpy array or pandas dataframe of target variable Y.\n",
    "    '''\n",
    "    c0, c1 = np.bincount(dfs)\n",
    "    w0=(1/c0)*(len(dfs))/2 \n",
    "    w1=(1/c1)*(len(dfs))/2 \n",
    "    \n",
    "    return {0: w0, 1: w1}\n",
    "\n",
    "# time series generator to transform data for LSTM input\n",
    "\n",
    "def time_series_generator(X, Y, seqlen):\n",
    "    '''\n",
    "    Calls the TimeSeriesGenerator module in Tensorflow.preprocessing.sequence.\n",
    "    For a given pair of X, Y and lookback period\n",
    "    '''\n",
    "    return TimeseriesGenerator(X, Y, length=seqlen)\n",
    "\n",
    "# turn Y raw values into direction labels\n",
    "\n",
    "y_train = np.where(Y_train_df_raw['label']>0.001, 1, 0)\n",
    "y_dev = np.where(Y_dev_df_raw['label']>0.001, 1, 0)\n",
    "y_test = np.where(Y_test_df_raw['label']>0.001, 1, 0)\n",
    "\n",
    "# create classweights\n",
    "\n",
    "class_weight = cwts(y_train)\n",
    "\n",
    "# create sequential data\n",
    "\n",
    "g_train_corr_filtered = time_series_generator(X_train_df_scaled_corr_filtered, y_train, seqlen=21)\n",
    "g_dev_corr_filtered = time_series_generator(X_dev_df_scaled_corr_filtered, y_dev, seqlen=21)\n",
    "g_test_corr_filtered = time_series_generator(X_test_df_scaled_corr_filtered, y_test, seqlen=21)\n",
    "\n",
    "g_train_kmeans_som = time_series_generator(X_train_df_scaled_kmeans_som, y_train, seqlen=21)\n",
    "g_dev_kmeans_som = time_series_generator(X_dev_df_scaled_kmeans_som, y_dev, seqlen=21)\n",
    "g_test_kmeans_som = time_series_generator(X_test_df_scaled_kmeans_som, y_test, seqlen=21)\n",
    "\n",
    "g_train_xg = time_series_generator(X_train_df_scaled_xg, y_train, seqlen=21)\n",
    "g_dev_xg = time_series_generator(X_dev_df_scaled_xg, y_dev, seqlen=21)\n",
    "g_test_xg = time_series_generator(X_test_df_scaled_xg, y_test, seqlen=21)\n",
    "\n",
    "# Visualise sequential data shape\n",
    "\n",
    "print(\"Sequential data after filtering high-correlation: \" )\n",
    "for i in range(len(g_train_corr_filtered)):\n",
    "    a, b = g_train_corr_filtered[i]\n",
    "    print(a.shape, b.shape)\n",
    "print()\n",
    "print(\"Sequential data from K-means clustering and SOM selection: \" )\n",
    "for i in range(len(g_train_kmeans_som)):\n",
    "    a, b = g_train_kmeans_som[i]\n",
    "    print(a.shape, b.shape)\n",
    "print()\n",
    "print(\"Sequential data from XGBoost selection: \" )\n",
    "for i in range(len(g_train_xg)):\n",
    "    a, b = g_train_xg[i]\n",
    "    print(a.shape, b.shape)\n",
    "    \n",
    "# Other global parameters\n",
    "\n",
    "num_features_kmeans_som = X_train_df_scaled_kmeans_som.shape[1]                       # number of features selected by K-means and SOM\n",
    "num_features_corr_filtered = X_train_df_scaled_corr_filtered.shape[1]                 # number of features remaining after filtering high correlation\n",
    "num_features_xg = X_train_df_scaled_xg.shape[1]                                       # number of features selectee after XGBoost\n",
    "S2 = 40         # Number of units in the last dense layer before LSTM units\n",
    "S1 = 80         # Number of units in the second-to-last dense layer before LSTM units\n",
    "LR = 0.005      # Learning rate\n",
    "seqlen = 21     # lookback period\n",
    "BATCH = 64     # batch size\n",
    "EPOCHS = 50    # number of epochs\n",
    "PATIENCE = 10  # patience\n",
    "logdir = f\"./tensorboard/LSTM/initial_run/\"  # tensorboard root directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82871d38-f94c-4d31-bfa8-984cf0e73b9e",
   "metadata": {},
   "source": [
    "### LSTM Model architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1116ec27-5cbf-4194-a659-f16a1669be86",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def LSTM_model_arch_1(g_train, g_valid, features, lookback, class_weights, hu=128, data='high_corr'):\n",
    "    '''\n",
    "    Model architecture: \n",
    "    - 0 dense layers before LSTM layers\n",
    "    - 1 LSTM layer, with drop-out\n",
    "    - 0 dense layer before output\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    tf.keras.backend.clear_session()   \n",
    "    \n",
    "    # instantiate the model\n",
    "    model = Sequential()\n",
    "\n",
    "    # tensorboard location\n",
    "    datetime = dt.datetime.now().strftime(\"%Y_%m_%d-%H_%M_%S\")\n",
    "    logdir = f\"./tensorboard/LSTM/initial_run/{data}/{inspect.currentframe().f_code.co_name}_{datetime}\"\n",
    "    print(f\"Now fitting model: {inspect.currentframe().f_code.co_name}\")\n",
    "    \n",
    "    # first LSTM layer\n",
    "    model.add(LSTM(units=hu*2, input_shape=(lookback, features), activation = 'elu', return_sequences=False, name='LSTM1'))\n",
    "\n",
    "    # first dropout layer\n",
    "    model.add(Dropout(0.4, name='Dropout1'))\n",
    "\n",
    "    # output layer\n",
    "    model.add(Dense(units=1, activation='sigmoid', name='Output'))\n",
    "\n",
    "    # optimizer\n",
    "    opt = Adam(learning_rate=LR, epsilon=1e-08)\n",
    "    \n",
    "    my_callbacks = [\n",
    "        EarlyStopping(patience=PATIENCE, monitor='val_loss', mode='min', verbose=1, restore_best_weights=True),TensorBoard(log_dir=logdir)\n",
    "    ]\n",
    "\n",
    "    # model compilation - 'binary_crossentropy' - 'accuracy' - BinaryAccuracy(name='accuracy', threshold=0.5)\n",
    "    model.compile(optimizer=opt, \n",
    "                  loss=BinaryCrossentropy(), \n",
    "                  metrics=['accuracy',\n",
    "                           Precision(),\n",
    "                           Recall()])\n",
    "    # print model summary\n",
    "    model.summary()\n",
    "\n",
    "    # fit model\n",
    "    history = model.fit(g_train,\n",
    "              epochs=EPOCHS, \n",
    "                        batch_size = BATCH,\n",
    "              verbose=1, \n",
    "              callbacks=my_callbacks, \n",
    "              shuffle=False,\n",
    "              class_weight=class_weights,\n",
    "              validation_data=g_valid)\n",
    "\n",
    "    return model, history\n",
    "\n",
    "def LSTM_model_arch_10(g_train, g_valid, features, lookback, class_weights, hu=128, data='high_corr'):\n",
    "    '''\n",
    "    Model architecture: \n",
    "    \n",
    "    - 2 dense layer at start\n",
    "    - 1 LSTM layer, with drop-out layer\n",
    "    - 0 dense layer before output\n",
    "    '''\n",
    "    \n",
    "    tf.keras.backend.clear_session()   \n",
    "    \n",
    "    # instantiate the model\n",
    "    model = Sequential()\n",
    "\n",
    "    # tensorboard path\n",
    "    datetime = dt.datetime.now().strftime(\"%Y_%m_%d-%H_%M_%S\")\n",
    "    logdir = f\"./tensorboard/LSTM/initial_run/{data}/{inspect.currentframe().f_code.co_name}_{datetime}\"\n",
    "    print(f\"Now fitting model: {inspect.currentframe().f_code.co_name}\")\n",
    "\n",
    "    # dense layer\n",
    "    model.add(Dense(units=features, name='Dense_start_1', input_shape=(lookback, features),)) \n",
    "    model.add(Dense(units=S2, name='Dense_start_2')) \n",
    "    \n",
    "    # first LSTM layer\n",
    "    model.add(LSTM(units=hu, input_shape=(lookback, S2), activation = 'elu', return_sequences=False, name='LSTM1'))\n",
    "    \n",
    "    # first dropout layer\n",
    "    model.add(Dropout(0.4, name='Dropout1'))\n",
    "\n",
    "    # output layer\n",
    "    model.add(Dense(units=1, activation='sigmoid', name='Output'))\n",
    "\n",
    "    # optimizer\n",
    "    opt = Adam(learning_rate=LR, epsilon=1e-08)\n",
    "    \n",
    "    my_callbacks = [\n",
    "        EarlyStopping(patience=PATIENCE, monitor='val_loss', mode='min', verbose=1, restore_best_weights=True),\n",
    "    ]\n",
    "\n",
    "    # model compilation - 'binary_crossentropy' - 'accuracy' - BinaryAccuracy(name='accuracy', threshold=0.5)\n",
    "    model.compile(optimizer=opt, \n",
    "                  loss=BinaryCrossentropy(), \n",
    "                  metrics=['accuracy',\n",
    "                           Precision(),\n",
    "                           Recall()])\n",
    "    \n",
    "    model.build(input_shape=(None, lookback, features))\n",
    "    \n",
    "    # print model summary\n",
    "    model.summary()\n",
    "\n",
    "    \n",
    "\n",
    "    # fit model\n",
    "    history = model.fit(g_train,\n",
    "              epochs=EPOCHS, \n",
    "                        batch_size = BATCH,\n",
    "              verbose=1, \n",
    "              callbacks=my_callbacks, \n",
    "              shuffle=False,\n",
    "              class_weight=class_weights,\n",
    "              validation_data=g_valid)\n",
    "\n",
    "    return model, history\n",
    "\n",
    "def LSTM_model_arch_11(g_train, g_valid, features, lookback, class_weights, hu=128, data='high_corr'):\n",
    "    '''\n",
    "    Model architecture: \n",
    "    \n",
    "    - 3 dense layer at start\n",
    "    - 1 LSTM layer, with drop-out layer\n",
    "    - 0 dense layer before output\n",
    "    '''\n",
    "    \n",
    "    tf.keras.backend.clear_session()   \n",
    "    \n",
    "    # instantiate the model\n",
    "    model = Sequential()\n",
    "\n",
    "    # tensorboard path\n",
    "    datetime = dt.datetime.now().strftime(\"%Y_%m_%d-%H_%M_%S\")\n",
    "    logdir = f\"./tensorboard/LSTM/initial_run/{data}/{inspect.currentframe().f_code.co_name}_{datetime}\"\n",
    "    print(f\"Now fitting model: {inspect.currentframe().f_code.co_name}\")\n",
    "    \n",
    "    # dense layer\n",
    "    model.add(Dense(units=features, name='Dense_start_1', input_shape=(lookback, features))) \n",
    "    model.add(Dense(units=S1, name='Dense_start_2')) \n",
    "    model.add(Dense(units=S2, name='Dense_start_3')) \n",
    "    \n",
    "    # first LSTM layer\n",
    "    model.add(LSTM(units=hu, input_shape=(lookback, S2), activation = 'elu', return_sequences=False, name='LSTM1'))\n",
    "    \n",
    "    # first dropout layer\n",
    "    model.add(Dropout(0.4, name='Dropout1'))\n",
    "\n",
    "    # output layer\n",
    "    model.add(Dense(units=1, activation='sigmoid', name='Output'))\n",
    "\n",
    "    # optimizer\n",
    "    opt = Adam(learning_rate=LR, epsilon=1e-08)\n",
    "    \n",
    "    my_callbacks = [\n",
    "        EarlyStopping(patience=PATIENCE, monitor='val_loss', mode='min', verbose=1, restore_best_weights=True),TensorBoard(log_dir=logdir)\n",
    "    ]\n",
    "\n",
    "    # model compilation - 'binary_crossentropy' - 'accuracy' - BinaryAccuracy(name='accuracy', threshold=0.5)\n",
    "    model.compile(optimizer=opt, \n",
    "                  loss=BinaryCrossentropy(), \n",
    "                  metrics=['accuracy',\n",
    "                           Precision(),\n",
    "                           Recall()])\n",
    "    # print model summary\n",
    "    model.summary()\n",
    "\n",
    "    # fit model\n",
    "    history = model.fit(g_train,\n",
    "              epochs=EPOCHS, \n",
    "                        batch_size = BATCH,\n",
    "              verbose=1, \n",
    "              callbacks=my_callbacks, \n",
    "              shuffle=False,\n",
    "              class_weight=class_weights,\n",
    "              validation_data=g_valid)\n",
    "\n",
    "    return model, history\n",
    "\n",
    "def LSTM_model_arch_2(g_train, g_valid, features, lookback, class_weights, hu=128, data='high_corr'):\n",
    "    '''\n",
    "    Model architecture: \n",
    "    - 0 Dense layer before LSTM layers\n",
    "    - 1 LSTM layer, with drop-out layer\n",
    "    - One dense layer\n",
    "    '''\n",
    "    \n",
    "    tf.keras.backend.clear_session()   \n",
    "    \n",
    "    # instantiate the model\n",
    "    model = Sequential()\n",
    "\n",
    "    # tensorboard path\n",
    "    datetime = dt.datetime.now().strftime(\"%Y_%m_%d-%H_%M_%S\")\n",
    "    logdir = f\"./tensorboard/LSTM/initial_run/{data}/{inspect.currentframe().f_code.co_name}_{datetime}\"\n",
    "    print(f\"Now fitting model: {inspect.currentframe().f_code.co_name}\")\n",
    "    \n",
    "    # first LSTM layer\n",
    "    model.add(LSTM(units=hu, input_shape=(lookback, features), activation = 'elu', return_sequences=False, name='LSTM1'))\n",
    "    \n",
    "    # first dropout layer\n",
    "    model.add(Dropout(0.4, name='Dropout1'))\n",
    "\n",
    "    # dense layer\n",
    "    model.add(Dense(units=int(hu/2), activation='elu', name='Dense_end_1'))\n",
    "\n",
    "    # output layer\n",
    "    model.add(Dense(units=1, activation='sigmoid', name='Output'))\n",
    "\n",
    "    # optimizer\n",
    "    opt = Adam(learning_rate=LR, epsilon=1e-08)\n",
    "\n",
    "    # callback\n",
    "    my_callbacks = [\n",
    "        EarlyStopping(patience=PATIENCE, monitor='val_loss', mode='min', verbose=1, restore_best_weights=True),TensorBoard(log_dir=logdir)\n",
    "    ]\n",
    "\n",
    "    # model compilation - 'binary_crossentropy' - 'accuracy' - BinaryAccuracy(name='accuracy', threshold=0.5)\n",
    "    model.compile(optimizer=opt, \n",
    "                  loss=BinaryCrossentropy(), \n",
    "                  metrics=['accuracy',\n",
    "                           Precision(),\n",
    "                           Recall()])\n",
    "    # print model summary\n",
    "    model.summary()\n",
    "\n",
    "    # fit model\n",
    "    history = model.fit(g_train,\n",
    "              epochs=EPOCHS, \n",
    "                        batch_size = BATCH,\n",
    "              verbose=1, \n",
    "              callbacks=my_callbacks, \n",
    "              shuffle=False,\n",
    "              class_weight=class_weights,\n",
    "              validation_data=g_valid)\n",
    "\n",
    "    return model, history\n",
    "\n",
    "def LSTM_model_arch_12(g_train, g_valid, features, lookback, class_weights, hu=128, data='high_corr'):\n",
    "    '''\n",
    "    Model architecture: \n",
    "    - 2 dense layer before LSTM\n",
    "    - 1 LSTM layer, with drop-out layer\n",
    "    - 1 dense layer before output\n",
    "    '''\n",
    "    \n",
    "    tf.keras.backend.clear_session()   \n",
    "    \n",
    "    # instantiate the model\n",
    "    model = Sequential()\n",
    "\n",
    "    # tensorboard path\n",
    "    datetime = dt.datetime.now().strftime(\"%Y_%m_%d-%H_%M_%S\")\n",
    "    logdir = f\"./tensorboard/LSTM/initial_run/{data}/{inspect.currentframe().f_code.co_name}_{datetime}\"\n",
    "    print(f\"Now fitting model: {inspect.currentframe().f_code.co_name}\")\n",
    "    \n",
    "    # dense layer\n",
    "    model.add(Dense(units=features, name='Dense_start_1', input_shape=(lookback, features))) \n",
    "    model.add(Dense(units=S2, name='Dense_start_2')) \n",
    "\n",
    "    # first LSTM layer\n",
    "    model.add(LSTM(units=hu, input_shape=(lookback, S2), activation = 'elu', return_sequences=False, name='LSTM1'))\n",
    "    \n",
    "    # first dropout layer\n",
    "    model.add(Dropout(0.4, name='Dropout1'))\n",
    "\n",
    "    # dense layer\n",
    "    model.add(Dense(units=int(hu/2), activation='elu', name='Dense_end_1'))\n",
    "\n",
    "    # output layer\n",
    "    model.add(Dense(units=1, activation='sigmoid', name='Output'))\n",
    "\n",
    "    # optimizer\n",
    "    opt = Adam(learning_rate=LR, epsilon=1e-08)\n",
    "\n",
    "    # callback\n",
    "    my_callbacks = [\n",
    "        EarlyStopping(patience=PATIENCE, monitor='val_loss', mode='min', verbose=1, restore_best_weights=True),TensorBoard(log_dir=logdir)\n",
    "    ]\n",
    "\n",
    "    # model compilation - 'binary_crossentropy' - 'accuracy' - BinaryAccuracy(name='accuracy', threshold=0.5)\n",
    "    model.compile(optimizer=opt, \n",
    "                  loss=BinaryCrossentropy(), \n",
    "                  metrics=['accuracy',\n",
    "                           Precision(),\n",
    "                           Recall()])\n",
    "    # print model summary\n",
    "    model.summary()\n",
    "\n",
    "    # fit model\n",
    "    history = model.fit(g_train,\n",
    "              epochs=EPOCHS, \n",
    "                        batch_size = BATCH,\n",
    "              verbose=1, \n",
    "              callbacks=my_callbacks, \n",
    "              shuffle=False,\n",
    "              class_weight=class_weights,\n",
    "              validation_data=g_valid)\n",
    "\n",
    "    return model, history\n",
    "\n",
    "def LSTM_model_arch_13(g_train, g_valid, features, lookback, class_weights, hu=128, data='high_corr'):\n",
    "    '''\n",
    "    Model architecture: \n",
    "    - 3 dense layer before LSTM\n",
    "    - 1 LSTM layer, with drop-out layer\n",
    "    - 1 dense layer before output\n",
    "    '''\n",
    "    \n",
    "    tf.keras.backend.clear_session()   \n",
    "    \n",
    "    # instantiate the model\n",
    "    model = Sequential()\n",
    "\n",
    "    # tensorboard path\n",
    "    datetime = dt.datetime.now().strftime(\"%Y_%m_%d-%H_%M_%S\")\n",
    "    logdir = f\"./tensorboard/LSTM/initial_run/{data}/{inspect.currentframe().f_code.co_name}_{datetime}\"\n",
    "    print(f\"Now fitting model: {inspect.currentframe().f_code.co_name}\")\n",
    "    \n",
    "    # dense layer\n",
    "    model.add(Dense(units=features, name='Dense_start_1', input_shape=(lookback, features))) \n",
    "    model.add(Dense(units=S1, name='Dense_start_2')) \n",
    "    model.add(Dense(units=S2, name='Dense_start_3')) \n",
    "\n",
    "    # first LSTM layer\n",
    "    model.add(LSTM(units=hu, input_shape=(lookback, S2), activation = 'elu', return_sequences=False, name='LSTM1'))\n",
    "    \n",
    "    # first dropout layer\n",
    "    model.add(Dropout(0.4, name='Dropout1'))\n",
    "\n",
    "    # dense layer\n",
    "    model.add(Dense(units=int(hu/2), activation='elu', name='Dense_end_1'))\n",
    "\n",
    "    # output layer\n",
    "    model.add(Dense(units=1, activation='sigmoid', name='Output'))\n",
    "\n",
    "    # optimizer\n",
    "    opt = Adam(learning_rate=LR, epsilon=1e-08)\n",
    "\n",
    "    # callback\n",
    "    my_callbacks = [\n",
    "        EarlyStopping(patience=PATIENCE, monitor='val_loss', mode='min', verbose=1, restore_best_weights=True),TensorBoard(log_dir=logdir)\n",
    "    ]\n",
    "\n",
    "    # model compilation - 'binary_crossentropy' - 'accuracy' - BinaryAccuracy(name='accuracy', threshold=0.5)\n",
    "    model.compile(optimizer=opt, \n",
    "                  loss=BinaryCrossentropy(), \n",
    "                  metrics=['accuracy',\n",
    "                           Precision(),\n",
    "                           Recall()])\n",
    "    # print model summary\n",
    "    model.summary()\n",
    "\n",
    "    # fit model\n",
    "    history = model.fit(g_train,\n",
    "              epochs=EPOCHS, \n",
    "                        batch_size = BATCH,\n",
    "              verbose=1, \n",
    "              callbacks=my_callbacks, \n",
    "              shuffle=False,\n",
    "              class_weight=class_weights,\n",
    "              validation_data=g_valid)\n",
    "\n",
    "    return model, history\n",
    "\n",
    "def LSTM_model_arch_3(g_train, g_valid, features, lookback, class_weights, hu=128, data='high_corr'):\n",
    "    '''\n",
    "    Model architecture: \n",
    "    \n",
    "    - 0 dense layer before LSTM\n",
    "    - 1 LSTM layer, with drop-out layer\n",
    "    - 2 dense layers before output\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    tf.keras.backend.clear_session()   \n",
    "    \n",
    "    # instantiate the model\n",
    "    model = Sequential()\n",
    "\n",
    "    # tensorboard path\n",
    "    datetime = dt.datetime.now().strftime(\"%Y_%m_%d-%H_%M_%S\")\n",
    "    logdir = f\"./tensorboard/LSTM/initial_run/{data}/{inspect.currentframe().f_code.co_name}_{datetime}\"\n",
    "    print(f\"Now fitting model: {inspect.currentframe().f_code.co_name}\")\n",
    "    \n",
    "    # first LSTM layer\n",
    "    model.add(LSTM(units=hu*2, input_shape=(lookback, features), activation = 'elu', return_sequences=False, name='LSTM1'))\n",
    "    \n",
    "    # first dropout layer\n",
    "    model.add(Dropout(0.4, name='Dropout1'))\n",
    "\n",
    "    # first dense layer\n",
    "    model.add(Dense(units=int(hu*3/4), activation='elu', name='Dense_end_1'))\n",
    "\n",
    "    # second dense layer\n",
    "    model.add(Dense(units=int(hu/2), activation='elu', name='Dense_end_2'))\n",
    "\n",
    "    # output layer\n",
    "    model.add(Dense(units=1, activation='sigmoid', name='Output'))   \n",
    "\n",
    "    # optimizer\n",
    "    opt = Adam(learning_rate=LR, epsilon=1e-08)\n",
    "\n",
    "    # callback\n",
    "    my_callbacks = [\n",
    "        EarlyStopping(patience=PATIENCE, monitor='val_loss', mode='min', verbose=1, restore_best_weights=True),TensorBoard(log_dir=logdir)\n",
    "    ]\n",
    "\n",
    "    # model compilation - 'binary_crossentropy' - 'accuracy' - BinaryAccuracy(name='accuracy', threshold=0.5)\n",
    "    model.compile(optimizer=opt, \n",
    "                  loss=BinaryCrossentropy(), \n",
    "                  metrics=['accuracy',\n",
    "                           Precision(),\n",
    "                           Recall()])\n",
    "    # print model summary\n",
    "    model.summary()\n",
    "\n",
    "    # fit model\n",
    "    history = model.fit(g_train,\n",
    "              epochs=EPOCHS, \n",
    "                        batch_size = BATCH,\n",
    "              verbose=1, \n",
    "              shuffle=False,\n",
    "              class_weight=class_weights,\n",
    "              validation_data=g_valid)\n",
    "\n",
    "    return model, history\n",
    "\n",
    "def LSTM_model_arch_14(g_train, g_valid, features, lookback, class_weights, hu=128, data='high_corr'):\n",
    "    '''\n",
    "    Model architecture: \n",
    "    \n",
    "    - 2 dense layer before LSTM\n",
    "    - 1 LSTM layer, with drop-out layer\n",
    "    - 2 dense layers before output\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    tf.keras.backend.clear_session()   \n",
    "    \n",
    "    # instantiate the model\n",
    "    model = Sequential()\n",
    "\n",
    "    # tensorboard path\n",
    "    datetime = dt.datetime.now().strftime(\"%Y_%m_%d-%H_%M_%S\")\n",
    "    logdir = f\"./tensorboard/LSTM/initial_run/{data}/{inspect.currentframe().f_code.co_name}_{datetime}\"\n",
    "    print(f\"Now fitting model: {inspect.currentframe().f_code.co_name}\")\n",
    "    \n",
    "    # dense layer\n",
    "    model.add(Dense(units=features, name='Dense_start_1', input_shape=(lookback, features))) \n",
    "    model.add(Dense(units=S2, name='Dense_start_2')) \n",
    "\n",
    "    # first LSTM layer\n",
    "    model.add(LSTM(units=hu, input_shape=(lookback, S2), activation = 'elu', return_sequences=False, name='LSTM1'))\n",
    "    \n",
    "    # first dropout layer\n",
    "    model.add(Dropout(0.4, name='Dropout1'))\n",
    "\n",
    "    # first dense layer\n",
    "    model.add(Dense(units=int(hu*3/4), activation='elu', name='Dense_end_1'))\n",
    "\n",
    "    # second dense layer\n",
    "    model.add(Dense(units=int(hu/2), activation='elu', name='Dense_end_2'))\n",
    "\n",
    "    # output layer\n",
    "    model.add(Dense(units=1, activation='sigmoid', name='Output'))   \n",
    "\n",
    "    # optimizer\n",
    "    opt = Adam(learning_rate=LR, epsilon=1e-08)\n",
    "\n",
    "    # callback\n",
    "    my_callbacks = [\n",
    "        EarlyStopping(patience=PATIENCE, monitor='val_loss', mode='min', verbose=1, restore_best_weights=True),TensorBoard(log_dir=logdir)\n",
    "    ]\n",
    "\n",
    "    # model compilation - 'binary_crossentropy' - 'accuracy' - BinaryAccuracy(name='accuracy', threshold=0.5)\n",
    "    model.compile(optimizer=opt, \n",
    "                  loss=BinaryCrossentropy(), \n",
    "                  metrics=['accuracy',\n",
    "                           Precision(),\n",
    "                           Recall()])\n",
    "    # print model summary\n",
    "    model.summary()\n",
    "\n",
    "    # fit model\n",
    "    history = model.fit(g_train,\n",
    "              epochs=EPOCHS, \n",
    "                        batch_size = BATCH,\n",
    "              verbose=1, \n",
    "              shuffle=False,\n",
    "              class_weight=class_weights,\n",
    "              validation_data=g_valid)\n",
    "\n",
    "    return model, history\n",
    "\n",
    "def LSTM_model_arch_15(g_train, g_valid, features, lookback, class_weights, hu=128, data='high_corr'):\n",
    "    '''\n",
    "    Model architecture: \n",
    "    \n",
    "    - 3 dense layer before LSTM\n",
    "    - 1 LSTM layer, with drop-out layer\n",
    "    - 2 dense layers before output\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    tf.keras.backend.clear_session()   \n",
    "    \n",
    "    # instantiate the model\n",
    "    model = Sequential()\n",
    "\n",
    "    # tensorboard path\n",
    "    datetime = dt.datetime.now().strftime(\"%Y_%m_%d-%H_%M_%S\")\n",
    "    logdir = f\"./tensorboard/LSTM/initial_run/{data}/{inspect.currentframe().f_code.co_name}_{datetime}\"\n",
    "    print(f\"Now fitting model: {inspect.currentframe().f_code.co_name}\")\n",
    "    \n",
    "    # dense layer\n",
    "    model.add(Dense(units=features, name='Dense_start_1', input_shape=(lookback, features))) \n",
    "    model.add(Dense(units=S1, name='Dense_start_2')) \n",
    "    model.add(Dense(units=S2, name='Dense_start_3')) \n",
    "\n",
    "    # first LSTM layer\n",
    "    model.add(LSTM(units=hu*2, input_shape=(lookback, S2), activation = 'elu', return_sequences=False, name='LSTM1'))\n",
    "    \n",
    "    # first dropout layer\n",
    "    model.add(Dropout(0.4, name='Dropout1'))\n",
    "\n",
    "    # first dense layer\n",
    "    model.add(Dense(units=int(hu*3/4), activation='elu', name='Dense_end_1'))\n",
    "\n",
    "    # second dense layer\n",
    "    model.add(Dense(units=int(hu/2), activation='elu', name='Dense_end_2'))\n",
    "\n",
    "    # output layer\n",
    "    model.add(Dense(units=1, activation='sigmoid', name='Output'))   \n",
    "\n",
    "    # optimizer\n",
    "    opt = Adam(learning_rate=LR, epsilon=1e-08)\n",
    "\n",
    "    # callback\n",
    "    my_callbacks = [\n",
    "        EarlyStopping(patience=PATIENCE, monitor='val_loss', mode='min', verbose=1, restore_best_weights=True),TensorBoard(log_dir=logdir)\n",
    "    ]\n",
    "\n",
    "    # model compilation - 'binary_crossentropy' - 'accuracy' - BinaryAccuracy(name='accuracy', threshold=0.5)\n",
    "    model.compile(optimizer=opt, \n",
    "                  loss=BinaryCrossentropy(), \n",
    "                  metrics=['accuracy',\n",
    "                           Precision(),\n",
    "                           Recall()])\n",
    "    # print model summary\n",
    "    model.summary()\n",
    "\n",
    "    # fit model\n",
    "    history = model.fit(g_train,epochs=EPOCHS, batch_size = BATCH, verbose=1, shuffle=False,class_weight=class_weights,validation_data=g_valid)\n",
    "\n",
    "    return model, history\n",
    "\n",
    "def LSTM_model_arch_4(g_train, g_valid, features, lookback, class_weights, hu=128, data='high_corr'):\n",
    "    '''\n",
    "    Baseline model architecture: \n",
    "    \n",
    "    - 0 dense layer before LSTM\n",
    "    - 2 LSTM layers, with drop-out layers\n",
    "    - 0 dense layer before output\n",
    "    '''\n",
    "    \n",
    "    tf.keras.backend.clear_session()   \n",
    "    \n",
    "    # instantiate the model\n",
    "    model = Sequential()\n",
    "\n",
    "    # tensorboard path\n",
    "    datetime = dt.datetime.now().strftime(\"%Y_%m_%d-%H_%M_%S\")\n",
    "    logdir = f\"./tensorboard/LSTM/initial_run/{data}/{inspect.currentframe().f_code.co_name}_{datetime}\"\n",
    "    print(f\"Now fitting model: {inspect.currentframe().f_code.co_name}\")\n",
    "    \n",
    "    # first LSTM layer\n",
    "    model.add(LSTM(units=hu*2, input_shape=(lookback, features), activation = 'elu', return_sequences=True, name='LSTM1'))\n",
    "    # first dropout layer\n",
    "    model.add(Dropout(0.4, name='Dropout1'))\n",
    "\n",
    "    # second LSTM layer\n",
    "    model.add(LSTM(units=hu, activation = 'elu', return_sequences=False, name='LSTM2'))\n",
    "\n",
    "    # output layer\n",
    "    model.add(Dense(units=1, activation='sigmoid', name='Output'))\n",
    "\n",
    "    # optimizer\n",
    "    opt = Adam(learning_rate=LR, epsilon=1e-08)\n",
    "\n",
    "    # callback\n",
    "    my_callbacks = [\n",
    "        EarlyStopping(patience=PATIENCE, monitor='val_loss', mode='min', verbose=1, restore_best_weights=True),TensorBoard(log_dir=logdir)\n",
    "    ]\n",
    "\n",
    "    # model compilation - 'binary_crossentropy' - 'accuracy' - BinaryAccuracy(name='accuracy', threshold=0.5)\n",
    "    model.compile(optimizer=opt, \n",
    "                  loss=BinaryCrossentropy(), \n",
    "                  metrics=['accuracy',\n",
    "                           Precision(),\n",
    "                           Recall()])\n",
    "    # print model summary\n",
    "    model.summary()\n",
    "\n",
    "    # fit model\n",
    "    history = model.fit(g_train,\n",
    "              epochs=EPOCHS, \n",
    "                        batch_size = BATCH,\n",
    "              verbose=1, \n",
    "              callbacks=my_callbacks, \n",
    "              shuffle=False,\n",
    "              class_weight=class_weights,\n",
    "              validation_data=g_valid)\n",
    "\n",
    "    return model, history\n",
    "\n",
    "def LSTM_model_arch_16(g_train, g_valid, features, lookback, class_weights, hu=128, data='high_corr'):\n",
    "    '''\n",
    "    Model architecture: \n",
    "    \n",
    "    - 2 dense layer before LSTM\n",
    "    - 2 LSTM layers, with drop-out layers\n",
    "    - 0 dense layer before output\n",
    "    '''\n",
    "    \n",
    "    tf.keras.backend.clear_session()   \n",
    "    \n",
    "    # instantiate the model\n",
    "    model = Sequential()\n",
    "\n",
    "    # tensorboard path\n",
    "    datetime = dt.datetime.now().strftime(\"%Y_%m_%d-%H_%M_%S\")\n",
    "    logdir = f\"./tensorboard/LSTM/initial_run/{data}/{inspect.currentframe().f_code.co_name}_{datetime}\"\n",
    "    print(f\"Now fitting model: {inspect.currentframe().f_code.co_name}\")\n",
    "    \n",
    "    # dense layer\n",
    "    model.add(Dense(units=features, name='Dense_start_1', input_shape=(lookback, features))) \n",
    "    model.add(Dense(units=S2, name='Dense_start_2')) \n",
    "\n",
    "    # first LSTM layer\n",
    "    model.add(LSTM(units=hu*2, input_shape=(lookback, S2), activation = 'elu', return_sequences=True, name='LSTM1'))\n",
    "    \n",
    "    # first dropout layer\n",
    "    model.add(Dropout(0.4, name='Dropout1'))\n",
    "\n",
    "    # second LSTM layer\n",
    "    model.add(LSTM(units=hu, activation = 'elu', return_sequences=False, name='LSTM2'))\n",
    "\n",
    "    # output layer\n",
    "    model.add(Dense(units=1, activation='sigmoid', name='Output'))\n",
    "\n",
    "    # optimizer\n",
    "    opt = Adam(learning_rate=LR, epsilon=1e-08)\n",
    "\n",
    "    # callback\n",
    "    my_callbacks = [\n",
    "        EarlyStopping(patience=PATIENCE, monitor='val_loss', mode='min', verbose=1, restore_best_weights=True),TensorBoard(log_dir=logdir)\n",
    "    ]\n",
    "\n",
    "    # model compilation - 'binary_crossentropy' - 'accuracy' - BinaryAccuracy(name='accuracy', threshold=0.5)\n",
    "    model.compile(optimizer=opt, \n",
    "                  loss=BinaryCrossentropy(), \n",
    "                  metrics=['accuracy',\n",
    "                           Precision(),\n",
    "                           Recall()])\n",
    "    # print model summary\n",
    "    model.summary()\n",
    "\n",
    "    # fit model\n",
    "    history = model.fit(g_train,\n",
    "              epochs=EPOCHS, \n",
    "                        batch_size = BATCH,\n",
    "              verbose=1, \n",
    "              callbacks=my_callbacks, \n",
    "              shuffle=False,\n",
    "              class_weight=class_weights,\n",
    "              validation_data=g_valid)\n",
    "\n",
    "    return model, history\n",
    "\n",
    "def LSTM_model_arch_17(g_train, g_valid, features, lookback, class_weights, hu=128, data='high_corr'):\n",
    "    '''\n",
    "    Model architecture: \n",
    "    \n",
    "    - 3 dense layer before LSTM\n",
    "    - 2 LSTM layers, with drop-out layers\n",
    "    - 0 dense layer before output\n",
    "    '''\n",
    "    \n",
    "    tf.keras.backend.clear_session()   \n",
    "    \n",
    "    # instantiate the model\n",
    "    model = Sequential()\n",
    "\n",
    "    # tensorboard path\n",
    "    datetime = dt.datetime.now().strftime(\"%Y_%m_%d-%H_%M_%S\")\n",
    "    logdir = f\"./tensorboard/LSTM/initial_run/{data}/{inspect.currentframe().f_code.co_name}_{datetime}\"\n",
    "    print(f\"Now fitting model: {inspect.currentframe().f_code.co_name}\")\n",
    "    \n",
    "    # dense layer\n",
    "    model.add(Dense(units=features, name='Dense_start_1', input_shape=(lookback, features))) \n",
    "    model.add(Dense(units=S1, name='Dense_start_2')) \n",
    "    model.add(Dense(units=S2, name='Dense_start_3')) \n",
    "\n",
    "    # first LSTM layer\n",
    "    model.add(LSTM(units=hu*2, input_shape=(lookback, S2), activation = 'elu', return_sequences=True, name='LSTM1'))\n",
    "    \n",
    "    # first dropout layer\n",
    "    model.add(Dropout(0.4, name='Dropout1'))\n",
    "\n",
    "    # second LSTM layer\n",
    "    model.add(LSTM(units=hu, activation = 'elu', return_sequences=False, name='LSTM2'))\n",
    "\n",
    "    # output layer\n",
    "    model.add(Dense(units=1, activation='sigmoid', name='Output'))\n",
    "\n",
    "    # optimizer\n",
    "    opt = Adam(learning_rate=LR, epsilon=1e-08)\n",
    "\n",
    "    # callback\n",
    "    my_callbacks = [\n",
    "        EarlyStopping(patience=PATIENCE, monitor='val_loss', mode='min', verbose=1, restore_best_weights=True),TensorBoard(log_dir=logdir)\n",
    "    ]\n",
    "\n",
    "    # model compilation - 'binary_crossentropy' - 'accuracy' - BinaryAccuracy(name='accuracy', threshold=0.5)\n",
    "    model.compile(optimizer=opt, \n",
    "                  loss=BinaryCrossentropy(), \n",
    "                  metrics=['accuracy',\n",
    "                           Precision(),\n",
    "                           Recall()])\n",
    "    # print model summary\n",
    "    model.summary()\n",
    "\n",
    "    # fit model\n",
    "    history = model.fit(g_train,\n",
    "              epochs=EPOCHS, \n",
    "                        batch_size = BATCH,\n",
    "              verbose=1, \n",
    "              callbacks=my_callbacks, \n",
    "              shuffle=False,\n",
    "              class_weight=class_weights,\n",
    "              validation_data=g_valid)\n",
    "\n",
    "    return model, history\n",
    "\n",
    "def LSTM_model_arch_5(g_train, g_valid, features, lookback, class_weights, hu=128, data='high_corr'):\n",
    "    '''\n",
    "    Model architecture: \n",
    "    - 0 dense layers before LSTM layers\n",
    "    - 2 LSTM layers, with drop-out layers\n",
    "    - 1 dense layer before output\n",
    "    '''\n",
    "    \n",
    "    tf.keras.backend.clear_session()   \n",
    "    \n",
    "    # instantiate the model\n",
    "    model = Sequential()\n",
    "\n",
    "    # tensorboard path\n",
    "    datetime = dt.datetime.now().strftime(\"%Y_%m_%d-%H_%M_%S\")\n",
    "    logdir = f\"./tensorboard/LSTM/initial_run/{data}/{inspect.currentframe().f_code.co_name}_{datetime}\"\n",
    "    print(f\"Now fitting model: {inspect.currentframe().f_code.co_name}\")\n",
    "    \n",
    "    # first LSTM layer\n",
    "    model.add(LSTM(units=hu*2, input_shape=(lookback, features), activation = 'elu', return_sequences=True, name='LSTM1'))\n",
    "    # first dropout layer\n",
    "    model.add(Dropout(0.4, name='Dropout1'))\n",
    "\n",
    "    # second LSTM layer\n",
    "    model.add(LSTM(units=hu, activation = 'relu', return_sequences=False, name='LSTM2'))\n",
    "\n",
    "    # first dense layer\n",
    "    model.add(Dense(units=int(hu/2), activation='relu', name='Dense1'))\n",
    "    \n",
    "    # output layer\n",
    "    model.add(Dense(units=1, activation='sigmoid', name='Output'))\n",
    "\n",
    "    # optimizer\n",
    "    opt = Adam(learning_rate=LR, epsilon=1e-08)\n",
    "\n",
    "    # callback\n",
    "    my_callbacks = [\n",
    "        EarlyStopping(patience=PATIENCE, monitor='val_loss', mode='min', verbose=1, restore_best_weights=True),TensorBoard(log_dir=logdir)\n",
    "    ]\n",
    "\n",
    "    # model compilation - 'binary_crossentropy' - 'accuracy' - BinaryAccuracy(name='accuracy', threshold=0.5)\n",
    "    model.compile(optimizer=opt, \n",
    "                  loss=BinaryCrossentropy(), \n",
    "                  metrics=['accuracy',\n",
    "                           Precision(),\n",
    "                           Recall()])\n",
    "    # print model summary\n",
    "    model.summary()\n",
    "\n",
    "    # fit model\n",
    "    history = model.fit(g_train,\n",
    "              epochs=EPOCHS, \n",
    "                        batch_size = BATCH,\n",
    "              callbacks=my_callbacks, \n",
    "              verbose=1, \n",
    "              shuffle=False,\n",
    "              class_weight=class_weights,\n",
    "              validation_data=g_valid)\n",
    "\n",
    "    return model, history\n",
    "\n",
    "def LSTM_model_arch_18(g_train, g_valid, features, lookback, class_weights, hu=128, data='high_corr'):\n",
    "    '''\n",
    "    Model architecture: \n",
    "\n",
    "    - 2 dense layers before LSTM\n",
    "    - 2 LSTM layers, with drop-out layers\n",
    "    - 1 dense layer before output\n",
    "    '''\n",
    "    \n",
    "    tf.keras.backend.clear_session()   \n",
    "    \n",
    "    # instantiate the model\n",
    "    model = Sequential()\n",
    "\n",
    "    # tensorboard path\n",
    "    datetime = dt.datetime.now().strftime(\"%Y_%m_%d-%H_%M_%S\")\n",
    "    logdir = f\"./tensorboard/LSTM/initial_run/{data}/{inspect.currentframe().f_code.co_name}_{datetime}\"\n",
    "    print(f\"Now fitting model: {inspect.currentframe().f_code.co_name}\")\n",
    "    \n",
    "    # dense layer\n",
    "    model.add(Dense(units=features, name='Dense_start_1', input_shape=(lookback, features))) \n",
    "    model.add(Dense(units=S2, name='Dense_start_2')) \n",
    "\n",
    "    # first LSTM layer\n",
    "    model.add(LSTM(units=hu*2, input_shape=(lookback, S2), activation = 'elu', return_sequences=True, name='LSTM1'))\n",
    "    # first dropout layer\n",
    "    model.add(Dropout(0.4, name='Dropout1'))\n",
    "\n",
    "    # second LSTM layer\n",
    "    model.add(LSTM(units=hu, activation = 'elu', return_sequences=False, name='LSTM2'))\n",
    "\n",
    "    # first dense layer\n",
    "    model.add(Dense(units=int(hu*3/4), activation='elu', name='Dense_end_1'))\n",
    "    \n",
    "    # output layer\n",
    "    model.add(Dense(units=1, activation='sigmoid', name='Output'))\n",
    "\n",
    "    # optimizer\n",
    "    opt = Adam(learning_rate=LR, epsilon=1e-08)\n",
    "\n",
    "    # callback\n",
    "    my_callbacks = [\n",
    "        EarlyStopping(patience=PATIENCE, monitor='val_loss', mode='min', verbose=1, restore_best_weights=True),TensorBoard(log_dir=logdir)\n",
    "    ]\n",
    "\n",
    "    # model compilation - 'binary_crossentropy' - 'accuracy' - BinaryAccuracy(name='accuracy', threshold=0.5)\n",
    "    model.compile(optimizer=opt, \n",
    "                  loss=BinaryCrossentropy(), \n",
    "                  metrics=['accuracy',\n",
    "                           Precision(),\n",
    "                           Recall()])\n",
    "    # print model summary\n",
    "    model.summary()\n",
    "\n",
    "    # fit model\n",
    "    history = model.fit(g_train,\n",
    "              epochs=EPOCHS, \n",
    "                        batch_size = BATCH,\n",
    "              callbacks=my_callbacks, \n",
    "              verbose=1, \n",
    "              shuffle=False,\n",
    "              class_weight=class_weights,\n",
    "              validation_data=g_valid)\n",
    "\n",
    "    return model, history\n",
    "\n",
    "def LSTM_model_arch_19(g_train, g_valid, features, lookback, class_weights, hu=128, data='high_corr'):\n",
    "    '''\n",
    "    Model architecture: \n",
    "\n",
    "    - 3 dense layers before LSTM\n",
    "    - 2 LSTM layers, with drop-out layers\n",
    "    - 1 dense layer before output\n",
    "    '''\n",
    "    \n",
    "    tf.keras.backend.clear_session()   \n",
    "    \n",
    "    # instantiate the model\n",
    "    model = Sequential()\n",
    "\n",
    "    # tensorboard path\n",
    "    datetime = dt.datetime.now().strftime(\"%Y_%m_%d-%H_%M_%S\")\n",
    "    logdir = f\"./tensorboard/LSTM/initial_run/{data}/{inspect.currentframe().f_code.co_name}_{datetime}\"\n",
    "    print(f\"Now fitting model: {inspect.currentframe().f_code.co_name}\")\n",
    "    \n",
    "    # dense layer\n",
    "    model.add(Dense(units=features, name='Dense_start_1', input_shape=(lookback, features))) \n",
    "    model.add(Dense(units=S1, name='Dense_start_2')) \n",
    "    model.add(Dense(units=S2, name='Dense_start_3')) \n",
    "\n",
    "    # first LSTM layer\n",
    "    model.add(LSTM(units=hu*2, input_shape=(lookback, S2), activation = 'elu', return_sequences=True, name='LSTM1'))\n",
    "    # first dropout layer\n",
    "    model.add(Dropout(0.4, name='Dropout1'))\n",
    "\n",
    "    # second LSTM layer\n",
    "    model.add(LSTM(units=hu, activation = 'elu', return_sequences=False, name='LSTM2'))\n",
    "\n",
    "    # first dense layer\n",
    "    model.add(Dense(units=int(hu/2), activation='elu', name='Dense_end_1'))\n",
    "    \n",
    "    # output layer\n",
    "    model.add(Dense(units=1, activation='sigmoid', name='Output'))\n",
    "\n",
    "    # optimizer\n",
    "    opt = Adam(learning_rate=LR, epsilon=1e-08)\n",
    "\n",
    "    # callback\n",
    "    my_callbacks = [\n",
    "        EarlyStopping(patience=PATIENCE, monitor='val_loss', mode='min', verbose=1, restore_best_weights=True),TensorBoard(log_dir=logdir)\n",
    "    ]\n",
    "\n",
    "    # model compilation - 'binary_crossentropy' - 'accuracy' - BinaryAccuracy(name='accuracy', threshold=0.5)\n",
    "    model.compile(optimizer=opt, \n",
    "                  loss=BinaryCrossentropy(), \n",
    "                  metrics=['accuracy',\n",
    "                           Precision(),\n",
    "                           Recall()])\n",
    "    # print model summary\n",
    "    model.summary()\n",
    "\n",
    "    # fit model\n",
    "    history = model.fit(g_train,epochs=EPOCHS, batch_size = BATCH, callbacks=my_callbacks, verbose=1, shuffle=False, class_weight=class_weights, validation_data=g_valid)\n",
    "\n",
    "    return model, history\n",
    "\n",
    "def LSTM_model_arch_6(g_train, g_valid, features, lookback, class_weights, hu=128, data='high_corr'):\n",
    "    '''\n",
    "    Model architecture: \n",
    "    - 0 dense layers before LSTM layers\n",
    "    - 2 LSTM layers, with drop-out layers\n",
    "    - 2 dense layer before output layer\n",
    "    '''\n",
    "    \n",
    "    tf.keras.backend.clear_session()   \n",
    "    \n",
    "    # instantiate the model\n",
    "    model = Sequential()\n",
    "\n",
    "    # tensorboard path\n",
    "    datetime = dt.datetime.now().strftime(\"%Y_%m_%d-%H_%M_%S\")\n",
    "    logdir = f\"./tensorboard/LSTM/initial_run/{data}/{inspect.currentframe().f_code.co_name}_{datetime}\"\n",
    "    print(f\"Now fitting model: {inspect.currentframe().f_code.co_name}\")\n",
    "    \n",
    "    # first LSTM layer\n",
    "    model.add(LSTM(units=hu*2, input_shape=(lookback, features), activation = 'elu', return_sequences=True, name='LSTM1'))\n",
    "    \n",
    "    # first dropout layer\n",
    "    model.add(Dropout(0.4, name='Dropout1'))\n",
    "\n",
    "    # second LSTM layer\n",
    "    model.add(LSTM(units=hu, activation = 'elu', return_sequences=False, name='LSTM2'))\n",
    "\n",
    "    # first dense layer\n",
    "    model.add(Dense(units=int(hu*3/4), activation='elu', name='Dense_end_1'))\n",
    "    \n",
    "    # second dense layer\n",
    "    model.add(Dense(units=int(hu/2), activation='elu', name='Dense_end_2'))\n",
    "    \n",
    "    # output layer\n",
    "    model.add(Dense(units=1, activation='sigmoid', name='Output'))\n",
    "\n",
    "    # optimizer\n",
    "    opt = Adam(learning_rate=LR, epsilon=1e-08)\n",
    "\n",
    "    # callback\n",
    "    my_callbacks = [\n",
    "        EarlyStopping(patience=PATIENCE, monitor='val_loss', mode='min', verbose=1, restore_best_weights=True),TensorBoard(log_dir=logdir)\n",
    "    ]\n",
    "\n",
    "    # model compilation - 'binary_crossentropy' - 'accuracy' - BinaryAccuracy(name='accuracy', threshold=0.5)\n",
    "    model.compile(optimizer=opt, \n",
    "                  loss=BinaryCrossentropy(), \n",
    "                  metrics=['accuracy',\n",
    "                           Precision(),\n",
    "                           Recall()])\n",
    "    # print model summary\n",
    "    model.summary()\n",
    "\n",
    "    # fit model\n",
    "    history = model.fit(g_train,\n",
    "              epochs=EPOCHS, \n",
    "                        batch_size = BATCH,\n",
    "              callbacks=my_callbacks, \n",
    "              verbose=1, \n",
    "              shuffle=False,\n",
    "              class_weight=class_weights,\n",
    "              validation_data=g_valid)\n",
    "\n",
    "    return model, history\n",
    "\n",
    "def LSTM_model_arch_20(g_train, g_valid, features, lookback, class_weights, hu=128, data='high_corr'):\n",
    "    '''\n",
    "    Model architecture: \n",
    "    - 2 dense layers before LSTM layers\n",
    "    - 2 LSTM layers, with drop-out layers\n",
    "    - 2 dense layer before output layer\n",
    "    '''\n",
    "    \n",
    "    tf.keras.backend.clear_session()   \n",
    "    \n",
    "    # instantiate the model\n",
    "    model = Sequential()\n",
    "\n",
    "    # tensorboard path\n",
    "    datetime = dt.datetime.now().strftime(\"%Y_%m_%d-%H_%M_%S\")\n",
    "    logdir = f\"./tensorboard/LSTM/initial_run/{data}/{inspect.currentframe().f_code.co_name}_{datetime}\"\n",
    "    print(f\"Now fitting model: {inspect.currentframe().f_code.co_name}\")\n",
    "    \n",
    "    # dense layer\n",
    "    model.add(Dense(units=features, name='Dense_start_1',input_shape=(lookback, features))) \n",
    "    model.add(Dense(units=S2, name='Dense_start_2')) \n",
    "\n",
    "    # first LSTM layer\n",
    "    model.add(LSTM(units=hu*2, input_shape=(lookback, S2), activation = 'elu', return_sequences=True, name='LSTM1'))\n",
    "    \n",
    "    # first dropout layer\n",
    "    model.add(Dropout(0.4, name='Dropout1'))\n",
    "\n",
    "    # second LSTM layer\n",
    "    model.add(LSTM(units=hu, activation = 'elu', return_sequences=False, name='LSTM2'))\n",
    "\n",
    "    # first dense layer\n",
    "    model.add(Dense(units=int(hu*3/4), activation='elu', name='Dense_end_1'))\n",
    "    \n",
    "    # second dense layer\n",
    "    model.add(Dense(units=int(hu/2), activation='elu', name='Dense_end_2'))\n",
    "    \n",
    "    # output layer\n",
    "    model.add(Dense(units=1, activation='sigmoid', name='Output'))\n",
    "\n",
    "    # optimizer\n",
    "    opt = Adam(learning_rate=LR, epsilon=1e-08)\n",
    "\n",
    "    # callback\n",
    "    my_callbacks = [\n",
    "        EarlyStopping(patience=PATIENCE, monitor='val_loss', mode='min', verbose=1, restore_best_weights=True),TensorBoard(log_dir=logdir)\n",
    "    ]\n",
    "\n",
    "    # model compilation - 'binary_crossentropy' - 'accuracy' - BinaryAccuracy(name='accuracy', threshold=0.5)\n",
    "    model.compile(optimizer=opt, \n",
    "                  loss=BinaryCrossentropy(), \n",
    "                  metrics=['accuracy',\n",
    "                           Precision(),\n",
    "                           Recall()])\n",
    "    # print model summary\n",
    "    model.summary()\n",
    "\n",
    "    # fit model\n",
    "    history = model.fit(g_train,\n",
    "              epochs=EPOCHS, \n",
    "                        batch_size = BATCH,\n",
    "              callbacks=my_callbacks, \n",
    "              verbose=1, \n",
    "              shuffle=False,\n",
    "              class_weight=class_weights,\n",
    "              validation_data=g_valid)\n",
    "\n",
    "    return model, history\n",
    "\n",
    "def LSTM_model_arch_21(g_train, g_valid, features, lookback, class_weights, hu=128, data='high_corr'):\n",
    "    '''\n",
    "    Model architecture: \n",
    "    - 3 dense layers before LSTM layers\n",
    "    - 2 LSTM layers, with drop-out layers\n",
    "    - 2 dense layer before output layer\n",
    "    '''\n",
    "    \n",
    "    tf.keras.backend.clear_session()   \n",
    "    \n",
    "    # instantiate the model\n",
    "    model = Sequential()\n",
    "\n",
    "    # tensorboard path\n",
    "    datetime = dt.datetime.now().strftime(\"%Y_%m_%d-%H_%M_%S\")\n",
    "    logdir = f\"./tensorboard/LSTM/initial_run/{data}/{inspect.currentframe().f_code.co_name}_{datetime}\"\n",
    "    print(f\"Now fitting model: {inspect.currentframe().f_code.co_name}\")\n",
    "    \n",
    "    # dense layer\n",
    "    model.add(Dense(units=features, name='Dense_start_1', input_shape=(lookback, features))) \n",
    "    model.add(Dense(units=S1, name='Dense_start_2')) \n",
    "    model.add(Dense(units=S2, name='Dense_start_3')) \n",
    "\n",
    "    # first LSTM layer\n",
    "    model.add(LSTM(units=hu*2, input_shape=(lookback, S2), activation = 'elu', return_sequences=True, name='LSTM1'))\n",
    "    \n",
    "    # first dropout layer\n",
    "    model.add(Dropout(0.4, name='Dropout1'))\n",
    "\n",
    "    # second LSTM layer\n",
    "    model.add(LSTM(units=hu, activation = 'elu', return_sequences=False, name='LSTM2'))\n",
    "\n",
    "    # first dense layer\n",
    "    model.add(Dense(units=int(hu*3/4), activation='elu', name='Dense_end_1'))\n",
    "    \n",
    "    # second dense layer\n",
    "    model.add(Dense(units=int(hu/2), activation='elu', name='Dense_end_2'))\n",
    "    \n",
    "    # output layer\n",
    "    model.add(Dense(units=1, activation='sigmoid', name='Output'))\n",
    "\n",
    "    # optimizer\n",
    "    opt = Adam(learning_rate=LR, epsilon=1e-08)\n",
    "\n",
    "    # callback\n",
    "    my_callbacks = [\n",
    "        EarlyStopping(patience=PATIENCE, monitor='val_loss', mode='min', verbose=1, restore_best_weights=True),TensorBoard(log_dir=logdir)\n",
    "    ]\n",
    "\n",
    "    # model compilation - 'binary_crossentropy' - 'accuracy' - BinaryAccuracy(name='accuracy', threshold=0.5)\n",
    "    model.compile(optimizer=opt, \n",
    "                  loss=BinaryCrossentropy(), \n",
    "                  metrics=['accuracy',\n",
    "                           Precision(),\n",
    "                           Recall()])\n",
    "    # print model summary\n",
    "    model.summary()\n",
    "\n",
    "    # fit model\n",
    "    history = model.fit(g_train,\n",
    "              epochs=EPOCHS, \n",
    "                        batch_size = BATCH,\n",
    "              callbacks=my_callbacks, \n",
    "              verbose=1, \n",
    "              shuffle=False,\n",
    "              class_weight=class_weights,\n",
    "              validation_data=g_valid)\n",
    "\n",
    "    return model, history\n",
    "\n",
    "def LSTM_model_arch_7(g_train, g_valid, features, lookback, class_weights, hu=128, data='high_corr'):\n",
    "    '''\n",
    "    Baseline model architecture: \n",
    "\n",
    "    - 0 dense layer before LSTM layers\n",
    "    - 3 LSTM layers, with drop-out layers\n",
    "    - 0 dense layer before output\n",
    "    '''\n",
    "    \n",
    "    tf.keras.backend.clear_session()   \n",
    "    \n",
    "    # instantiate the model\n",
    "    model = Sequential()\n",
    "\n",
    "    # tensorboard path\n",
    "    datetime = dt.datetime.now().strftime(\"%Y_%m_%d-%H_%M_%S\")\n",
    "    logdir = f\"./tensorboard/LSTM/initial_run/{data}/{inspect.currentframe().f_code.co_name}_{datetime}\"\n",
    "    print(f\"Now fitting model: {inspect.currentframe().f_code.co_name}\")\n",
    "    \n",
    "    # first LSTM layer\n",
    "    model.add(LSTM(units=hu*2, input_shape=(lookback, features), activation = 'elu', return_sequences=True, name='LSTM1'))\n",
    "    # first dropout layer\n",
    "    model.add(Dropout(0.4, name='Dropout1'))\n",
    "\n",
    "    # second LSTM layer\n",
    "    model.add(LSTM(units=hu, activation = 'elu', return_sequences=True, name='LSTM2'))\n",
    "    # second dropout layer\n",
    "    model.add(Dropout(0.4, name='Dropout2'))\n",
    "\n",
    "    # third LSTM layer\n",
    "    model.add(LSTM(units=hu, activation = 'elu', return_sequences=False, name='LSTM3'))\n",
    "\n",
    "    # output layer\n",
    "    model.add(Dense(units=1, activation='sigmoid', name='Output'))\n",
    "\n",
    "    # optimizer\n",
    "    opt = Adam(learning_rate=LR, epsilon=1e-08)\n",
    "\n",
    "    # callback\n",
    "    my_callbacks = [\n",
    "        EarlyStopping(patience=PATIENCE, monitor='val_loss', mode='min', verbose=1, restore_best_weights=True),TensorBoard(log_dir=logdir)\n",
    "    ]\n",
    "\n",
    "    # model compilation - 'binary_crossentropy' - 'accuracy' - BinaryAccuracy(name='accuracy', threshold=0.5)\n",
    "    model.compile(optimizer=opt, \n",
    "                  loss=BinaryCrossentropy(), \n",
    "                  metrics=['accuracy',\n",
    "                           Precision(),\n",
    "                           Recall()])\n",
    "    # print model summary\n",
    "    model.summary()\n",
    "\n",
    "    # fit model\n",
    "    history = model.fit(g_train,\n",
    "              epochs=EPOCHS, \n",
    "                        batch_size = BATCH,\n",
    "              callbacks=my_callbacks, \n",
    "              verbose=1, \n",
    "              shuffle=False,\n",
    "              class_weight=class_weights,\n",
    "              validation_data=g_valid)\n",
    "\n",
    "    return model, history\n",
    "\n",
    "def LSTM_model_arch_22(g_train, g_valid, features, lookback, class_weights, hu=128, data='high_corr'):\n",
    "    '''\n",
    "    Baseline model architecture: \n",
    "\n",
    "    - 2 dense layer before LSTM layers\n",
    "    - 3 LSTM layers, with drop-out layers\n",
    "    - 0 dense layer before output\n",
    "    '''\n",
    "    \n",
    "    tf.keras.backend.clear_session()   \n",
    "    \n",
    "    # instantiate the model\n",
    "    model = Sequential()\n",
    "\n",
    "    # tensorboard path\n",
    "    datetime = dt.datetime.now().strftime(\"%Y_%m_%d-%H_%M_%S\")\n",
    "    logdir = f\"./tensorboard/LSTM/initial_run/{data}/{inspect.currentframe().f_code.co_name}_{datetime}\"\n",
    "    print(f\"Now fitting model: {inspect.currentframe().f_code.co_name}\")\n",
    "    \n",
    "    # dense layer\n",
    "    model.add(Dense(units=features, name='Dense_start_1', input_shape=(lookback, features))) \n",
    "    model.add(Dense(units=S2, name='Dense_start_2')) \n",
    "    \n",
    "    # first LSTM layer\n",
    "    model.add(LSTM(units=hu*2, input_shape=(lookback, S2), activation = 'elu', return_sequences=True, name='LSTM1'))\n",
    "    # first dropout layer\n",
    "    model.add(Dropout(0.4, name='Dropout1'))\n",
    "\n",
    "    # second LSTM layer\n",
    "    model.add(LSTM(units=hu, activation = 'elu', return_sequences=True, name='LSTM2'))\n",
    "    # second dropout layer\n",
    "    model.add(Dropout(0.4, name='Dropout2'))\n",
    "\n",
    "    # third LSTM layer\n",
    "    model.add(LSTM(units=hu, activation = 'elu', return_sequences=False, name='LSTM3'))\n",
    "\n",
    "    # output layer\n",
    "    model.add(Dense(units=1, activation='sigmoid', name='Output'))\n",
    "\n",
    "    # optimizer\n",
    "    opt = Adam(learning_rate=LR, epsilon=1e-08)\n",
    "\n",
    "    # callback\n",
    "    my_callbacks = [\n",
    "        EarlyStopping(patience=PATIENCE, monitor='val_loss', mode='min', verbose=1, restore_best_weights=True),TensorBoard(log_dir=logdir)\n",
    "    ]\n",
    "\n",
    "    # model compilation - 'binary_crossentropy' - 'accuracy' - BinaryAccuracy(name='accuracy', threshold=0.5)\n",
    "    model.compile(optimizer=opt, \n",
    "                  loss=BinaryCrossentropy(), \n",
    "                  metrics=['accuracy',\n",
    "                           Precision(),\n",
    "                           Recall()])\n",
    "    # print model summary\n",
    "    model.summary()\n",
    "\n",
    "    # fit model\n",
    "    history = model.fit(g_train,\n",
    "              epochs=EPOCHS, \n",
    "                        batch_size = BATCH,\n",
    "              callbacks=my_callbacks, \n",
    "              verbose=1, \n",
    "              shuffle=False,\n",
    "              class_weight=class_weights,\n",
    "              validation_data=g_valid)\n",
    "\n",
    "    return model, history\n",
    "\n",
    "def LSTM_model_arch_23(g_train, g_valid, features, lookback, class_weights, hu=128, data='high_corr'):\n",
    "    '''\n",
    "    Model architecture: \n",
    "\n",
    "    - 3 dense layer before LSTM layers\n",
    "    - 3 LSTM layers, with drop-out layers\n",
    "    - 0 dense layer before output\n",
    "    '''\n",
    "    \n",
    "    tf.keras.backend.clear_session()   \n",
    "    \n",
    "    # instantiate the model\n",
    "    model = Sequential()\n",
    "\n",
    "    # tensorboard path\n",
    "    datetime = dt.datetime.now().strftime(\"%Y_%m_%d-%H_%M_%S\")\n",
    "    logdir = f\"./tensorboard/LSTM/initial_run/{data}/{inspect.currentframe().f_code.co_name}_{datetime}\"\n",
    "    print(f\"Now fitting model: {inspect.currentframe().f_code.co_name}\")\n",
    "    \n",
    "    # dense layer\n",
    "    model.add(Dense(units=features, name='Dense_start_1', input_shape=(lookback, features))) \n",
    "    model.add(Dense(units=S1, name='Dense_start_2')) \n",
    "    model.add(Dense(units=S2, name='Dense_start_3')) \n",
    "    \n",
    "    # first LSTM layer\n",
    "    model.add(LSTM(units=hu*2, input_shape=(lookback, S2), activation = 'elu', return_sequences=True, name='LSTM1'))\n",
    "    # first dropout layer\n",
    "    model.add(Dropout(0.4, name='Dropout1'))\n",
    "\n",
    "    # second LSTM layer\n",
    "    model.add(LSTM(units=hu, activation = 'elu', return_sequences=True, name='LSTM2'))\n",
    "    # second dropout layer\n",
    "    model.add(Dropout(0.4, name='Dropout2'))\n",
    "\n",
    "    # third LSTM layer\n",
    "    model.add(LSTM(units=hu, activation = 'elu', return_sequences=False, name='LSTM3'))\n",
    "\n",
    "    # output layer\n",
    "    model.add(Dense(units=1, activation='sigmoid', name='Output'))\n",
    "\n",
    "    # optimizer\n",
    "    opt = Adam(learning_rate=LR, epsilon=1e-08)\n",
    "\n",
    "    # callback\n",
    "    my_callbacks = [\n",
    "        EarlyStopping(patience=PATIENCE, monitor='val_loss', mode='min', verbose=1, restore_best_weights=True),TensorBoard(log_dir=logdir)\n",
    "    ]\n",
    "\n",
    "    # model compilation - 'binary_crossentropy' - 'accuracy' - BinaryAccuracy(name='accuracy', threshold=0.5)\n",
    "    model.compile(optimizer=opt, \n",
    "                  loss=BinaryCrossentropy(), \n",
    "                  metrics=['accuracy',\n",
    "                           Precision(),\n",
    "                           Recall()])\n",
    "    # print model summary\n",
    "    model.summary()\n",
    "\n",
    "    # fit model\n",
    "    history = model.fit(g_train,\n",
    "              epochs=EPOCHS, \n",
    "                        batch_size = BATCH,\n",
    "              callbacks=my_callbacks, \n",
    "              verbose=1, \n",
    "              shuffle=False,\n",
    "              class_weight=class_weights,\n",
    "              validation_data=g_valid)\n",
    "\n",
    "    return model, history\n",
    "\n",
    "def LSTM_model_arch_8(g_train, g_valid, features, lookback, class_weights, hu=128, data='high_corr'):\n",
    "    '''\n",
    "    Model architecture: \n",
    "    \n",
    "    - 0 dense layers before LSTM layers\n",
    "    - 3 LSTM layers, with drop-out layers\n",
    "    - 1 dense layer before output\n",
    "    '''\n",
    "    \n",
    "    tf.keras.backend.clear_session()   \n",
    "    \n",
    "    # instantiate the model\n",
    "    model = Sequential()\n",
    "\n",
    "    # tensorboard path\n",
    "    datetime = dt.datetime.now().strftime(\"%Y_%m_%d-%H_%M_%S\")\n",
    "    logdir = f\"./tensorboard/LSTM/initial_run/{data}/{inspect.currentframe().f_code.co_name}_{datetime}\"\n",
    "    print(f\"Now fitting model: {inspect.currentframe().f_code.co_name}\")\n",
    "    \n",
    "    # first LSTM layer\n",
    "    model.add(LSTM(units=hu*2, input_shape=(lookback, features), activation = 'elu', return_sequences=True, name='LSTM1'))\n",
    "    # first dropout layer\n",
    "    model.add(Dropout(0.4, name='Dropout1'))\n",
    "\n",
    "    # second LSTM layer\n",
    "    model.add(LSTM(units=hu, activation = 'elu', return_sequences=True, name='LSTM2'))\n",
    "    # second dropout layer\n",
    "    model.add(Dropout(0.4, name='Dropout2'))\n",
    "\n",
    "    # third LSTM layer\n",
    "    model.add(LSTM(units=hu, activation = 'elu', return_sequences=False, name='LSTM3'))\n",
    "    \n",
    "    # first dense layer\n",
    "    model.add(Dense(units=int(hu/2), activation='elu', name='Dense_end_1'))\n",
    "    \n",
    "    # output layer\n",
    "    model.add(Dense(units=1, activation='sigmoid', name='Output'))\n",
    "\n",
    "    # optimizer\n",
    "    opt = Adam(learning_rate=LR, epsilon=1e-08)\n",
    "\n",
    "    # callback\n",
    "    my_callbacks = [\n",
    "        EarlyStopping(patience=PATIENCE, monitor='val_loss', mode='min', verbose=1, restore_best_weights=True),TensorBoard(log_dir=logdir)\n",
    "    ]\n",
    "\n",
    "    # model compilation - 'binary_crossentropy' - 'accuracy' - BinaryAccuracy(name='accuracy', threshold=0.5)\n",
    "    model.compile(optimizer=opt, \n",
    "                  loss=BinaryCrossentropy(), \n",
    "                  metrics=['accuracy',\n",
    "                           Precision(),\n",
    "                           Recall()])\n",
    "    # print model summary\n",
    "    model.summary()\n",
    "\n",
    "    # fit model\n",
    "    history = model.fit(g_train,\n",
    "              epochs=EPOCHS, \n",
    "                        batch_size = BATCH,\n",
    "              callbacks=my_callbacks, \n",
    "              verbose=1, \n",
    "              shuffle=False,\n",
    "              class_weight=class_weights,\n",
    "              validation_data=g_valid)\n",
    "\n",
    "    return model, history\n",
    "\n",
    "def LSTM_model_arch_24(g_train, g_valid, features, lookback, class_weights, hu=128, data='high_corr'):\n",
    "    '''\n",
    "    Model architecture: \n",
    "    \n",
    "    - 2 dense layers before LSTM layers\n",
    "    - 3 LSTM layers, with drop-out layers\n",
    "    - 1 dense layer before output\n",
    "    '''\n",
    "    \n",
    "    tf.keras.backend.clear_session()   \n",
    "    \n",
    "    # instantiate the model\n",
    "    model = Sequential()\n",
    "\n",
    "    # tensorboard path\n",
    "    datetime = dt.datetime.now().strftime(\"%Y_%m_%d-%H_%M_%S\")\n",
    "    logdir = f\"./tensorboard/LSTM/initial_run/{data}/model_arch_24_{datetime}\"\n",
    "    print(f\"Now fitting model: {inspect.currentframe().f_code.co_name}\")\n",
    "\n",
    "    # dense layer\n",
    "    model.add(Dense(units=features, name='Dense_start_1', input_shape=(lookback, features))) \n",
    "    model.add(Dense(units=S2, name='Dense_start_2')) \n",
    "\n",
    "    # first LSTM layer\n",
    "    model.add(LSTM(units=hu*2, input_shape=(lookback, S2), activation = 'elu', return_sequences=True, name='LSTM1'))\n",
    "    # first dropout layer\n",
    "    model.add(Dropout(0.4, name='Dropout1'))\n",
    "\n",
    "    # second LSTM layer\n",
    "    model.add(LSTM(units=hu, activation = 'elu', return_sequences=True, name='LSTM2'))\n",
    "    # second dropout layer\n",
    "    model.add(Dropout(0.4, name='Dropout2'))\n",
    "\n",
    "    # third LSTM layer\n",
    "    model.add(LSTM(units=int(hu*3/4), activation = 'elu', return_sequences=False, name='LSTM3'))\n",
    "    \n",
    "    # first dense layer\n",
    "    model.add(Dense(units=int(hu/2), activation='elu', name='Dense_end_1'))\n",
    "    \n",
    "    # output layer\n",
    "    model.add(Dense(units=1, activation='sigmoid', name='Output'))\n",
    "\n",
    "    # optimizer\n",
    "    opt = Adam(learning_rate=LR, epsilon=1e-08)\n",
    "\n",
    "    # callback\n",
    "    my_callbacks = [\n",
    "        EarlyStopping(patience=PATIENCE, monitor='val_loss', mode='min', verbose=1, restore_best_weights=True), TensorBoard(log_dir=logdir)\n",
    "    ]\n",
    "\n",
    "    # model compilation - 'binary_crossentropy' - 'accuracy' - BinaryAccuracy(name='accuracy', threshold=0.5)\n",
    "    model.compile(optimizer=opt, \n",
    "                  loss=BinaryCrossentropy(), \n",
    "                  metrics=['accuracy',\n",
    "                           Precision(),\n",
    "                           Recall()])\n",
    "    # print model summary\n",
    "    model.summary()\n",
    "\n",
    "    # fit model\n",
    "    history = model.fit(g_train,\n",
    "              epochs=EPOCHS, \n",
    "                        batch_size = BATCH,\n",
    "              callbacks=my_callbacks, \n",
    "              verbose=1, \n",
    "              shuffle=False,\n",
    "              class_weight=class_weights,\n",
    "              validation_data=g_valid)\n",
    "\n",
    "    return model, history\n",
    "\n",
    "def LSTM_model_arch_25(g_train, g_valid, features, lookback, class_weights, hu=128, data='high_corr'):\n",
    "    '''\n",
    "    Model architecture: \n",
    "    \n",
    "    - 3 dense layers before LSTM layers\n",
    "    - 3 LSTM layers, with drop-out layers\n",
    "    - 1 dense layer before output\n",
    "    '''\n",
    "    \n",
    "    tf.keras.backend.clear_session()   \n",
    "    \n",
    "    # instantiate the model\n",
    "    model = Sequential()\n",
    "\n",
    "    # tensorboard path\n",
    "    datetime = dt.datetime.now().strftime(\"%Y_%m_%d-%H_%M_%S\")\n",
    "    logdir = f\"./tensorboard/LSTM/initial_run/{data}/{inspect.currentframe().f_code.co_name}_{datetime}\"\n",
    "    print(f\"Now fitting model: {inspect.currentframe().f_code.co_name}\")\n",
    "    \n",
    "    # dense layer\n",
    "    model.add(Dense(units=features, name='Dense_start_1', input_shape=(lookback, features))) \n",
    "    model.add(Dense(units=S1, name='Dense_start_2'))\n",
    "    model.add(Dense(units=S2, name='Dense_start_3')) \n",
    "\n",
    "    # first LSTM layer\n",
    "    model.add(LSTM(units=hu*2, input_shape=(lookback, S2), activation = 'elu', return_sequences=True, name='LSTM1'))\n",
    "    # first dropout layer\n",
    "    model.add(Dropout(0.4, name='Dropout1'))\n",
    "\n",
    "    # second LSTM layer\n",
    "    model.add(LSTM(units=hu, activation = 'elu', return_sequences=True, name='LSTM2'))\n",
    "    # second dropout layer\n",
    "    model.add(Dropout(0.4, name='Dropout2'))\n",
    "\n",
    "    # third LSTM layer\n",
    "    model.add(LSTM(units=hu, activation = 'elu', return_sequences=False, name='LSTM3'))\n",
    "    \n",
    "    # first dense layer\n",
    "    model.add(Dense(units=int(hu/2), activation='elu', name='Dense_end_1'))\n",
    "    \n",
    "    # output layer\n",
    "    model.add(Dense(units=1, activation='sigmoid', name='Output'))\n",
    "\n",
    "    # optimizer\n",
    "    opt = Adam(learning_rate=LR, epsilon=1e-08)\n",
    "\n",
    "    # callback\n",
    "    my_callbacks = [\n",
    "        EarlyStopping(patience=PATIENCE, monitor='val_loss', mode='min', verbose=1, restore_best_weights=True),TensorBoard(log_dir=logdir)\n",
    "    ]\n",
    "\n",
    "    # model compilation - 'binary_crossentropy' - 'accuracy' - BinaryAccuracy(name='accuracy', threshold=0.5)\n",
    "    model.compile(optimizer=opt, \n",
    "                  loss=BinaryCrossentropy(), \n",
    "                  metrics=['accuracy',\n",
    "                           Precision(),\n",
    "                           Recall()])\n",
    "    # print model summary\n",
    "    model.summary()\n",
    "\n",
    "    # fit model\n",
    "    history = model.fit(g_train,\n",
    "              epochs=EPOCHS, \n",
    "                        batch_size = BATCH,\n",
    "              callbacks=my_callbacks, \n",
    "              verbose=1, \n",
    "              shuffle=False,\n",
    "              class_weight=class_weights,\n",
    "              validation_data=g_valid)\n",
    "\n",
    "    return model, history\n",
    "\n",
    "def LSTM_model_arch_9(g_train, g_valid, features, lookback, class_weights, hu=128, data='high_corr'):\n",
    "    '''\n",
    "    Model architecture: \n",
    "    \n",
    "    - 0 dense layers before LSTM layers\n",
    "    - 3 LSTM layers, with drop-out layers for the first LSTM layer\n",
    "    - 2 dense layers before output\n",
    "    '''\n",
    "    \n",
    "    tf.keras.backend.clear_session() \n",
    "    \n",
    "    # instantiate the model\n",
    "    model = Sequential()\n",
    "\n",
    "    # tensorboard path\n",
    "    datetime = dt.datetime.now().strftime(\"%Y_%m_%d-%H_%M_%S\")\n",
    "    logdir = f\"./tensorboard/LSTM/initial_run/{data}/{inspect.currentframe().f_code.co_name}_{datetime}\"\n",
    "    print(f\"Now fitting model: {inspect.currentframe().f_code.co_name}\")\n",
    "    \n",
    "    # first LSTM layer\n",
    "    model.add(LSTM(units=hu*2, input_shape=(lookback, features), activation = 'elu', return_sequences=True, name='LSTM1'))\n",
    "    \n",
    "    # first dropout layer\n",
    "    model.add(Dropout(0.4, name='Dropout1'))\n",
    "\n",
    "    # second LSTM layer\n",
    "    model.add(LSTM(units=hu, activation = 'elu', return_sequences=True, name='LSTM2'))\n",
    "    \n",
    "    # second dropout layer\n",
    "    model.add(Dropout(0.4, name='Dropout2'))\n",
    "\n",
    "    # third LSTM layer\n",
    "    model.add(LSTM(units=hu, activation = 'elu', return_sequences=False, name='LSTM3'))\n",
    "    \n",
    "    # first dense layer\n",
    "    model.add(Dense(units=int(hu*3/4), activation='elu', name='Dense_end_1'))\n",
    "\n",
    "    # second dense layer\n",
    "    model.add(Dense(units=int(hu/2), activation='elu', name='Dense_end_2'))\n",
    "    \n",
    "    # output layer\n",
    "    model.add(Dense(units=1, activation='sigmoid', name='Output'))\n",
    "\n",
    "    # optimizer\n",
    "    opt = Adam(learning_rate=LR, epsilon=1e-08)\n",
    "\n",
    "    # callback\n",
    "    my_callbacks = [\n",
    "        EarlyStopping(patience=PATIENCE, monitor='val_loss', mode='min', verbose=1, restore_best_weights=True),TensorBoard(log_dir=logdir)\n",
    "    ]\n",
    "\n",
    "    model.build(input_shape=(None, lookback, features))\n",
    "\n",
    "    # model compilation - 'binary_crossentropy' - 'accuracy' - BinaryAccuracy(name='accuracy', threshold=0.5)\n",
    "    model.compile(optimizer=opt, \n",
    "                  loss=BinaryCrossentropy(), \n",
    "                  metrics=['accuracy',\n",
    "                           Precision(),\n",
    "                           Recall()])\n",
    "    # print model summary\n",
    "    model.summary()\n",
    "\n",
    "    # fit model\n",
    "    history = model.fit(g_train,\n",
    "              epochs=EPOCHS, \n",
    "                        batch_size = BATCH,\n",
    "              callbacks=my_callbacks, \n",
    "              verbose=1, \n",
    "              shuffle=False,\n",
    "              class_weight=class_weights,\n",
    "              validation_data=g_valid)\n",
    "\n",
    "    return model, history\n",
    "\n",
    "def LSTM_model_arch_26(g_train, g_valid, features, lookback, class_weights, hu=128, data='high_corr'):\n",
    "    '''\n",
    "    Model architecture: \n",
    "    \n",
    "    - 2 dense layers before LSTM layers\n",
    "    - 3 LSTM layers, with drop-out layers for the first LSTM layer\n",
    "    - 2 dense layers before output\n",
    "    '''\n",
    "    \n",
    "    tf.keras.backend.clear_session() \n",
    "    \n",
    "    # instantiate the model\n",
    "    model = Sequential()\n",
    "    \n",
    "    # tensorboard path\n",
    "    datetime = dt.datetime.now().strftime(\"%Y_%m_%d-%H_%M_%S\")\n",
    "    logdir = f\"./tensorboard/LSTM/initial_run/{data}/{inspect.currentframe().f_code.co_name}_{datetime}\"\n",
    "    print(f\"Now fitting model: {inspect.currentframe().f_code.co_name}\")\n",
    "    \n",
    "    # dense layer\n",
    "    model.add(Dense(units=features, name='Dense_start_1', input_shape=(lookback, features))) \n",
    "    model.add(Dense(units=S2, name='Dense_start_2')) \n",
    "\n",
    "    # first LSTM layer\n",
    "    model.add(LSTM(units=hu*2, input_shape=(lookback, S2), activation = 'elu', return_sequences=True, name='LSTM1'))\n",
    "    # first dropout layer\n",
    "    model.add(Dropout(0.4, name='Dropout1'))\n",
    "\n",
    "    # second LSTM layer\n",
    "    model.add(LSTM(units=hu, activation = 'elu', return_sequences=True, name='LSTM2'))\n",
    "    \n",
    "    # second dropout layer\n",
    "    model.add(Dropout(0.4, name='Dropout2'))\n",
    "\n",
    "    # third LSTM layer\n",
    "    model.add(LSTM(units=hu, activation = 'elu', return_sequences=False, name='LSTM3'))\n",
    "    \n",
    "    # first dense layer\n",
    "    model.add(Dense(units=int(hu*3/4), activation='elu', name='Dense_end_1'))\n",
    "\n",
    "    # second dense layer\n",
    "    model.add(Dense(units=int(hu/2), activation='elu', name='Dense_end_2'))\n",
    "    \n",
    "    # output layer\n",
    "    model.add(Dense(units=1, activation='sigmoid', name='Output'))\n",
    "\n",
    "    # optimizer\n",
    "    opt = Adam(learning_rate=LR, epsilon=1e-08)\n",
    "\n",
    "    # callback\n",
    "    my_callbacks = [\n",
    "        EarlyStopping(patience=PATIENCE, monitor='val_loss', mode='min', verbose=1, restore_best_weights=True),TensorBoard(log_dir=logdir)\n",
    "    ]\n",
    "\n",
    "    # model compilation - 'binary_crossentropy' - 'accuracy' - BinaryAccuracy(name='accuracy', threshold=0.5)\n",
    "    model.compile(optimizer=opt, \n",
    "                  loss=BinaryCrossentropy(), \n",
    "                  metrics=['accuracy',\n",
    "                           Precision(),\n",
    "                           Recall()])\n",
    "    # print model summary\n",
    "    model.summary()\n",
    "\n",
    "    # fit model\n",
    "    history = model.fit(g_train,\n",
    "              epochs=EPOCHS, \n",
    "                        batch_size = BATCH,\n",
    "              callbacks=my_callbacks, \n",
    "              verbose=1, \n",
    "              shuffle=False,\n",
    "              class_weight=class_weights,\n",
    "              validation_data=g_valid)\n",
    "\n",
    "    return model, history\n",
    "\n",
    "def LSTM_model_arch_27(g_train, g_valid, features, lookback, class_weights, hu=128, data='high_corr'):\n",
    "    '''\n",
    "    Model architecture: \n",
    "    \n",
    "    - 3 dense layers before LSTM layers\n",
    "    - 3 LSTM layers, with drop-out layers for the first LSTM layer\n",
    "    - 2 dense layers before output\n",
    "    '''\n",
    "    \n",
    "    tf.keras.backend.clear_session() \n",
    "    \n",
    "    # instantiate the model\n",
    "    model = Sequential()\n",
    "\n",
    "    # tensorboard path\n",
    "    datetime = dt.datetime.now().strftime(\"%Y_%m_%d-%H_%M_%S\")\n",
    "    logdir = f\"./tensorboard/LSTM/initial_run/{data}/{inspect.currentframe().f_code.co_name}_{datetime}\"\n",
    "    print(f\"Now fitting model: {inspect.currentframe().f_code.co_name}\")\n",
    "    \n",
    "    # dense layer\n",
    "    model.add(Dense(units=features, name='Dense_start_1', input_shape=(lookback, features),)) \n",
    "    model.add(Dense(units=S1, name='Dense_start_2')) \n",
    "    model.add(Dense(units=S2, name='Dense_start_3')) \n",
    "\n",
    "    # first LSTM layer\n",
    "    model.add(LSTM(units=hu*2, input_shape=(lookback, S2), activation = 'elu', return_sequences=True, name='LSTM1'))\n",
    "    # first dropout layer\n",
    "    model.add(Dropout(0.4, name='Dropout1'))\n",
    "\n",
    "    # second LSTM layer\n",
    "    model.add(LSTM(units=hu, activation = 'elu', return_sequences=True, name='LSTM2'))\n",
    "    \n",
    "    # second dropout layer\n",
    "    model.add(Dropout(0.4, name='Dropout2'))\n",
    "\n",
    "    # third LSTM layer\n",
    "    model.add(LSTM(units=hu, activation = 'elu', return_sequences=False, name='LSTM3'))\n",
    "    \n",
    "    # first dense layer\n",
    "    model.add(Dense(units=int(hu*3/4), activation='elu', name='Dense_end_1'))\n",
    "\n",
    "    # second dense layer\n",
    "    model.add(Dense(units=int(hu/2), activation='elu', name='Dense_end_2'))\n",
    "    \n",
    "    # output layer\n",
    "    model.add(Dense(units=1, activation='sigmoid', name='Output'))\n",
    "\n",
    "    # optimizer\n",
    "    opt = Adam(learning_rate=LR, epsilon=1e-08)\n",
    "\n",
    "    # callback\n",
    "    my_callbacks = [\n",
    "        EarlyStopping(patience=PATIENCE, monitor='val_loss', mode='min', verbose=1, restore_best_weights=True),TensorBoard(log_dir=logdir)\n",
    "    ]\n",
    "\n",
    "    # model compilation - 'binary_crossentropy' - 'accuracy' - BinaryAccuracy(name='accuracy', threshold=0.5)\n",
    "    model.compile(optimizer=opt, \n",
    "                  loss=BinaryCrossentropy(), \n",
    "                  metrics=['accuracy',\n",
    "                           Precision(),\n",
    "                           Recall()])\n",
    "    # print model summary\n",
    "    model.summary()\n",
    "\n",
    "    # fit model\n",
    "    history = model.fit(g_train,\n",
    "              epochs=EPOCHS, \n",
    "                        batch_size = BATCH,\n",
    "              callbacks=my_callbacks, \n",
    "              verbose=1, \n",
    "              shuffle=False,\n",
    "              class_weight=class_weights,\n",
    "              validation_data=g_valid)\n",
    "\n",
    "    return model, history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09eefd96-fff2-4f68-a4de-586609aac974",
   "metadata": {},
   "source": [
    "### Baseline model: Fit to training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3b2e3e15-390c-48eb-9537-ee8637ff116d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now fitting model: LSTM_model_arch_1\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " LSTM1 (LSTM)                (None, 20)                9360      \n",
      "                                                                 \n",
      " Dropout1 (Dropout)          (None, 20)                0         \n",
      "                                                                 \n",
      " Output (Dense)              (None, 1)                 21        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9381 (36.64 KB)\n",
      "Trainable params: 9381 (36.64 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 1s 21ms/step - loss: 0.7922 - accuracy: 0.4830 - precision: 0.4475 - recall: 0.5550 - val_loss: 0.7385 - val_accuracy: 0.4934 - val_precision: 0.4706 - val_recall: 0.7583\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.7073 - accuracy: 0.5206 - precision: 0.4798 - recall: 0.5721 - val_loss: 0.7180 - val_accuracy: 0.5022 - val_precision: 0.4669 - val_recall: 0.5355\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6927 - accuracy: 0.5376 - precision: 0.4952 - recall: 0.5550 - val_loss: 0.7188 - val_accuracy: 0.5110 - val_precision: 0.4615 - val_recall: 0.3412\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6786 - accuracy: 0.5759 - precision: 0.5364 - recall: 0.5364 - val_loss: 0.7230 - val_accuracy: 0.5175 - val_precision: 0.4698 - val_recall: 0.3318\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6719 - accuracy: 0.5780 - precision: 0.5387 - recall: 0.5395 - val_loss: 0.7324 - val_accuracy: 0.5110 - val_precision: 0.4565 - val_recall: 0.2986\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6645 - accuracy: 0.6021 - precision: 0.5665 - recall: 0.5550 - val_loss: 0.7462 - val_accuracy: 0.5066 - val_precision: 0.4624 - val_recall: 0.4076\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6578 - accuracy: 0.6057 - precision: 0.5622 - recall: 0.6233 - val_loss: 0.7473 - val_accuracy: 0.5154 - val_precision: 0.4702 - val_recall: 0.3744\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.6484 - accuracy: 0.6227 - precision: 0.5890 - recall: 0.5798 - val_loss: 0.7532 - val_accuracy: 0.5110 - val_precision: 0.4709 - val_recall: 0.4597\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.6379 - accuracy: 0.6291 - precision: 0.5889 - recall: 0.6264 - val_loss: 0.7673 - val_accuracy: 0.4956 - val_precision: 0.4574 - val_recall: 0.4834\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6280 - accuracy: 0.6284 - precision: 0.5839 - recall: 0.6527 - val_loss: 0.7713 - val_accuracy: 0.5285 - val_precision: 0.4907 - val_recall: 0.4976\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.6340 - accuracy: 0.6326 - precision: 0.6036 - recall: 0.5736 - val_loss: 0.7938 - val_accuracy: 0.4912 - val_precision: 0.4644 - val_recall: 0.6493\n",
      "Epoch 12/50\n",
      " 7/12 [================>.............] - ETA: 0s - loss: 0.5889 - accuracy: 0.6741 - precision: 0.6130 - recall: 0.7666Restoring model weights from the end of the best epoch: 2.\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.6052 - accuracy: 0.6603 - precision: 0.6092 - recall: 0.7178 - val_loss: 0.7911 - val_accuracy: 0.5175 - val_precision: 0.4815 - val_recall: 0.5545\n",
      "Epoch 12: early stopping\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Model_Architecture</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Validation_Loss</th>\n",
       "      <th>Validation_Accuracy</th>\n",
       "      <th>Validation_Precision</th>\n",
       "      <th>Validation_Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>High-corr filtered</td>\n",
       "      <td>LSTM_model_arch_1</td>\n",
       "      <td>0.605165</td>\n",
       "      <td>0.660284</td>\n",
       "      <td>0.609211</td>\n",
       "      <td>0.717829</td>\n",
       "      <td>0.791142</td>\n",
       "      <td>0.517544</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.554502</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Dataset Model_Architecture      Loss  Accuracy  Precision  \\\n",
       "0  High-corr filtered  LSTM_model_arch_1  0.605165  0.660284   0.609211   \n",
       "\n",
       "     Recall  Validation_Loss  Validation_Accuracy  Validation_Precision  \\\n",
       "0  0.717829         0.791142             0.517544              0.481481   \n",
       "\n",
       "   Validation_Recall  \n",
       "0           0.554502  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create empty dataframe to store results\n",
    "LSTM_baseline_model_som_kmeans_data =  pd.DataFrame(columns=['Dataset','Model_Architecture', 'Loss', 'Accuracy', 'Precision', 'Recall', \n",
    "                                            'Validation_Loss', \n",
    "                                            'Validation_Accuracy', 'Validation_Precision', 'Validation_Recall'])\n",
    "\n",
    "# Fit baseline model\n",
    "baseline_model_arch, fit_history = LSTM_model_arch_1(g_train_kmeans_som, g_dev_kmeans_som, features=num_features_kmeans_som, lookback=seqlen, class_weights=class_weight, hu=10, data=\"baseline_trial\")\n",
    "# Get baseline model results on development set\n",
    "LSTM_baseline_model_som_kmeans_data = LSTM_baseline_model_som_kmeans_data.append({\n",
    "    'Dataset': \"SOM K-means dimentionally reduced \",\n",
    "    'Model_Architecture': LSTM_model_arch_1.__name__,\n",
    "    'Loss': fit_history.history['loss'][-1], \n",
    "    'Accuracy': fit_history.history['accuracy'][-1], \n",
    "    'Precision': fit_history.history['precision'][-1], \n",
    "    'Recall': fit_history.history['recall'][-1], \n",
    "    'Validation_Loss': fit_history.history['val_loss'][-1], \n",
    "    'Validation_Accuracy': fit_history.history['val_accuracy'][-1], \n",
    "    'Validation_Precision': fit_history.history['val_precision'][-1], \n",
    "    'Validation_Recall': fit_history.history['val_recall'][-1]\n",
    "},ignore_index=True)\n",
    "\n",
    "# View baseline model results\n",
    "LSTM_baseline_model_som_kmeans_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b33ecc9-6943-407c-aa64-ade947b2a143",
   "metadata": {},
   "source": [
    "### Initial runs: Architecture shorlisting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d906fa7f-7f86-4364-babd-f8422282cade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now fitting model: LSTM_model_arch_1\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " LSTM1 (LSTM)                (None, 20)                9360      \n",
      "                                                                 \n",
      " Dropout1 (Dropout)          (None, 20)                0         \n",
      "                                                                 \n",
      " Output (Dense)              (None, 1)                 21        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9381 (36.64 KB)\n",
      "Trainable params: 9381 (36.64 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 1s 21ms/step - loss: 0.7626 - accuracy: 0.4986 - precision: 0.4574 - recall: 0.5163 - val_loss: 0.7049 - val_accuracy: 0.5219 - val_precision: 0.4685 - val_recall: 0.2464\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.7035 - accuracy: 0.5596 - precision: 0.5224 - recall: 0.4341 - val_loss: 0.7021 - val_accuracy: 0.5329 - val_precision: 0.4875 - val_recall: 0.1848\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6823 - accuracy: 0.5688 - precision: 0.5271 - recall: 0.5581 - val_loss: 0.7013 - val_accuracy: 0.5022 - val_precision: 0.4286 - val_recall: 0.2275\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6742 - accuracy: 0.5801 - precision: 0.5391 - recall: 0.5659 - val_loss: 0.7059 - val_accuracy: 0.4781 - val_precision: 0.4151 - val_recall: 0.3128\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6615 - accuracy: 0.5922 - precision: 0.5473 - recall: 0.6279 - val_loss: 0.7066 - val_accuracy: 0.4803 - val_precision: 0.4261 - val_recall: 0.3555\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.6509 - accuracy: 0.6227 - precision: 0.5790 - recall: 0.6419 - val_loss: 0.7122 - val_accuracy: 0.5044 - val_precision: 0.4503 - val_recall: 0.3223\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6435 - accuracy: 0.6255 - precision: 0.5869 - recall: 0.6124 - val_loss: 0.7192 - val_accuracy: 0.5088 - val_precision: 0.4663 - val_recall: 0.4265\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6276 - accuracy: 0.6440 - precision: 0.5968 - recall: 0.6837 - val_loss: 0.7636 - val_accuracy: 0.5044 - val_precision: 0.4497 - val_recall: 0.3175\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.6120 - accuracy: 0.6617 - precision: 0.6203 - recall: 0.6713 - val_loss: 0.7480 - val_accuracy: 0.5088 - val_precision: 0.4695 - val_recall: 0.4739\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6027 - accuracy: 0.6511 - precision: 0.6061 - recall: 0.6775 - val_loss: 0.7647 - val_accuracy: 0.5263 - val_precision: 0.4845 - val_recall: 0.3697\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.5877 - accuracy: 0.6816 - precision: 0.6463 - recall: 0.6713 - val_loss: 0.7460 - val_accuracy: 0.4978 - val_precision: 0.4575 - val_recall: 0.4597\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.5908 - accuracy: 0.6730 - precision: 0.6264 - recall: 0.7070 - val_loss: 0.7769 - val_accuracy: 0.5285 - val_precision: 0.4904 - val_recall: 0.4834\n",
      "Epoch 13/50\n",
      " 8/12 [===================>..........] - ETA: 0s - loss: 0.5809 - accuracy: 0.6689 - precision: 0.6218 - recall: 0.7155Restoring model weights from the end of the best epoch: 3.\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.5828 - accuracy: 0.6674 - precision: 0.6209 - recall: 0.7008 - val_loss: 0.7828 - val_accuracy: 0.5263 - val_precision: 0.4878 - val_recall: 0.4739\n",
      "Epoch 13: early stopping\n",
      "Now fitting model: LSTM_model_arch_1\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " LSTM1 (LSTM)                (None, 20)                4640      \n",
      "                                                                 \n",
      " Dropout1 (Dropout)          (None, 20)                0         \n",
      "                                                                 \n",
      " Output (Dense)              (None, 1)                 21        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4661 (18.21 KB)\n",
      "Trainable params: 4661 (18.21 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 1s 19ms/step - loss: 0.7493 - accuracy: 0.4915 - precision: 0.4439 - recall: 0.4419 - val_loss: 0.7066 - val_accuracy: 0.5197 - val_precision: 0.4706 - val_recall: 0.3033\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.7005 - accuracy: 0.5163 - precision: 0.4734 - recall: 0.5101 - val_loss: 0.7243 - val_accuracy: 0.4912 - val_precision: 0.4348 - val_recall: 0.3318\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5333 - precision: 0.4905 - recall: 0.5209 - val_loss: 0.7465 - val_accuracy: 0.5197 - val_precision: 0.4778 - val_recall: 0.4076\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6774 - accuracy: 0.5596 - precision: 0.5170 - recall: 0.5659 - val_loss: 0.7483 - val_accuracy: 0.4868 - val_precision: 0.4498 - val_recall: 0.4882\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6760 - accuracy: 0.5638 - precision: 0.5207 - recall: 0.5860 - val_loss: 0.7802 - val_accuracy: 0.4890 - val_precision: 0.4574 - val_recall: 0.5592\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6734 - accuracy: 0.5851 - precision: 0.5398 - recall: 0.6310 - val_loss: 0.8000 - val_accuracy: 0.4912 - val_precision: 0.4626 - val_recall: 0.6161\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6694 - accuracy: 0.5979 - precision: 0.5562 - recall: 0.5984 - val_loss: 0.8751 - val_accuracy: 0.5066 - val_precision: 0.4727 - val_recall: 0.5735\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6582 - accuracy: 0.6071 - precision: 0.5658 - recall: 0.6062 - val_loss: 0.8491 - val_accuracy: 0.5044 - val_precision: 0.4719 - val_recall: 0.5972\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6512 - accuracy: 0.6064 - precision: 0.5710 - recall: 0.5612 - val_loss: 0.9404 - val_accuracy: 0.5088 - val_precision: 0.4739 - val_recall: 0.5592\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6377 - accuracy: 0.6220 - precision: 0.5773 - recall: 0.6481 - val_loss: 0.9532 - val_accuracy: 0.4803 - val_precision: 0.4532 - val_recall: 0.5972\n",
      "Epoch 11/50\n",
      "10/12 [========================>.....] - ETA: 0s - loss: 0.6330 - accuracy: 0.6313 - precision: 0.5881 - recall: 0.6678Restoring model weights from the end of the best epoch: 1.\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6342 - accuracy: 0.6348 - precision: 0.5895 - recall: 0.6636 - val_loss: 1.0222 - val_accuracy: 0.5066 - val_precision: 0.4688 - val_recall: 0.4976\n",
      "Epoch 11: early stopping\n",
      "Now fitting model: LSTM_model_arch_2\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " LSTM1 (LSTM)                (None, 10)                4280      \n",
      "                                                                 \n",
      " Dropout1 (Dropout)          (None, 10)                0         \n",
      "                                                                 \n",
      " Dense_end_1 (Dense)         (None, 5)                 55        \n",
      "                                                                 \n",
      " Output (Dense)              (None, 1)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4341 (16.96 KB)\n",
      "Trainable params: 4341 (16.96 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 1s 19ms/step - loss: 0.7640 - accuracy: 0.4872 - precision: 0.4496 - recall: 0.5395 - val_loss: 0.7541 - val_accuracy: 0.4561 - val_precision: 0.4360 - val_recall: 0.5972\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.6940 - accuracy: 0.5262 - precision: 0.4819 - recall: 0.4760 - val_loss: 0.7374 - val_accuracy: 0.4518 - val_precision: 0.3789 - val_recall: 0.2891\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.6850 - accuracy: 0.5546 - precision: 0.5184 - recall: 0.3721 - val_loss: 0.7426 - val_accuracy: 0.5000 - val_precision: 0.4370 - val_recall: 0.2796\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.6916 - accuracy: 0.5546 - precision: 0.5157 - recall: 0.4341 - val_loss: 0.7448 - val_accuracy: 0.4846 - val_precision: 0.4294 - val_recall: 0.3460\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.6741 - accuracy: 0.5709 - precision: 0.5315 - recall: 0.5225 - val_loss: 0.7479 - val_accuracy: 0.4846 - val_precision: 0.4388 - val_recall: 0.4076\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.6769 - accuracy: 0.5652 - precision: 0.5252 - recall: 0.5163 - val_loss: 0.7508 - val_accuracy: 0.4868 - val_precision: 0.4433 - val_recall: 0.4265\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.6685 - accuracy: 0.5723 - precision: 0.5300 - recall: 0.5752 - val_loss: 0.7528 - val_accuracy: 0.4627 - val_precision: 0.4261 - val_recall: 0.4645\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6621 - accuracy: 0.5887 - precision: 0.5483 - recall: 0.5721 - val_loss: 0.7549 - val_accuracy: 0.4671 - val_precision: 0.4344 - val_recall: 0.5024\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6532 - accuracy: 0.6021 - precision: 0.5577 - recall: 0.6295 - val_loss: 0.7669 - val_accuracy: 0.4649 - val_precision: 0.4304 - val_recall: 0.4834\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6516 - accuracy: 0.6156 - precision: 0.5821 - recall: 0.5659 - val_loss: 0.7921 - val_accuracy: 0.4671 - val_precision: 0.4344 - val_recall: 0.5024\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6472 - accuracy: 0.6050 - precision: 0.5596 - recall: 0.6403 - val_loss: 0.7742 - val_accuracy: 0.4759 - val_precision: 0.4489 - val_recall: 0.5829\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.6528 - accuracy: 0.6227 - precision: 0.6037 - recall: 0.5101Restoring model weights from the end of the best epoch: 2.\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.6528 - accuracy: 0.6227 - precision: 0.6037 - recall: 0.5101 - val_loss: 0.7559 - val_accuracy: 0.4868 - val_precision: 0.4498 - val_recall: 0.4882\n",
      "Epoch 12: early stopping\n",
      "Now fitting model: LSTM_model_arch_2\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " LSTM1 (LSTM)                (None, 10)                1920      \n",
      "                                                                 \n",
      " Dropout1 (Dropout)          (None, 10)                0         \n",
      "                                                                 \n",
      " Dense_end_1 (Dense)         (None, 5)                 55        \n",
      "                                                                 \n",
      " Output (Dense)              (None, 1)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1981 (7.74 KB)\n",
      "Trainable params: 1981 (7.74 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 1s 18ms/step - loss: 0.7426 - accuracy: 0.4858 - precision: 0.4523 - recall: 0.5876 - val_loss: 0.7284 - val_accuracy: 0.4978 - val_precision: 0.4683 - val_recall: 0.6303\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.7146 - accuracy: 0.5340 - precision: 0.4914 - recall: 0.5287 - val_loss: 0.7205 - val_accuracy: 0.4671 - val_precision: 0.4344 - val_recall: 0.5024\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.6891 - accuracy: 0.5589 - precision: 0.5271 - recall: 0.3473 - val_loss: 0.7314 - val_accuracy: 0.5329 - val_precision: 0.4912 - val_recall: 0.2654\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.7043 - accuracy: 0.5454 - precision: 0.5052 - recall: 0.3023 - val_loss: 0.7784 - val_accuracy: 0.5417 - val_precision: 0.5088 - val_recall: 0.2749\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.7046 - accuracy: 0.5525 - precision: 0.5142 - recall: 0.3938 - val_loss: 0.7654 - val_accuracy: 0.5110 - val_precision: 0.4674 - val_recall: 0.4076\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.6840 - accuracy: 0.5667 - precision: 0.5260 - recall: 0.5333 - val_loss: 0.7430 - val_accuracy: 0.4978 - val_precision: 0.4622 - val_recall: 0.5213\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.6795 - accuracy: 0.5801 - precision: 0.5387 - recall: 0.5721 - val_loss: 0.7558 - val_accuracy: 0.4956 - val_precision: 0.4578 - val_recall: 0.4882\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.6881 - accuracy: 0.5511 - precision: 0.5087 - recall: 0.5457 - val_loss: 0.7683 - val_accuracy: 0.4803 - val_precision: 0.4496 - val_recall: 0.5498\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.6798 - accuracy: 0.5681 - precision: 0.5259 - recall: 0.5674 - val_loss: 0.7568 - val_accuracy: 0.4803 - val_precision: 0.4586 - val_recall: 0.6825\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.6824 - accuracy: 0.5716 - precision: 0.5300 - recall: 0.5612 - val_loss: 0.8204 - val_accuracy: 0.4978 - val_precision: 0.4702 - val_recall: 0.6730\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.6782 - accuracy: 0.5730 - precision: 0.5311 - recall: 0.5690 - val_loss: 0.7427 - val_accuracy: 0.4934 - val_precision: 0.4691 - val_recall: 0.7204\n",
      "Epoch 12/50\n",
      " 1/12 [=>............................] - ETA: 0s - loss: 0.6466 - accuracy: 0.6562 - precision: 0.6176 - recall: 0.4038Restoring model weights from the end of the best epoch: 2.\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.6737 - accuracy: 0.5837 - precision: 0.5424 - recall: 0.5752 - val_loss: 0.7569 - val_accuracy: 0.5022 - val_precision: 0.4722 - val_recall: 0.6445\n",
      "Epoch 12: early stopping\n",
      "Now fitting model: LSTM_model_arch_3\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " LSTM1 (LSTM)                (None, 20)                9360      \n",
      "                                                                 \n",
      " Dropout1 (Dropout)          (None, 20)                0         \n",
      "                                                                 \n",
      " Dense_end_1 (Dense)         (None, 7)                 147       \n",
      "                                                                 \n",
      " Dense_end_2 (Dense)         (None, 5)                 40        \n",
      "                                                                 \n",
      " Output (Dense)              (None, 1)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9553 (37.32 KB)\n",
      "Trainable params: 9553 (37.32 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 1s 20ms/step - loss: 0.7271 - accuracy: 0.5135 - precision: 0.4659 - recall: 0.4341 - val_loss: 0.7131 - val_accuracy: 0.5154 - val_precision: 0.4760 - val_recall: 0.4692\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6881 - accuracy: 0.5496 - precision: 0.5197 - recall: 0.2047 - val_loss: 0.7081 - val_accuracy: 0.5395 - val_precision: 0.5035 - val_recall: 0.3365\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6801 - accuracy: 0.5660 - precision: 0.5487 - recall: 0.2884 - val_loss: 0.7190 - val_accuracy: 0.5307 - val_precision: 0.4929 - val_recall: 0.4929\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6726 - accuracy: 0.5709 - precision: 0.5407 - recall: 0.4124 - val_loss: 0.7325 - val_accuracy: 0.5263 - val_precision: 0.4877 - val_recall: 0.4692\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6715 - accuracy: 0.5730 - precision: 0.5405 - recall: 0.4450 - val_loss: 0.7400 - val_accuracy: 0.5285 - val_precision: 0.4896 - val_recall: 0.4455\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6540 - accuracy: 0.6163 - precision: 0.5793 - recall: 0.5891 - val_loss: 0.7552 - val_accuracy: 0.5066 - val_precision: 0.4713 - val_recall: 0.5450\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6345 - accuracy: 0.6220 - precision: 0.5814 - recall: 0.6202 - val_loss: 0.7784 - val_accuracy: 0.5044 - val_precision: 0.4658 - val_recall: 0.4834\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6340 - accuracy: 0.6291 - precision: 0.5866 - recall: 0.6403 - val_loss: 0.7921 - val_accuracy: 0.4846 - val_precision: 0.4516 - val_recall: 0.5308\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6183 - accuracy: 0.6582 - precision: 0.6169 - recall: 0.6667 - val_loss: 0.8284 - val_accuracy: 0.4781 - val_precision: 0.4487 - val_recall: 0.5592\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.5907 - accuracy: 0.6745 - precision: 0.6405 - recall: 0.6574 - val_loss: 0.8606 - val_accuracy: 0.4978 - val_precision: 0.4662 - val_recall: 0.5877\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.5940 - accuracy: 0.6645 - precision: 0.6094 - recall: 0.7426 - val_loss: 0.8588 - val_accuracy: 0.5132 - val_precision: 0.4766 - val_recall: 0.5308\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.5957 - accuracy: 0.6922 - precision: 0.6972 - recall: 0.5783 - val_loss: 0.8759 - val_accuracy: 0.4956 - val_precision: 0.4715 - val_recall: 0.7441\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.5873 - accuracy: 0.6752 - precision: 0.6238 - recall: 0.7302 - val_loss: 0.8458 - val_accuracy: 0.5373 - val_precision: 0.5000 - val_recall: 0.4028\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.5658 - accuracy: 0.6965 - precision: 0.6770 - recall: 0.6434 - val_loss: 0.9163 - val_accuracy: 0.5154 - val_precision: 0.4841 - val_recall: 0.7204\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.5330 - accuracy: 0.7284 - precision: 0.6932 - recall: 0.7287 - val_loss: 0.9300 - val_accuracy: 0.5241 - val_precision: 0.4887 - val_recall: 0.6161\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.5370 - accuracy: 0.7277 - precision: 0.6856 - recall: 0.7473 - val_loss: 0.9533 - val_accuracy: 0.5154 - val_precision: 0.4813 - val_recall: 0.6114\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.4991 - accuracy: 0.7383 - precision: 0.7248 - recall: 0.6899 - val_loss: 0.9968 - val_accuracy: 0.5044 - val_precision: 0.4713 - val_recall: 0.5829\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.4955 - accuracy: 0.7433 - precision: 0.6979 - recall: 0.7736 - val_loss: 1.0005 - val_accuracy: 0.5307 - val_precision: 0.4939 - val_recall: 0.5735\n",
      "Epoch 19/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.4815 - accuracy: 0.7511 - precision: 0.7450 - recall: 0.6930 - val_loss: 1.0647 - val_accuracy: 0.5066 - val_precision: 0.4765 - val_recall: 0.6730\n",
      "Epoch 20/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.4581 - accuracy: 0.7716 - precision: 0.7386 - recall: 0.7752 - val_loss: 1.0843 - val_accuracy: 0.5132 - val_precision: 0.4784 - val_recall: 0.5782\n",
      "Epoch 21/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.4960 - accuracy: 0.7504 - precision: 0.7078 - recall: 0.7736 - val_loss: 1.0031 - val_accuracy: 0.5219 - val_precision: 0.4862 - val_recall: 0.5829\n",
      "Epoch 22/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.4372 - accuracy: 0.7936 - precision: 0.8183 - recall: 0.7054 - val_loss: 1.0885 - val_accuracy: 0.5066 - val_precision: 0.4739 - val_recall: 0.6019\n",
      "Epoch 23/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.4301 - accuracy: 0.7922 - precision: 0.7573 - recall: 0.8031 - val_loss: 1.0994 - val_accuracy: 0.4978 - val_precision: 0.4625 - val_recall: 0.5261\n",
      "Epoch 24/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.4316 - accuracy: 0.7901 - precision: 0.7748 - recall: 0.7628 - val_loss: 1.2028 - val_accuracy: 0.5022 - val_precision: 0.4706 - val_recall: 0.6066\n",
      "Epoch 25/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.4187 - accuracy: 0.8043 - precision: 0.8010 - recall: 0.7612 - val_loss: 1.2006 - val_accuracy: 0.5044 - val_precision: 0.4706 - val_recall: 0.5687\n",
      "Epoch 26/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.3831 - accuracy: 0.8199 - precision: 0.7846 - recall: 0.8357 - val_loss: 1.2938 - val_accuracy: 0.5241 - val_precision: 0.4886 - val_recall: 0.6114\n",
      "Epoch 27/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.3848 - accuracy: 0.8206 - precision: 0.8131 - recall: 0.7891 - val_loss: 1.3437 - val_accuracy: 0.4956 - val_precision: 0.4669 - val_recall: 0.6351\n",
      "Epoch 28/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.3715 - accuracy: 0.8284 - precision: 0.7950 - recall: 0.8419 - val_loss: 1.2277 - val_accuracy: 0.5066 - val_precision: 0.4676 - val_recall: 0.4787\n",
      "Epoch 29/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.3678 - accuracy: 0.8248 - precision: 0.8252 - recall: 0.7829 - val_loss: 1.3076 - val_accuracy: 0.5197 - val_precision: 0.4850 - val_recall: 0.6114\n",
      "Epoch 30/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.3479 - accuracy: 0.8355 - precision: 0.8124 - recall: 0.8326 - val_loss: 1.3610 - val_accuracy: 0.5088 - val_precision: 0.4723 - val_recall: 0.5261\n",
      "Epoch 31/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.3199 - accuracy: 0.8660 - precision: 0.8608 - recall: 0.8434 - val_loss: 1.3765 - val_accuracy: 0.4978 - val_precision: 0.4609 - val_recall: 0.5024\n",
      "Epoch 32/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.3675 - accuracy: 0.8277 - precision: 0.8430 - recall: 0.7659 - val_loss: 1.3965 - val_accuracy: 0.5044 - val_precision: 0.4686 - val_recall: 0.5308\n",
      "Epoch 33/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.3650 - accuracy: 0.8291 - precision: 0.7971 - recall: 0.8403 - val_loss: 1.3626 - val_accuracy: 0.5373 - val_precision: 0.5000 - val_recall: 0.5118\n",
      "Epoch 34/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.3679 - accuracy: 0.8312 - precision: 0.8375 - recall: 0.7829 - val_loss: 1.4466 - val_accuracy: 0.5154 - val_precision: 0.4797 - val_recall: 0.5592\n",
      "Epoch 35/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.3510 - accuracy: 0.8404 - precision: 0.8191 - recall: 0.8357 - val_loss: 1.3373 - val_accuracy: 0.4956 - val_precision: 0.4523 - val_recall: 0.4265\n",
      "Epoch 36/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.3265 - accuracy: 0.8539 - precision: 0.8512 - recall: 0.8248 - val_loss: 1.4639 - val_accuracy: 0.4912 - val_precision: 0.4610 - val_recall: 0.5877\n",
      "Epoch 37/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.3051 - accuracy: 0.8582 - precision: 0.8387 - recall: 0.8543 - val_loss: 1.4266 - val_accuracy: 0.5000 - val_precision: 0.4601 - val_recall: 0.4645\n",
      "Epoch 38/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.2982 - accuracy: 0.8723 - precision: 0.8756 - recall: 0.8403 - val_loss: 1.5839 - val_accuracy: 0.5022 - val_precision: 0.4667 - val_recall: 0.5308\n",
      "Epoch 39/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.2948 - accuracy: 0.8752 - precision: 0.8505 - recall: 0.8822 - val_loss: 1.5737 - val_accuracy: 0.4868 - val_precision: 0.4475 - val_recall: 0.4645\n",
      "Epoch 40/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.2681 - accuracy: 0.8879 - precision: 0.9092 - recall: 0.8388 - val_loss: 1.7239 - val_accuracy: 0.5000 - val_precision: 0.4659 - val_recall: 0.5498\n",
      "Epoch 41/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.2712 - accuracy: 0.8823 - precision: 0.8559 - recall: 0.8930 - val_loss: 1.6481 - val_accuracy: 0.4868 - val_precision: 0.4498 - val_recall: 0.4882\n",
      "Epoch 42/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.2687 - accuracy: 0.8851 - precision: 0.8889 - recall: 0.8558 - val_loss: 1.7580 - val_accuracy: 0.4956 - val_precision: 0.4622 - val_recall: 0.5498\n",
      "Epoch 43/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.2569 - accuracy: 0.8929 - precision: 0.8800 - recall: 0.8868 - val_loss: 1.6147 - val_accuracy: 0.4934 - val_precision: 0.4558 - val_recall: 0.4882\n",
      "Epoch 44/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.2581 - accuracy: 0.8844 - precision: 0.8912 - recall: 0.8512 - val_loss: 1.6415 - val_accuracy: 0.4912 - val_precision: 0.4561 - val_recall: 0.5166\n",
      "Epoch 45/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.2396 - accuracy: 0.8972 - precision: 0.8894 - recall: 0.8853 - val_loss: 1.6740 - val_accuracy: 0.5044 - val_precision: 0.4696 - val_recall: 0.5498\n",
      "Epoch 46/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.2313 - accuracy: 0.9028 - precision: 0.9006 - recall: 0.8853 - val_loss: 1.7256 - val_accuracy: 0.4978 - val_precision: 0.4587 - val_recall: 0.4739\n",
      "Epoch 47/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.2201 - accuracy: 0.9064 - precision: 0.8977 - recall: 0.8977 - val_loss: 1.8218 - val_accuracy: 0.4978 - val_precision: 0.4619 - val_recall: 0.5166\n",
      "Epoch 48/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.2241 - accuracy: 0.9028 - precision: 0.9110 - recall: 0.8729 - val_loss: 1.8733 - val_accuracy: 0.4978 - val_precision: 0.4634 - val_recall: 0.5403\n",
      "Epoch 49/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.2288 - accuracy: 0.9014 - precision: 0.8845 - recall: 0.9023 - val_loss: 1.8839 - val_accuracy: 0.5175 - val_precision: 0.4791 - val_recall: 0.4882\n",
      "Epoch 50/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.2367 - accuracy: 0.8986 - precision: 0.9010 - recall: 0.8744 - val_loss: 1.8481 - val_accuracy: 0.4890 - val_precision: 0.4534 - val_recall: 0.5071\n",
      "Now fitting model: LSTM_model_arch_3\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " LSTM1 (LSTM)                (None, 20)                4640      \n",
      "                                                                 \n",
      " Dropout1 (Dropout)          (None, 20)                0         \n",
      "                                                                 \n",
      " Dense_end_1 (Dense)         (None, 7)                 147       \n",
      "                                                                 \n",
      " Dense_end_2 (Dense)         (None, 5)                 40        \n",
      "                                                                 \n",
      " Output (Dense)              (None, 1)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4833 (18.88 KB)\n",
      "Trainable params: 4833 (18.88 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 1s 19ms/step - loss: 0.7107 - accuracy: 0.5248 - precision: 0.4785 - recall: 0.4310 - val_loss: 0.6964 - val_accuracy: 0.5197 - val_precision: 0.4810 - val_recall: 0.4787\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6943 - accuracy: 0.5000 - precision: 0.4636 - recall: 0.5922 - val_loss: 0.6917 - val_accuracy: 0.5636 - val_precision: 0.5484 - val_recall: 0.3223\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6889 - accuracy: 0.5411 - precision: 0.4984 - recall: 0.4744 - val_loss: 0.7022 - val_accuracy: 0.5526 - val_precision: 0.5455 - val_recall: 0.1991\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.6880 - accuracy: 0.5809 - precision: 0.5441 - recall: 0.5163 - val_loss: 0.7403 - val_accuracy: 0.5417 - val_precision: 0.5111 - val_recall: 0.2180\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6817 - accuracy: 0.5674 - precision: 0.5252 - recall: 0.5659 - val_loss: 0.7056 - val_accuracy: 0.5197 - val_precision: 0.4773 - val_recall: 0.3981\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.6728 - accuracy: 0.5816 - precision: 0.5385 - recall: 0.5969 - val_loss: 0.7112 - val_accuracy: 0.5307 - val_precision: 0.4908 - val_recall: 0.3791\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.6629 - accuracy: 0.5972 - precision: 0.5581 - recall: 0.5736 - val_loss: 0.7339 - val_accuracy: 0.5197 - val_precision: 0.4773 - val_recall: 0.3981\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.6566 - accuracy: 0.5922 - precision: 0.5497 - recall: 0.6000 - val_loss: 0.7550 - val_accuracy: 0.5219 - val_precision: 0.4851 - val_recall: 0.5403\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6499 - accuracy: 0.6113 - precision: 0.5694 - recall: 0.6171 - val_loss: 0.7851 - val_accuracy: 0.5175 - val_precision: 0.4816 - val_recall: 0.5592\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6570 - accuracy: 0.6071 - precision: 0.5666 - recall: 0.6000 - val_loss: 0.7987 - val_accuracy: 0.5285 - val_precision: 0.4912 - val_recall: 0.5308\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6398 - accuracy: 0.6206 - precision: 0.5764 - recall: 0.6434 - val_loss: 0.7553 - val_accuracy: 0.5263 - val_precision: 0.4905 - val_recall: 0.6114\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6306 - accuracy: 0.6475 - precision: 0.6104 - recall: 0.6341 - val_loss: 0.7826 - val_accuracy: 0.4956 - val_precision: 0.4691 - val_recall: 0.6825\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6253 - accuracy: 0.6511 - precision: 0.6123 - recall: 0.6465 - val_loss: 0.8194 - val_accuracy: 0.5066 - val_precision: 0.4735 - val_recall: 0.5924\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.6192 - accuracy: 0.6546 - precision: 0.6201 - recall: 0.6326 - val_loss: 0.8325 - val_accuracy: 0.4846 - val_precision: 0.4577 - val_recall: 0.6161\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.5972 - accuracy: 0.6610 - precision: 0.6112 - recall: 0.7116 - val_loss: 0.8548 - val_accuracy: 0.5088 - val_precision: 0.4695 - val_recall: 0.4739\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.5973 - accuracy: 0.6773 - precision: 0.6661 - recall: 0.5907 - val_loss: 0.8833 - val_accuracy: 0.4649 - val_precision: 0.4400 - val_recall: 0.5735\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.5986 - accuracy: 0.6546 - precision: 0.6026 - recall: 0.7194 - val_loss: 0.8583 - val_accuracy: 0.5154 - val_precision: 0.4781 - val_recall: 0.5166\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.6032 - accuracy: 0.6709 - precision: 0.6585 - recall: 0.5829 - val_loss: 0.8472 - val_accuracy: 0.4956 - val_precision: 0.4669 - val_recall: 0.6351\n",
      "Epoch 19/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.5857 - accuracy: 0.6787 - precision: 0.6364 - recall: 0.6946 - val_loss: 0.8481 - val_accuracy: 0.5000 - val_precision: 0.4664 - val_recall: 0.5592\n",
      "Epoch 20/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.5829 - accuracy: 0.6773 - precision: 0.6298 - recall: 0.7147 - val_loss: 0.8301 - val_accuracy: 0.5110 - val_precision: 0.4796 - val_recall: 0.6682\n",
      "Epoch 21/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.5590 - accuracy: 0.7035 - precision: 0.6810 - recall: 0.6620 - val_loss: 0.8727 - val_accuracy: 0.4934 - val_precision: 0.4612 - val_recall: 0.5640\n",
      "Epoch 22/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.5549 - accuracy: 0.6993 - precision: 0.6550 - recall: 0.7240 - val_loss: 0.9038 - val_accuracy: 0.5175 - val_precision: 0.4789 - val_recall: 0.4834\n",
      "Epoch 23/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.5552 - accuracy: 0.7092 - precision: 0.7072 - recall: 0.6217 - val_loss: 0.8883 - val_accuracy: 0.5022 - val_precision: 0.4680 - val_recall: 0.5545\n",
      "Epoch 24/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.5544 - accuracy: 0.7057 - precision: 0.6497 - recall: 0.7736 - val_loss: 0.8874 - val_accuracy: 0.4868 - val_precision: 0.4582 - val_recall: 0.5972\n",
      "Epoch 25/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.5365 - accuracy: 0.7121 - precision: 0.6729 - recall: 0.7209 - val_loss: 0.8964 - val_accuracy: 0.4912 - val_precision: 0.4644 - val_recall: 0.6493\n",
      "Epoch 26/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.5567 - accuracy: 0.6979 - precision: 0.6786 - recall: 0.6450 - val_loss: 0.8664 - val_accuracy: 0.5219 - val_precision: 0.4859 - val_recall: 0.5735\n",
      "Epoch 27/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.5411 - accuracy: 0.7106 - precision: 0.6570 - recall: 0.7690 - val_loss: 0.8640 - val_accuracy: 0.5000 - val_precision: 0.4712 - val_recall: 0.6588\n",
      "Epoch 28/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.5085 - accuracy: 0.7468 - precision: 0.7143 - recall: 0.7442 - val_loss: 0.8629 - val_accuracy: 0.4890 - val_precision: 0.4530 - val_recall: 0.5024\n",
      "Epoch 29/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.4935 - accuracy: 0.7447 - precision: 0.7124 - recall: 0.7411 - val_loss: 0.9158 - val_accuracy: 0.5000 - val_precision: 0.4679 - val_recall: 0.5877\n",
      "Epoch 30/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.4997 - accuracy: 0.7404 - precision: 0.7130 - recall: 0.7240 - val_loss: 0.9211 - val_accuracy: 0.4956 - val_precision: 0.4642 - val_recall: 0.5829\n",
      "Epoch 31/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.5164 - accuracy: 0.7355 - precision: 0.6948 - recall: 0.7519 - val_loss: 0.9047 - val_accuracy: 0.4956 - val_precision: 0.4652 - val_recall: 0.6019\n",
      "Epoch 32/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.5065 - accuracy: 0.7355 - precision: 0.6915 - recall: 0.7612 - val_loss: 0.9215 - val_accuracy: 0.4956 - val_precision: 0.4627 - val_recall: 0.5592\n",
      "Epoch 33/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.4909 - accuracy: 0.7482 - precision: 0.7231 - recall: 0.7287 - val_loss: 0.9807 - val_accuracy: 0.4759 - val_precision: 0.4435 - val_recall: 0.5213\n",
      "Epoch 34/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.5006 - accuracy: 0.7397 - precision: 0.7044 - recall: 0.7426 - val_loss: 1.0304 - val_accuracy: 0.4846 - val_precision: 0.4562 - val_recall: 0.5924\n",
      "Epoch 35/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.4783 - accuracy: 0.7489 - precision: 0.7270 - recall: 0.7225 - val_loss: 1.0320 - val_accuracy: 0.5088 - val_precision: 0.4758 - val_recall: 0.6066\n",
      "Epoch 36/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.4550 - accuracy: 0.7773 - precision: 0.7341 - recall: 0.8047 - val_loss: 1.0567 - val_accuracy: 0.4978 - val_precision: 0.4637 - val_recall: 0.5450\n",
      "Epoch 37/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.4731 - accuracy: 0.7496 - precision: 0.7378 - recall: 0.7023 - val_loss: 1.0496 - val_accuracy: 0.4890 - val_precision: 0.4599 - val_recall: 0.5972\n",
      "Epoch 38/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.4873 - accuracy: 0.7433 - precision: 0.6996 - recall: 0.7690 - val_loss: 1.0194 - val_accuracy: 0.5066 - val_precision: 0.4737 - val_recall: 0.5972\n",
      "Epoch 39/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.5016 - accuracy: 0.7433 - precision: 0.6990 - recall: 0.7705 - val_loss: 0.9548 - val_accuracy: 0.4890 - val_precision: 0.4636 - val_recall: 0.6635\n",
      "Epoch 40/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.4584 - accuracy: 0.7709 - precision: 0.7622 - recall: 0.7256 - val_loss: 1.0043 - val_accuracy: 0.4803 - val_precision: 0.4398 - val_recall: 0.4502\n",
      "Epoch 41/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.4501 - accuracy: 0.7844 - precision: 0.7504 - recall: 0.7922 - val_loss: 1.0002 - val_accuracy: 0.4846 - val_precision: 0.4565 - val_recall: 0.5972\n",
      "Epoch 42/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.4408 - accuracy: 0.7879 - precision: 0.7537 - recall: 0.7969 - val_loss: 1.0354 - val_accuracy: 0.4715 - val_precision: 0.4436 - val_recall: 0.5592\n",
      "Epoch 43/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.4358 - accuracy: 0.7908 - precision: 0.7684 - recall: 0.7767 - val_loss: 1.0754 - val_accuracy: 0.4715 - val_precision: 0.4432 - val_recall: 0.5545\n",
      "Epoch 44/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.4276 - accuracy: 0.8021 - precision: 0.7740 - recall: 0.8016 - val_loss: 1.0998 - val_accuracy: 0.4890 - val_precision: 0.4593 - val_recall: 0.5877\n",
      "Epoch 45/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.4219 - accuracy: 0.7972 - precision: 0.7613 - recall: 0.8109 - val_loss: 1.0359 - val_accuracy: 0.5066 - val_precision: 0.4762 - val_recall: 0.6635\n",
      "Epoch 46/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.4274 - accuracy: 0.7879 - precision: 0.7686 - recall: 0.7674 - val_loss: 1.0681 - val_accuracy: 0.4912 - val_precision: 0.4634 - val_recall: 0.6303\n",
      "Epoch 47/50\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 0.3984 - accuracy: 0.8014 - precision: 0.7664 - recall: 0.8140 - val_loss: 1.1115 - val_accuracy: 0.4825 - val_precision: 0.4528 - val_recall: 0.5687\n",
      "Epoch 48/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.4099 - accuracy: 0.8035 - precision: 0.7730 - recall: 0.8078 - val_loss: 1.2042 - val_accuracy: 0.4825 - val_precision: 0.4555 - val_recall: 0.6066\n",
      "Epoch 49/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.3924 - accuracy: 0.8071 - precision: 0.7731 - recall: 0.8186 - val_loss: 1.2203 - val_accuracy: 0.4912 - val_precision: 0.4613 - val_recall: 0.5924\n",
      "Epoch 50/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.4126 - accuracy: 0.7887 - precision: 0.7406 - recall: 0.8279 - val_loss: 1.1585 - val_accuracy: 0.4803 - val_precision: 0.4539 - val_recall: 0.6066\n",
      "Now fitting model: LSTM_model_arch_4\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " LSTM1 (LSTM)                (None, 21, 20)            9360      \n",
      "                                                                 \n",
      " Dropout1 (Dropout)          (None, 21, 20)            0         \n",
      "                                                                 \n",
      " LSTM2 (LSTM)                (None, 10)                1240      \n",
      "                                                                 \n",
      " Output (Dense)              (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10611 (41.45 KB)\n",
      "Trainable params: 10611 (41.45 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 1s 29ms/step - loss: 0.7069 - accuracy: 0.5213 - precision: 0.4770 - recall: 0.4822 - val_loss: 0.7298 - val_accuracy: 0.5132 - val_precision: 0.4779 - val_recall: 0.5640\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.6912 - accuracy: 0.5511 - precision: 0.5138 - recall: 0.3473 - val_loss: 0.7011 - val_accuracy: 0.5132 - val_precision: 0.4645 - val_recall: 0.3412\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.6845 - accuracy: 0.5766 - precision: 0.5494 - recall: 0.4140 - val_loss: 0.7117 - val_accuracy: 0.5197 - val_precision: 0.4825 - val_recall: 0.5213\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.6723 - accuracy: 0.5922 - precision: 0.5729 - recall: 0.4264 - val_loss: 0.7357 - val_accuracy: 0.5351 - val_precision: 0.4979 - val_recall: 0.5498\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.6656 - accuracy: 0.6078 - precision: 0.5813 - recall: 0.5101 - val_loss: 0.7574 - val_accuracy: 0.5132 - val_precision: 0.4760 - val_recall: 0.5166\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.6635 - accuracy: 0.6113 - precision: 0.5799 - recall: 0.5457 - val_loss: 0.7620 - val_accuracy: 0.5110 - val_precision: 0.4781 - val_recall: 0.6209\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.6537 - accuracy: 0.6241 - precision: 0.5993 - recall: 0.5380 - val_loss: 0.7687 - val_accuracy: 0.5110 - val_precision: 0.4756 - val_recall: 0.5545\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.6480 - accuracy: 0.6270 - precision: 0.6000 - recall: 0.5535 - val_loss: 0.7589 - val_accuracy: 0.5000 - val_precision: 0.4725 - val_recall: 0.6919\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.6517 - accuracy: 0.6135 - precision: 0.5665 - recall: 0.6605 - val_loss: 0.7586 - val_accuracy: 0.5241 - val_precision: 0.4871 - val_recall: 0.5355\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.6355 - accuracy: 0.6440 - precision: 0.6261 - recall: 0.5504 - val_loss: 0.7783 - val_accuracy: 0.4715 - val_precision: 0.4348 - val_recall: 0.4739\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.6319 - accuracy: 0.6333 - precision: 0.5947 - recall: 0.6233 - val_loss: 0.8007 - val_accuracy: 0.4759 - val_precision: 0.4504 - val_recall: 0.6019\n",
      "Epoch 12/50\n",
      "10/12 [========================>.....] - ETA: 0s - loss: 0.6263 - accuracy: 0.6242 - precision: 0.5711 - recall: 0.7424Restoring model weights from the end of the best epoch: 2.\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.6285 - accuracy: 0.6227 - precision: 0.5662 - recall: 0.7488 - val_loss: 0.8028 - val_accuracy: 0.4737 - val_precision: 0.4548 - val_recall: 0.6919\n",
      "Epoch 12: early stopping\n",
      "Now fitting model: LSTM_model_arch_4\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " LSTM1 (LSTM)                (None, 21, 20)            4640      \n",
      "                                                                 \n",
      " Dropout1 (Dropout)          (None, 21, 20)            0         \n",
      "                                                                 \n",
      " LSTM2 (LSTM)                (None, 10)                1240      \n",
      "                                                                 \n",
      " Output (Dense)              (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5891 (23.01 KB)\n",
      "Trainable params: 5891 (23.01 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 1s 29ms/step - loss: 0.7023 - accuracy: 0.5028 - precision: 0.4607 - recall: 0.5085 - val_loss: 0.7030 - val_accuracy: 0.4627 - val_precision: 0.4241 - val_recall: 0.4502\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.6906 - accuracy: 0.5447 - precision: 0.5026 - recall: 0.4527 - val_loss: 0.7067 - val_accuracy: 0.4846 - val_precision: 0.3846 - val_recall: 0.1896\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.6930 - accuracy: 0.5404 - precision: 0.4972 - recall: 0.4202 - val_loss: 0.7384 - val_accuracy: 0.4627 - val_precision: 0.4167 - val_recall: 0.4028\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.6872 - accuracy: 0.5376 - precision: 0.4965 - recall: 0.7705 - val_loss: 0.7523 - val_accuracy: 0.4715 - val_precision: 0.4483 - val_recall: 0.6161\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.6775 - accuracy: 0.5695 - precision: 0.5271 - recall: 0.5721 - val_loss: 0.8531 - val_accuracy: 0.4693 - val_precision: 0.4428 - val_recall: 0.5687\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.6863 - accuracy: 0.5943 - precision: 0.5498 - recall: 0.6248 - val_loss: 0.8605 - val_accuracy: 0.4649 - val_precision: 0.4558 - val_recall: 0.8057\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.6691 - accuracy: 0.5801 - precision: 0.5310 - recall: 0.7039 - val_loss: 0.7335 - val_accuracy: 0.4715 - val_precision: 0.4603 - val_recall: 0.8246\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.6735 - accuracy: 0.5752 - precision: 0.5340 - recall: 0.5597 - val_loss: 0.8123 - val_accuracy: 0.4715 - val_precision: 0.4599 - val_recall: 0.8152\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.6660 - accuracy: 0.5943 - precision: 0.5539 - recall: 0.5814 - val_loss: 0.7522 - val_accuracy: 0.4671 - val_precision: 0.4429 - val_recall: 0.5877\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.6550 - accuracy: 0.6099 - precision: 0.5905 - recall: 0.4806 - val_loss: 0.7599 - val_accuracy: 0.4846 - val_precision: 0.4625 - val_recall: 0.7014\n",
      "Epoch 11/50\n",
      "11/12 [==========================>...] - ETA: 0s - loss: 0.6581 - accuracy: 0.6136 - precision: 0.5818 - recall: 0.5566Restoring model weights from the end of the best epoch: 1.\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.6581 - accuracy: 0.6135 - precision: 0.5809 - recall: 0.5566 - val_loss: 0.7189 - val_accuracy: 0.5066 - val_precision: 0.4657 - val_recall: 0.4502\n",
      "Epoch 11: early stopping\n",
      "Now fitting model: LSTM_model_arch_5\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " LSTM1 (LSTM)                (None, 21, 20)            9360      \n",
      "                                                                 \n",
      " Dropout1 (Dropout)          (None, 21, 20)            0         \n",
      "                                                                 \n",
      " LSTM2 (LSTM)                (None, 10)                1240      \n",
      "                                                                 \n",
      " Dense1 (Dense)              (None, 5)                 55        \n",
      "                                                                 \n",
      " Output (Dense)              (None, 1)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10661 (41.64 KB)\n",
      "Trainable params: 10661 (41.64 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 1s 30ms/step - loss: 0.7199 - accuracy: 0.4823 - precision: 0.4614 - recall: 0.7876 - val_loss: 0.6940 - val_accuracy: 0.5000 - val_precision: 0.4619 - val_recall: 0.4882\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.7018 - accuracy: 0.5270 - precision: 0.4701 - recall: 0.2682 - val_loss: 0.6911 - val_accuracy: 0.5285 - val_precision: 0.4848 - val_recall: 0.3033\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.6908 - accuracy: 0.5567 - precision: 0.5365 - recall: 0.2279 - val_loss: 0.6894 - val_accuracy: 0.5417 - val_precision: 0.5058 - val_recall: 0.4123\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.6899 - accuracy: 0.5660 - precision: 0.5487 - recall: 0.2884 - val_loss: 0.6909 - val_accuracy: 0.5351 - val_precision: 0.4973 - val_recall: 0.4408\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.6850 - accuracy: 0.5624 - precision: 0.5395 - recall: 0.2961 - val_loss: 0.6959 - val_accuracy: 0.5022 - val_precision: 0.4592 - val_recall: 0.4265\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.6849 - accuracy: 0.5603 - precision: 0.5269 - recall: 0.3798 - val_loss: 0.7006 - val_accuracy: 0.5110 - val_precision: 0.4746 - val_recall: 0.5308\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.6811 - accuracy: 0.5695 - precision: 0.5424 - recall: 0.3767 - val_loss: 0.7000 - val_accuracy: 0.5154 - val_precision: 0.4781 - val_recall: 0.5166\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.6799 - accuracy: 0.5759 - precision: 0.5569 - recall: 0.3566 - val_loss: 0.7056 - val_accuracy: 0.5197 - val_precision: 0.4828 - val_recall: 0.5308\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.6839 - accuracy: 0.5887 - precision: 0.6066 - recall: 0.2868 - val_loss: 0.7100 - val_accuracy: 0.5241 - val_precision: 0.4879 - val_recall: 0.5735\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.6778 - accuracy: 0.5809 - precision: 0.5482 - recall: 0.4760 - val_loss: 0.7004 - val_accuracy: 0.5307 - val_precision: 0.4902 - val_recall: 0.3555\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.6774 - accuracy: 0.5972 - precision: 0.6360 - recall: 0.2791 - val_loss: 0.7026 - val_accuracy: 0.5329 - val_precision: 0.4904 - val_recall: 0.2417\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.6715 - accuracy: 0.5851 - precision: 0.5575 - recall: 0.4512 - val_loss: 0.7081 - val_accuracy: 0.5088 - val_precision: 0.4633 - val_recall: 0.3886\n",
      "Epoch 13/50\n",
      "11/12 [==========================>...] - ETA: 0s - loss: 0.6679 - accuracy: 0.5909 - precision: 0.5613 - recall: 0.4899Restoring model weights from the end of the best epoch: 3.\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.6677 - accuracy: 0.5915 - precision: 0.5613 - recall: 0.4899 - val_loss: 0.7108 - val_accuracy: 0.5197 - val_precision: 0.4688 - val_recall: 0.2844\n",
      "Epoch 13: early stopping\n",
      "Now fitting model: LSTM_model_arch_5\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " LSTM1 (LSTM)                (None, 21, 20)            4640      \n",
      "                                                                 \n",
      " Dropout1 (Dropout)          (None, 21, 20)            0         \n",
      "                                                                 \n",
      " LSTM2 (LSTM)                (None, 10)                1240      \n",
      "                                                                 \n",
      " Dense1 (Dense)              (None, 5)                 55        \n",
      "                                                                 \n",
      " Output (Dense)              (None, 1)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5941 (23.21 KB)\n",
      "Trainable params: 5941 (23.21 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 1s 28ms/step - loss: 0.6984 - accuracy: 0.5064 - precision: 0.4602 - recall: 0.4574 - val_loss: 0.6926 - val_accuracy: 0.5175 - val_precision: 0.4384 - val_recall: 0.1517\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.6938 - accuracy: 0.5433 - precision: 0.5088 - recall: 0.0450 - val_loss: 0.6926 - val_accuracy: 0.5197 - val_precision: 0.2500 - val_recall: 0.0190\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.6931 - accuracy: 0.5475 - precision: 0.6129 - recall: 0.0295 - val_loss: 0.6976 - val_accuracy: 0.5307 - val_precision: 0.2857 - val_recall: 0.0095\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.7037 - accuracy: 0.5525 - precision: 0.5972 - recall: 0.0667 - val_loss: 0.7127 - val_accuracy: 0.5197 - val_precision: 0.3889 - val_recall: 0.0664\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.6914 - accuracy: 0.5461 - precision: 0.5131 - recall: 0.1519 - val_loss: 0.7148 - val_accuracy: 0.5022 - val_precision: 0.4259 - val_recall: 0.2180\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.6922 - accuracy: 0.5574 - precision: 0.5335 - recall: 0.2589 - val_loss: 0.7541 - val_accuracy: 0.4890 - val_precision: 0.4345 - val_recall: 0.3460\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.6853 - accuracy: 0.5645 - precision: 0.5381 - recall: 0.3395 - val_loss: 0.7171 - val_accuracy: 0.4846 - val_precision: 0.4500 - val_recall: 0.5118\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.6834 - accuracy: 0.5723 - precision: 0.5402 - recall: 0.4372 - val_loss: 0.7201 - val_accuracy: 0.4956 - val_precision: 0.4618 - val_recall: 0.5450\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.6759 - accuracy: 0.5759 - precision: 0.5441 - recall: 0.4496 - val_loss: 0.7580 - val_accuracy: 0.4868 - val_precision: 0.4572 - val_recall: 0.5829\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.6709 - accuracy: 0.5752 - precision: 0.5428 - recall: 0.4527 - val_loss: 0.7728 - val_accuracy: 0.4671 - val_precision: 0.4245 - val_recall: 0.4265\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.6698 - accuracy: 0.5950 - precision: 0.5808 - recall: 0.4124 - val_loss: 0.7562 - val_accuracy: 0.4781 - val_precision: 0.4416 - val_recall: 0.4834\n",
      "Epoch 12/50\n",
      "11/12 [==========================>...] - ETA: 0s - loss: 0.7204 - accuracy: 0.5788 - precision: 0.5897 - recall: 0.2651Restoring model weights from the end of the best epoch: 2.\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.7194 - accuracy: 0.5794 - precision: 0.5897 - recall: 0.2651 - val_loss: 0.7482 - val_accuracy: 0.4912 - val_precision: 0.4348 - val_recall: 0.3318\n",
      "Epoch 12: early stopping\n",
      "Now fitting model: LSTM_model_arch_6\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " LSTM1 (LSTM)                (None, 21, 20)            9360      \n",
      "                                                                 \n",
      " Dropout1 (Dropout)          (None, 21, 20)            0         \n",
      "                                                                 \n",
      " LSTM2 (LSTM)                (None, 10)                1240      \n",
      "                                                                 \n",
      " Dense_end_1 (Dense)         (None, 7)                 77        \n",
      "                                                                 \n",
      " Dense_end_2 (Dense)         (None, 5)                 40        \n",
      "                                                                 \n",
      " Output (Dense)              (None, 1)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10723 (41.89 KB)\n",
      "Trainable params: 10723 (41.89 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 1s 32ms/step - loss: 0.7279 - accuracy: 0.4929 - precision: 0.4481 - recall: 0.4682 - val_loss: 0.6945 - val_accuracy: 0.5263 - val_precision: 0.4786 - val_recall: 0.2654\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.6947 - accuracy: 0.5553 - precision: 0.5608 - recall: 0.1287 - val_loss: 0.6968 - val_accuracy: 0.5351 - val_precision: 0.4962 - val_recall: 0.3128\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.6830 - accuracy: 0.5865 - precision: 0.5692 - recall: 0.3953 - val_loss: 0.7035 - val_accuracy: 0.5154 - val_precision: 0.4762 - val_recall: 0.4739\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.6779 - accuracy: 0.5667 - precision: 0.5211 - recall: 0.6512 - val_loss: 0.7063 - val_accuracy: 0.5219 - val_precision: 0.4843 - val_recall: 0.5118\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.6802 - accuracy: 0.5688 - precision: 0.5318 - recall: 0.4791 - val_loss: 0.7283 - val_accuracy: 0.5132 - val_precision: 0.4749 - val_recall: 0.4929\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.6715 - accuracy: 0.6035 - precision: 0.5556 - recall: 0.6667 - val_loss: 0.7461 - val_accuracy: 0.4759 - val_precision: 0.4440 - val_recall: 0.5261\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.6693 - accuracy: 0.6113 - precision: 0.5838 - recall: 0.5240 - val_loss: 0.7679 - val_accuracy: 0.4693 - val_precision: 0.4440 - val_recall: 0.5829\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.6569 - accuracy: 0.6007 - precision: 0.5460 - recall: 0.7550 - val_loss: 0.7410 - val_accuracy: 0.4956 - val_precision: 0.4562 - val_recall: 0.4692\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.6552 - accuracy: 0.6156 - precision: 0.5974 - recall: 0.4899 - val_loss: 0.7914 - val_accuracy: 0.4452 - val_precision: 0.4356 - val_recall: 0.6730\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.6549 - accuracy: 0.5915 - precision: 0.5466 - recall: 0.6279 - val_loss: 0.7666 - val_accuracy: 0.5000 - val_precision: 0.4585 - val_recall: 0.4455\n",
      "Epoch 11/50\n",
      "10/12 [========================>.....] - ETA: 0s - loss: 0.6623 - accuracy: 0.5984 - precision: 0.5642 - recall: 0.5661Restoring model weights from the end of the best epoch: 1.\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.6608 - accuracy: 0.6043 - precision: 0.5639 - recall: 0.5953 - val_loss: 0.7461 - val_accuracy: 0.5044 - val_precision: 0.4759 - val_recall: 0.7014\n",
      "Epoch 11: early stopping\n",
      "Now fitting model: LSTM_model_arch_6\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " LSTM1 (LSTM)                (None, 21, 20)            4640      \n",
      "                                                                 \n",
      " Dropout1 (Dropout)          (None, 21, 20)            0         \n",
      "                                                                 \n",
      " LSTM2 (LSTM)                (None, 10)                1240      \n",
      "                                                                 \n",
      " Dense_end_1 (Dense)         (None, 7)                 77        \n",
      "                                                                 \n",
      " Dense_end_2 (Dense)         (None, 5)                 40        \n",
      "                                                                 \n",
      " Output (Dense)              (None, 1)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6003 (23.45 KB)\n",
      "Trainable params: 6003 (23.45 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 1s 29ms/step - loss: 0.7037 - accuracy: 0.4943 - precision: 0.4465 - recall: 0.4403 - val_loss: 0.7127 - val_accuracy: 0.4474 - val_precision: 0.4484 - val_recall: 0.8436\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.6951 - accuracy: 0.5539 - precision: 0.5135 - recall: 0.4729 - val_loss: 0.7025 - val_accuracy: 0.5044 - val_precision: 0.4696 - val_recall: 0.5498\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.6878 - accuracy: 0.5511 - precision: 0.5120 - recall: 0.3984 - val_loss: 0.7047 - val_accuracy: 0.5154 - val_precision: 0.4813 - val_recall: 0.6114\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.6840 - accuracy: 0.5660 - precision: 0.5339 - recall: 0.4031 - val_loss: 0.7201 - val_accuracy: 0.5197 - val_precision: 0.4846 - val_recall: 0.5972\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.6803 - accuracy: 0.5879 - precision: 0.5627 - recall: 0.4450 - val_loss: 0.7506 - val_accuracy: 0.5110 - val_precision: 0.4799 - val_recall: 0.6777\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.6793 - accuracy: 0.5780 - precision: 0.5355 - recall: 0.5845 - val_loss: 0.7712 - val_accuracy: 0.4803 - val_precision: 0.4488 - val_recall: 0.5403\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.6722 - accuracy: 0.6071 - precision: 0.5923 - recall: 0.4527 - val_loss: 0.7775 - val_accuracy: 0.4825 - val_precision: 0.4601 - val_recall: 0.6825\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.6773 - accuracy: 0.5738 - precision: 0.5276 - recall: 0.6527 - val_loss: 0.7608 - val_accuracy: 0.5285 - val_precision: 0.4931 - val_recall: 0.6730\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.6788 - accuracy: 0.5979 - precision: 0.5924 - recall: 0.3876 - val_loss: 0.8349 - val_accuracy: 0.4890 - val_precision: 0.4633 - val_recall: 0.6588\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.6687 - accuracy: 0.5901 - precision: 0.5467 - recall: 0.6078 - val_loss: 0.7994 - val_accuracy: 0.4693 - val_precision: 0.4456 - val_recall: 0.6019\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.6585 - accuracy: 0.6092 - precision: 0.5723 - recall: 0.5767 - val_loss: 0.8758 - val_accuracy: 0.4693 - val_precision: 0.4467 - val_recall: 0.6161\n",
      "Epoch 12/50\n",
      "11/12 [==========================>...] - ETA: 0s - loss: 0.6607 - accuracy: 0.6200 - precision: 0.5914 - recall: 0.5519Restoring model weights from the end of the best epoch: 2.\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.6597 - accuracy: 0.6206 - precision: 0.5914 - recall: 0.5519 - val_loss: 0.8302 - val_accuracy: 0.4759 - val_precision: 0.4551 - val_recall: 0.6730\n",
      "Epoch 12: early stopping\n",
      "Now fitting model: LSTM_model_arch_7\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " LSTM1 (LSTM)                (None, 21, 20)            9360      \n",
      "                                                                 \n",
      " Dropout1 (Dropout)          (None, 21, 20)            0         \n",
      "                                                                 \n",
      " LSTM2 (LSTM)                (None, 21, 10)            1240      \n",
      "                                                                 \n",
      " Dropout2 (Dropout)          (None, 21, 10)            0         \n",
      "                                                                 \n",
      " LSTM3 (LSTM)                (None, 10)                840       \n",
      "                                                                 \n",
      " Output (Dense)              (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11451 (44.73 KB)\n",
      "Trainable params: 11451 (44.73 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 2s 37ms/step - loss: 0.6968 - accuracy: 0.5071 - precision: 0.4447 - recall: 0.3116 - val_loss: 0.7002 - val_accuracy: 0.4583 - val_precision: 0.4135 - val_recall: 0.4076\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.6948 - accuracy: 0.5121 - precision: 0.4547 - recall: 0.3349 - val_loss: 0.6972 - val_accuracy: 0.5263 - val_precision: 0.4286 - val_recall: 0.0711\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.6927 - accuracy: 0.5525 - precision: 0.5236 - recall: 0.2403 - val_loss: 0.6978 - val_accuracy: 0.5132 - val_precision: 0.4382 - val_recall: 0.1848\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.6860 - accuracy: 0.5652 - precision: 0.5357 - recall: 0.3721 - val_loss: 0.7018 - val_accuracy: 0.4978 - val_precision: 0.4521 - val_recall: 0.4028\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.6828 - accuracy: 0.5468 - precision: 0.5046 - recall: 0.5132 - val_loss: 0.7169 - val_accuracy: 0.4561 - val_precision: 0.4337 - val_recall: 0.5735\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.6886 - accuracy: 0.5610 - precision: 0.5259 - recall: 0.4093 - val_loss: 0.7043 - val_accuracy: 0.5329 - val_precision: 0.4940 - val_recall: 0.3934\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.6792 - accuracy: 0.5922 - precision: 0.5574 - recall: 0.5271 - val_loss: 0.7277 - val_accuracy: 0.4868 - val_precision: 0.4599 - val_recall: 0.6256\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.6724 - accuracy: 0.5823 - precision: 0.5380 - recall: 0.6140 - val_loss: 0.7682 - val_accuracy: 0.4693 - val_precision: 0.4517 - val_recall: 0.6872\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.6737 - accuracy: 0.5844 - precision: 0.5333 - recall: 0.7318 - val_loss: 0.7500 - val_accuracy: 0.5219 - val_precision: 0.4765 - val_recall: 0.3365\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.6795 - accuracy: 0.5809 - precision: 0.5549 - recall: 0.4233 - val_loss: 0.7220 - val_accuracy: 0.4518 - val_precision: 0.4506 - val_recall: 0.8436\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.6781 - accuracy: 0.5738 - precision: 0.5241 - recall: 0.7426 - val_loss: 0.7847 - val_accuracy: 0.4737 - val_precision: 0.4393 - val_recall: 0.4976\n",
      "Epoch 12/50\n",
      " 9/12 [=====================>........] - ETA: 0s - loss: 0.6679 - accuracy: 0.5964 - precision: 0.5581 - recall: 0.5570Restoring model weights from the end of the best epoch: 2.\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.6685 - accuracy: 0.5950 - precision: 0.5541 - recall: 0.5876 - val_loss: 0.8137 - val_accuracy: 0.4693 - val_precision: 0.4492 - val_recall: 0.6493\n",
      "Epoch 12: early stopping\n",
      "Now fitting model: LSTM_model_arch_7\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " LSTM1 (LSTM)                (None, 21, 20)            4640      \n",
      "                                                                 \n",
      " Dropout1 (Dropout)          (None, 21, 20)            0         \n",
      "                                                                 \n",
      " LSTM2 (LSTM)                (None, 21, 10)            1240      \n",
      "                                                                 \n",
      " Dropout2 (Dropout)          (None, 21, 10)            0         \n",
      "                                                                 \n",
      " LSTM3 (LSTM)                (None, 10)                840       \n",
      "                                                                 \n",
      " Output (Dense)              (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6731 (26.29 KB)\n",
      "Trainable params: 6731 (26.29 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 2s 35ms/step - loss: 0.6963 - accuracy: 0.4943 - precision: 0.4382 - recall: 0.3736 - val_loss: 0.6936 - val_accuracy: 0.4781 - val_precision: 0.4262 - val_recall: 0.3697\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.6923 - accuracy: 0.5142 - precision: 0.4588 - recall: 0.3457 - val_loss: 0.6909 - val_accuracy: 0.5263 - val_precision: 0.4444 - val_recall: 0.0948\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.6928 - accuracy: 0.5617 - precision: 0.5299 - recall: 0.3705 - val_loss: 0.7061 - val_accuracy: 0.5175 - val_precision: 0.4430 - val_recall: 0.1659\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.6931 - accuracy: 0.5489 - precision: 0.5068 - recall: 0.5178 - val_loss: 0.8125 - val_accuracy: 0.5329 - val_precision: 0.4949 - val_recall: 0.4645\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.6895 - accuracy: 0.5603 - precision: 0.5166 - recall: 0.6047 - val_loss: 0.7159 - val_accuracy: 0.4978 - val_precision: 0.4609 - val_recall: 0.5024\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.6896 - accuracy: 0.5603 - precision: 0.5277 - recall: 0.3690 - val_loss: 0.7553 - val_accuracy: 0.4868 - val_precision: 0.4594 - val_recall: 0.6161\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.6838 - accuracy: 0.5716 - precision: 0.5296 - recall: 0.5690 - val_loss: 0.7530 - val_accuracy: 0.4868 - val_precision: 0.4610 - val_recall: 0.6445\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.6763 - accuracy: 0.5695 - precision: 0.5246 - recall: 0.6279 - val_loss: 0.7691 - val_accuracy: 0.4825 - val_precision: 0.4608 - val_recall: 0.6967\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.6755 - accuracy: 0.5851 - precision: 0.5444 - recall: 0.5705 - val_loss: 0.7802 - val_accuracy: 0.4912 - val_precision: 0.4591 - val_recall: 0.5592\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.6742 - accuracy: 0.5844 - precision: 0.5440 - recall: 0.5659 - val_loss: 0.7834 - val_accuracy: 0.4912 - val_precision: 0.4694 - val_recall: 0.7630\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.6694 - accuracy: 0.5929 - precision: 0.5502 - recall: 0.6031 - val_loss: 0.7916 - val_accuracy: 0.5044 - val_precision: 0.4744 - val_recall: 0.6588\n",
      "Epoch 12/50\n",
      " 9/12 [=====================>........] - ETA: 0s - loss: 0.6671 - accuracy: 0.6094 - precision: 0.5909 - recall: 0.4696Restoring model weights from the end of the best epoch: 2.\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.6668 - accuracy: 0.6064 - precision: 0.5768 - recall: 0.5240 - val_loss: 0.7335 - val_accuracy: 0.4978 - val_precision: 0.4715 - val_recall: 0.7062\n",
      "Epoch 12: early stopping\n",
      "Now fitting model: LSTM_model_arch_8\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " LSTM1 (LSTM)                (None, 21, 20)            9360      \n",
      "                                                                 \n",
      " Dropout1 (Dropout)          (None, 21, 20)            0         \n",
      "                                                                 \n",
      " LSTM2 (LSTM)                (None, 21, 10)            1240      \n",
      "                                                                 \n",
      " Dropout2 (Dropout)          (None, 21, 10)            0         \n",
      "                                                                 \n",
      " LSTM3 (LSTM)                (None, 10)                840       \n",
      "                                                                 \n",
      " Dense_end_1 (Dense)         (None, 5)                 55        \n",
      "                                                                 \n",
      " Output (Dense)              (None, 1)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11501 (44.93 KB)\n",
      "Trainable params: 11501 (44.93 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 2s 37ms/step - loss: 0.7087 - accuracy: 0.5028 - precision: 0.4275 - recall: 0.2558 - val_loss: 0.6926 - val_accuracy: 0.5066 - val_precision: 0.4679 - val_recall: 0.4834\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.7050 - accuracy: 0.5348 - precision: 0.4781 - recall: 0.1860 - val_loss: 0.6918 - val_accuracy: 0.5307 - val_precision: 0.2857 - val_recall: 0.0095\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.6951 - accuracy: 0.5255 - precision: 0.4326 - recall: 0.1194 - val_loss: 0.6931 - val_accuracy: 0.5329 - val_precision: 0.4000 - val_recall: 0.0190\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.7031 - accuracy: 0.5355 - precision: 0.4775 - recall: 0.1643 - val_loss: 0.7009 - val_accuracy: 0.5132 - val_precision: 0.4179 - val_recall: 0.1327\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.6940 - accuracy: 0.5255 - precision: 0.4806 - recall: 0.4605 - val_loss: 0.6953 - val_accuracy: 0.4978 - val_precision: 0.4710 - val_recall: 0.6919\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.6960 - accuracy: 0.5128 - precision: 0.4723 - recall: 0.5550 - val_loss: 0.7021 - val_accuracy: 0.4890 - val_precision: 0.4610 - val_recall: 0.6161\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.6997 - accuracy: 0.5340 - precision: 0.4894 - recall: 0.4295 - val_loss: 0.7189 - val_accuracy: 0.4803 - val_precision: 0.4604 - val_recall: 0.7156\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.6890 - accuracy: 0.5177 - precision: 0.4798 - recall: 0.6450 - val_loss: 0.7040 - val_accuracy: 0.4912 - val_precision: 0.4690 - val_recall: 0.7536\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.6881 - accuracy: 0.5582 - precision: 0.5179 - recall: 0.4930 - val_loss: 0.7181 - val_accuracy: 0.5066 - val_precision: 0.4781 - val_recall: 0.7251\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.6894 - accuracy: 0.5723 - precision: 0.5294 - recall: 0.5860 - val_loss: 0.7251 - val_accuracy: 0.4912 - val_precision: 0.4697 - val_recall: 0.7725\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.6856 - accuracy: 0.5844 - precision: 0.5390 - recall: 0.6326 - val_loss: 0.7204 - val_accuracy: 0.4759 - val_precision: 0.4527 - val_recall: 0.6351\n",
      "Epoch 12/50\n",
      " 9/12 [=====================>........] - ETA: 0s - loss: 0.6841 - accuracy: 0.5773 - precision: 0.5350 - recall: 0.5665Restoring model weights from the end of the best epoch: 2.\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.6832 - accuracy: 0.5617 - precision: 0.5176 - recall: 0.6171 - val_loss: 0.7147 - val_accuracy: 0.4671 - val_precision: 0.4518 - val_recall: 0.7109\n",
      "Epoch 12: early stopping\n",
      "Now fitting model: LSTM_model_arch_8\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " LSTM1 (LSTM)                (None, 21, 20)            4640      \n",
      "                                                                 \n",
      " Dropout1 (Dropout)          (None, 21, 20)            0         \n",
      "                                                                 \n",
      " LSTM2 (LSTM)                (None, 21, 10)            1240      \n",
      "                                                                 \n",
      " Dropout2 (Dropout)          (None, 21, 10)            0         \n",
      "                                                                 \n",
      " LSTM3 (LSTM)                (None, 10)                840       \n",
      "                                                                 \n",
      " Dense_end_1 (Dense)         (None, 5)                 55        \n",
      "                                                                 \n",
      " Output (Dense)              (None, 1)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6781 (26.49 KB)\n",
      "Trainable params: 6781 (26.49 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 2s 36ms/step - loss: 0.7002 - accuracy: 0.4922 - precision: 0.4413 - recall: 0.4140 - val_loss: 0.6994 - val_accuracy: 0.4627 - val_precision: 0.4509 - val_recall: 0.7393\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.6921 - accuracy: 0.5397 - precision: 0.4945 - recall: 0.2806 - val_loss: 0.6985 - val_accuracy: 0.4868 - val_precision: 0.4135 - val_recall: 0.2607\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.6913 - accuracy: 0.5475 - precision: 0.5102 - recall: 0.2713 - val_loss: 0.7073 - val_accuracy: 0.4934 - val_precision: 0.4528 - val_recall: 0.4550\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.6907 - accuracy: 0.5553 - precision: 0.5150 - recall: 0.4791 - val_loss: 0.7079 - val_accuracy: 0.4934 - val_precision: 0.4686 - val_recall: 0.7062\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.6841 - accuracy: 0.5631 - precision: 0.5320 - recall: 0.3736 - val_loss: 0.7192 - val_accuracy: 0.4934 - val_precision: 0.4621 - val_recall: 0.5782\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.6850 - accuracy: 0.5681 - precision: 0.5289 - recall: 0.5101 - val_loss: 0.7436 - val_accuracy: 0.4649 - val_precision: 0.4558 - val_recall: 0.8057\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.6788 - accuracy: 0.5574 - precision: 0.5125 - recall: 0.6682 - val_loss: 0.7242 - val_accuracy: 0.4781 - val_precision: 0.4626 - val_recall: 0.7915\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.6938 - accuracy: 0.5688 - precision: 0.5325 - recall: 0.4698 - val_loss: 0.7727 - val_accuracy: 0.4605 - val_precision: 0.4584 - val_recall: 0.9147\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.6805 - accuracy: 0.5418 - precision: 0.4995 - recall: 0.7674 - val_loss: 0.6923 - val_accuracy: 0.5241 - val_precision: 0.4897 - val_recall: 0.6777\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.6807 - accuracy: 0.5865 - precision: 0.5749 - recall: 0.3690 - val_loss: 0.7678 - val_accuracy: 0.4561 - val_precision: 0.4536 - val_recall: 0.8578\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.6691 - accuracy: 0.5936 - precision: 0.5419 - recall: 0.7225 - val_loss: 0.7480 - val_accuracy: 0.4583 - val_precision: 0.4521 - val_recall: 0.8057\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.6638 - accuracy: 0.6092 - precision: 0.5799 - recall: 0.5287 - val_loss: 0.8167 - val_accuracy: 0.4671 - val_precision: 0.4626 - val_recall: 0.9384\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.6625 - accuracy: 0.5908 - precision: 0.5368 - recall: 0.7690 - val_loss: 0.7365 - val_accuracy: 0.4868 - val_precision: 0.4685 - val_recall: 0.8104\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.6654 - accuracy: 0.6035 - precision: 0.5850 - recall: 0.4589 - val_loss: 0.7819 - val_accuracy: 0.4583 - val_precision: 0.4559 - val_recall: 0.8815\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.6757 - accuracy: 0.5922 - precision: 0.5419 - recall: 0.7023 - val_loss: 0.8537 - val_accuracy: 0.4737 - val_precision: 0.4633 - val_recall: 0.8673\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.6614 - accuracy: 0.5865 - precision: 0.5369 - recall: 0.6992 - val_loss: 0.7424 - val_accuracy: 0.4671 - val_precision: 0.4641 - val_recall: 0.9810\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.6635 - accuracy: 0.6191 - precision: 0.5816 - recall: 0.5969 - val_loss: 0.7891 - val_accuracy: 0.4715 - val_precision: 0.4629 - val_recall: 0.8863\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.6519 - accuracy: 0.6277 - precision: 0.5898 - recall: 0.6109 - val_loss: 0.8382 - val_accuracy: 0.4803 - val_precision: 0.4673 - val_recall: 0.8815\n",
      "Epoch 19/50\n",
      " 9/12 [=====================>........] - ETA: 0s - loss: 0.6386 - accuracy: 0.6311 - precision: 0.5910 - recall: 0.6236Restoring model weights from the end of the best epoch: 9.\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.6473 - accuracy: 0.6213 - precision: 0.5837 - recall: 0.6000 - val_loss: 0.7867 - val_accuracy: 0.4737 - val_precision: 0.4611 - val_recall: 0.8152\n",
      "Epoch 19: early stopping\n",
      "Now fitting model: LSTM_model_arch_9\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " LSTM1 (LSTM)                (None, 21, 20)            9360      \n",
      "                                                                 \n",
      " Dropout1 (Dropout)          (None, 21, 20)            0         \n",
      "                                                                 \n",
      " LSTM2 (LSTM)                (None, 21, 10)            1240      \n",
      "                                                                 \n",
      " Dropout2 (Dropout)          (None, 21, 10)            0         \n",
      "                                                                 \n",
      " LSTM3 (LSTM)                (None, 10)                840       \n",
      "                                                                 \n",
      " Dense_end_1 (Dense)         (None, 7)                 77        \n",
      "                                                                 \n",
      " Dense_end_2 (Dense)         (None, 5)                 40        \n",
      "                                                                 \n",
      " Output (Dense)              (None, 1)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11563 (45.17 KB)\n",
      "Trainable params: 11563 (45.17 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 2s 38ms/step - loss: 0.6994 - accuracy: 0.4915 - precision: 0.4532 - recall: 0.5411 - val_loss: 0.6950 - val_accuracy: 0.4452 - val_precision: 0.4335 - val_recall: 0.6493\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.6978 - accuracy: 0.4972 - precision: 0.4468 - recall: 0.4171 - val_loss: 0.6945 - val_accuracy: 0.5197 - val_precision: 0.4600 - val_recall: 0.2180\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.6970 - accuracy: 0.5135 - precision: 0.4444 - recall: 0.2543 - val_loss: 0.6955 - val_accuracy: 0.5285 - val_precision: 0.4737 - val_recall: 0.1706\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.6910 - accuracy: 0.5340 - precision: 0.4872 - recall: 0.3535 - val_loss: 0.6990 - val_accuracy: 0.5110 - val_precision: 0.4774 - val_recall: 0.6019\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.6905 - accuracy: 0.5617 - precision: 0.5274 - recall: 0.4031 - val_loss: 0.7218 - val_accuracy: 0.5066 - val_precision: 0.4773 - val_recall: 0.6967\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.6822 - accuracy: 0.5461 - precision: 0.5028 - recall: 0.6992 - val_loss: 0.7159 - val_accuracy: 0.4978 - val_precision: 0.4667 - val_recall: 0.5972\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.6924 - accuracy: 0.5340 - precision: 0.4870 - recall: 0.3488 - val_loss: 0.7126 - val_accuracy: 0.5197 - val_precision: 0.4780 - val_recall: 0.4123\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.6931 - accuracy: 0.5078 - precision: 0.4723 - recall: 0.6465 - val_loss: 0.7477 - val_accuracy: 0.5175 - val_precision: 0.4717 - val_recall: 0.3555\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.6909 - accuracy: 0.5553 - precision: 0.5146 - recall: 0.4930 - val_loss: 0.7790 - val_accuracy: 0.5088 - val_precision: 0.4719 - val_recall: 0.5166\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.6824 - accuracy: 0.5645 - precision: 0.5233 - recall: 0.5395 - val_loss: 0.7448 - val_accuracy: 0.4759 - val_precision: 0.4548 - val_recall: 0.6682\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.6773 - accuracy: 0.5851 - precision: 0.5383 - recall: 0.6543 - val_loss: 0.7848 - val_accuracy: 0.4759 - val_precision: 0.4560 - val_recall: 0.6872\n",
      "Epoch 12/50\n",
      "10/12 [========================>.....] - ETA: 0s - loss: 0.6709 - accuracy: 0.5719 - precision: 0.5259 - recall: 0.7237Restoring model weights from the end of the best epoch: 2.\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.6719 - accuracy: 0.5702 - precision: 0.5225 - recall: 0.7023 - val_loss: 0.7480 - val_accuracy: 0.4803 - val_precision: 0.4500 - val_recall: 0.5545\n",
      "Epoch 12: early stopping\n",
      "Now fitting model: LSTM_model_arch_9\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " LSTM1 (LSTM)                (None, 21, 20)            4640      \n",
      "                                                                 \n",
      " Dropout1 (Dropout)          (None, 21, 20)            0         \n",
      "                                                                 \n",
      " LSTM2 (LSTM)                (None, 21, 10)            1240      \n",
      "                                                                 \n",
      " Dropout2 (Dropout)          (None, 21, 10)            0         \n",
      "                                                                 \n",
      " LSTM3 (LSTM)                (None, 10)                840       \n",
      "                                                                 \n",
      " Dense_end_1 (Dense)         (None, 7)                 77        \n",
      "                                                                 \n",
      " Dense_end_2 (Dense)         (None, 5)                 40        \n",
      "                                                                 \n",
      " Output (Dense)              (None, 1)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6843 (26.73 KB)\n",
      "Trainable params: 6843 (26.73 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 2s 37ms/step - loss: 0.7009 - accuracy: 0.5085 - precision: 0.4596 - recall: 0.4233 - val_loss: 0.6958 - val_accuracy: 0.4890 - val_precision: 0.4701 - val_recall: 0.8199\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.6916 - accuracy: 0.5489 - precision: 0.5243 - recall: 0.1504 - val_loss: 0.6887 - val_accuracy: 0.5373 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.6922 - accuracy: 0.5447 - precision: 0.5099 - recall: 0.1194 - val_loss: 0.6915 - val_accuracy: 0.5329 - val_precision: 0.4375 - val_recall: 0.0332\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.6882 - accuracy: 0.5723 - precision: 0.5407 - recall: 0.4326 - val_loss: 0.7049 - val_accuracy: 0.5088 - val_precision: 0.4649 - val_recall: 0.4076\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 0.6780 - accuracy: 0.5652 - precision: 0.5205 - recall: 0.6295 - val_loss: 0.7330 - val_accuracy: 0.4825 - val_precision: 0.4606 - val_recall: 0.6919\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.6778 - accuracy: 0.5801 - precision: 0.5317 - recall: 0.6884 - val_loss: 0.7443 - val_accuracy: 0.4890 - val_precision: 0.4693 - val_recall: 0.7962\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.6776 - accuracy: 0.5496 - precision: 0.5055 - recall: 0.7101 - val_loss: 0.7509 - val_accuracy: 0.4868 - val_precision: 0.4700 - val_recall: 0.8531\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.6761 - accuracy: 0.5865 - precision: 0.5425 - recall: 0.6140 - val_loss: 0.7393 - val_accuracy: 0.4890 - val_precision: 0.4703 - val_recall: 0.8246\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.6828 - accuracy: 0.5901 - precision: 0.5441 - recall: 0.6403 - val_loss: 0.7945 - val_accuracy: 0.5000 - val_precision: 0.4775 - val_recall: 0.8531\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.6580 - accuracy: 0.6021 - precision: 0.5484 - recall: 0.7380 - val_loss: 0.7266 - val_accuracy: 0.4956 - val_precision: 0.4743 - val_recall: 0.8294\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.6629 - accuracy: 0.6064 - precision: 0.5598 - recall: 0.6527 - val_loss: 0.7307 - val_accuracy: 0.4693 - val_precision: 0.4597 - val_recall: 0.8389\n",
      "Epoch 12/50\n",
      " 9/12 [=====================>........] - ETA: 0s - loss: 0.6602 - accuracy: 0.6033 - precision: 0.5638 - recall: 0.5798Restoring model weights from the end of the best epoch: 2.\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.6625 - accuracy: 0.6028 - precision: 0.5659 - recall: 0.5659 - val_loss: 0.7673 - val_accuracy: 0.4671 - val_precision: 0.4596 - val_recall: 0.8626\n",
      "Epoch 12: early stopping\n",
      "Now fitting model: LSTM_model_arch_10\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Dense_start_1 (Dense)       (None, 21, 96)            9312      \n",
      "                                                                 \n",
      " Dense_start_2 (Dense)       (None, 21, 40)            3880      \n",
      "                                                                 \n",
      " LSTM1 (LSTM)                (None, 10)                2040      \n",
      "                                                                 \n",
      " Dropout1 (Dropout)          (None, 10)                0         \n",
      "                                                                 \n",
      " Output (Dense)              (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15243 (59.54 KB)\n",
      "Trainable params: 15243 (59.54 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 1s 22ms/step - loss: 0.7897 - accuracy: 0.5106 - precision: 0.4691 - recall: 0.5302 - val_loss: 0.7160 - val_accuracy: 0.4934 - val_precision: 0.4603 - val_recall: 0.5498\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6927 - accuracy: 0.5532 - precision: 0.5155 - recall: 0.3860 - val_loss: 0.7040 - val_accuracy: 0.4978 - val_precision: 0.4211 - val_recall: 0.2275\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6979 - accuracy: 0.5440 - precision: 0.5025 - recall: 0.3116 - val_loss: 0.7155 - val_accuracy: 0.5417 - val_precision: 0.5050 - val_recall: 0.4787\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5475 - precision: 0.5050 - recall: 0.5535 - val_loss: 0.7159 - val_accuracy: 0.5132 - val_precision: 0.4758 - val_recall: 0.5118\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6761 - accuracy: 0.5482 - precision: 0.5065 - recall: 0.4837 - val_loss: 0.7212 - val_accuracy: 0.4846 - val_precision: 0.4531 - val_recall: 0.5498\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6725 - accuracy: 0.5723 - precision: 0.5331 - recall: 0.5240 - val_loss: 0.7309 - val_accuracy: 0.5110 - val_precision: 0.4732 - val_recall: 0.5024\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6569 - accuracy: 0.6021 - precision: 0.5792 - recall: 0.4760 - val_loss: 0.7527 - val_accuracy: 0.4956 - val_precision: 0.4642 - val_recall: 0.5829\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6578 - accuracy: 0.6043 - precision: 0.5698 - recall: 0.5504 - val_loss: 0.7651 - val_accuracy: 0.5175 - val_precision: 0.4830 - val_recall: 0.6066\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6525 - accuracy: 0.5936 - precision: 0.5545 - recall: 0.5674 - val_loss: 0.7385 - val_accuracy: 0.5263 - val_precision: 0.4910 - val_recall: 0.6445\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6449 - accuracy: 0.6220 - precision: 0.5795 - recall: 0.6326 - val_loss: 0.7357 - val_accuracy: 0.5263 - val_precision: 0.4915 - val_recall: 0.6872\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6667 - accuracy: 0.5865 - precision: 0.5445 - recall: 0.5876 - val_loss: 0.7371 - val_accuracy: 0.5022 - val_precision: 0.4730 - val_recall: 0.6635\n",
      "Epoch 12/50\n",
      " 9/12 [=====================>........] - ETA: 0s - loss: 0.6484 - accuracy: 0.6276 - precision: 0.5826 - recall: 0.6502Restoring model weights from the end of the best epoch: 2.\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6532 - accuracy: 0.6135 - precision: 0.5693 - recall: 0.6372 - val_loss: 0.7732 - val_accuracy: 0.5044 - val_precision: 0.4751 - val_recall: 0.6777\n",
      "Epoch 12: early stopping\n",
      "Now fitting model: LSTM_model_arch_10\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Dense_start_1 (Dense)       (None, 21, 37)            1406      \n",
      "                                                                 \n",
      " Dense_start_2 (Dense)       (None, 21, 40)            1520      \n",
      "                                                                 \n",
      " LSTM1 (LSTM)                (None, 10)                2040      \n",
      "                                                                 \n",
      " Dropout1 (Dropout)          (None, 10)                0         \n",
      "                                                                 \n",
      " Output (Dense)              (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4977 (19.44 KB)\n",
      "Trainable params: 4977 (19.44 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 1s 21ms/step - loss: 1.0112 - accuracy: 0.4844 - precision: 0.4426 - recall: 0.4899 - val_loss: 1.0349 - val_accuracy: 0.4583 - val_precision: 0.4423 - val_recall: 0.6540\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 0.7235 - accuracy: 0.5113 - precision: 0.4623 - recall: 0.4186 - val_loss: 0.7245 - val_accuracy: 0.4934 - val_precision: 0.4359 - val_recall: 0.3223\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.7115 - accuracy: 0.5234 - precision: 0.4790 - recall: 0.4775 - val_loss: 0.7398 - val_accuracy: 0.4496 - val_precision: 0.4048 - val_recall: 0.4028\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.7046 - accuracy: 0.5248 - precision: 0.4820 - recall: 0.5194 - val_loss: 0.7410 - val_accuracy: 0.4890 - val_precision: 0.4538 - val_recall: 0.5118\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.7000 - accuracy: 0.5277 - precision: 0.4834 - recall: 0.4744 - val_loss: 0.7792 - val_accuracy: 0.4846 - val_precision: 0.4535 - val_recall: 0.5545\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.7003 - accuracy: 0.5369 - precision: 0.4939 - recall: 0.5023 - val_loss: 0.7881 - val_accuracy: 0.4868 - val_precision: 0.4566 - val_recall: 0.5735\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.6898 - accuracy: 0.5376 - precision: 0.4946 - recall: 0.4961 - val_loss: 0.7676 - val_accuracy: 0.4890 - val_precision: 0.4583 - val_recall: 0.5735\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.6904 - accuracy: 0.5553 - precision: 0.5154 - recall: 0.4682 - val_loss: 0.7836 - val_accuracy: 0.5263 - val_precision: 0.4880 - val_recall: 0.4834\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5489 - precision: 0.5066 - recall: 0.5395 - val_loss: 0.7415 - val_accuracy: 0.4912 - val_precision: 0.4598 - val_recall: 0.5687\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6826 - accuracy: 0.5759 - precision: 0.5369 - recall: 0.5302 - val_loss: 0.7616 - val_accuracy: 0.5022 - val_precision: 0.4649 - val_recall: 0.5024\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6870 - accuracy: 0.5553 - precision: 0.5136 - recall: 0.5256 - val_loss: 0.8032 - val_accuracy: 0.4846 - val_precision: 0.4562 - val_recall: 0.5924\n",
      "Epoch 12/50\n",
      "10/12 [========================>.....] - ETA: 0s - loss: 0.6764 - accuracy: 0.5500 - precision: 0.5110 - recall: 0.5525Restoring model weights from the end of the best epoch: 2.\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6772 - accuracy: 0.5560 - precision: 0.5138 - recall: 0.5473 - val_loss: 0.8132 - val_accuracy: 0.4890 - val_precision: 0.4656 - val_recall: 0.7062\n",
      "Epoch 12: early stopping\n",
      "Now fitting model: LSTM_model_arch_11\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Dense_start_1 (Dense)       (None, 21, 199)           39800     \n",
      "                                                                 \n",
      " Dense_start_2 (Dense)       (None, 21, 80)            16000     \n",
      "                                                                 \n",
      " Dense_start_3 (Dense)       (None, 21, 40)            3240      \n",
      "                                                                 \n",
      " LSTM1 (LSTM)                (None, 10)                2040      \n",
      "                                                                 \n",
      " Dropout1 (Dropout)          (None, 10)                0         \n",
      "                                                                 \n",
      " Output (Dense)              (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 61091 (238.64 KB)\n",
      "Trainable params: 61091 (238.64 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 1s 26ms/step - loss: 1.0546 - accuracy: 0.5248 - precision: 0.4795 - recall: 0.4527 - val_loss: 0.7071 - val_accuracy: 0.4627 - val_precision: 0.4482 - val_recall: 0.6967\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.6968 - accuracy: 0.4936 - precision: 0.4620 - recall: 0.6512 - val_loss: 0.6956 - val_accuracy: 0.5044 - val_precision: 0.4654 - val_recall: 0.4787\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.6906 - accuracy: 0.5078 - precision: 0.4727 - recall: 0.6574 - val_loss: 0.6933 - val_accuracy: 0.4934 - val_precision: 0.4315 - val_recall: 0.2986\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.6953 - accuracy: 0.5142 - precision: 0.4662 - recall: 0.4279 - val_loss: 0.6942 - val_accuracy: 0.5154 - val_precision: 0.4528 - val_recall: 0.2275\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.6914 - accuracy: 0.5390 - precision: 0.4949 - recall: 0.3798 - val_loss: 0.6979 - val_accuracy: 0.5022 - val_precision: 0.4184 - val_recall: 0.1943\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.6864 - accuracy: 0.5362 - precision: 0.4913 - recall: 0.3938 - val_loss: 0.7043 - val_accuracy: 0.4912 - val_precision: 0.4054 - val_recall: 0.2133\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.6935 - accuracy: 0.5248 - precision: 0.4717 - recall: 0.3225 - val_loss: 0.7010 - val_accuracy: 0.5066 - val_precision: 0.4485 - val_recall: 0.2891\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.6832 - accuracy: 0.5511 - precision: 0.5122 - recall: 0.3907 - val_loss: 0.6962 - val_accuracy: 0.5132 - val_precision: 0.4421 - val_recall: 0.1991\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.6825 - accuracy: 0.5539 - precision: 0.5167 - recall: 0.3845 - val_loss: 0.6992 - val_accuracy: 0.5000 - val_precision: 0.4309 - val_recall: 0.2512\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.6840 - accuracy: 0.5660 - precision: 0.5353 - recall: 0.3876 - val_loss: 0.7018 - val_accuracy: 0.5110 - val_precision: 0.4375 - val_recall: 0.1991\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.6862 - accuracy: 0.5433 - precision: 0.5013 - recall: 0.3008 - val_loss: 0.7004 - val_accuracy: 0.5263 - val_precision: 0.4675 - val_recall: 0.1706\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.6858 - accuracy: 0.5418 - precision: 0.4983 - recall: 0.2310 - val_loss: 0.6973 - val_accuracy: 0.4912 - val_precision: 0.4234 - val_recall: 0.2749\n",
      "Epoch 13/50\n",
      " 7/12 [================>.............] - ETA: 0s - loss: 0.6793 - accuracy: 0.5725 - precision: 0.5283 - recall: 0.5504Restoring model weights from the end of the best epoch: 3.\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.6855 - accuracy: 0.5667 - precision: 0.5278 - recall: 0.5008 - val_loss: 0.6952 - val_accuracy: 0.5044 - val_precision: 0.4619 - val_recall: 0.4313\n",
      "Epoch 13: early stopping\n",
      "Now fitting model: LSTM_model_arch_11\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Dense_start_1 (Dense)       (None, 21, 96)            9312      \n",
      "                                                                 \n",
      " Dense_start_2 (Dense)       (None, 21, 80)            7760      \n",
      "                                                                 \n",
      " Dense_start_3 (Dense)       (None, 21, 40)            3240      \n",
      "                                                                 \n",
      " LSTM1 (LSTM)                (None, 10)                2040      \n",
      "                                                                 \n",
      " Dropout1 (Dropout)          (None, 10)                0         \n",
      "                                                                 \n",
      " Output (Dense)              (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 22363 (87.36 KB)\n",
      "Trainable params: 22363 (87.36 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 1s 23ms/step - loss: 0.7443 - accuracy: 0.5206 - precision: 0.4782 - recall: 0.5271 - val_loss: 0.7181 - val_accuracy: 0.4737 - val_precision: 0.4449 - val_recall: 0.5545\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.7037 - accuracy: 0.5213 - precision: 0.4754 - recall: 0.4496 - val_loss: 0.7007 - val_accuracy: 0.5417 - val_precision: 0.5119 - val_recall: 0.2038\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6934 - accuracy: 0.5504 - precision: 0.5247 - recall: 0.1814 - val_loss: 0.7020 - val_accuracy: 0.5461 - val_precision: 0.5250 - val_recall: 0.1991\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6897 - accuracy: 0.5546 - precision: 0.5321 - recall: 0.2186 - val_loss: 0.7046 - val_accuracy: 0.5373 - val_precision: 0.5000 - val_recall: 0.2370\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6863 - accuracy: 0.5489 - precision: 0.5136 - recall: 0.2636 - val_loss: 0.7041 - val_accuracy: 0.5395 - val_precision: 0.5041 - val_recall: 0.2938\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6834 - accuracy: 0.5553 - precision: 0.5263 - recall: 0.2791 - val_loss: 0.7374 - val_accuracy: 0.5373 - val_precision: 0.5000 - val_recall: 0.3791\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6747 - accuracy: 0.5475 - precision: 0.5064 - recall: 0.4279 - val_loss: 0.7545 - val_accuracy: 0.5154 - val_precision: 0.4750 - val_recall: 0.4502\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.7214 - accuracy: 0.5433 - precision: 0.5010 - recall: 0.3752 - val_loss: 0.7126 - val_accuracy: 0.5285 - val_precision: 0.4896 - val_recall: 0.4455\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 0.6951 - accuracy: 0.5383 - precision: 0.4952 - recall: 0.4791 - val_loss: 0.7087 - val_accuracy: 0.4715 - val_precision: 0.4531 - val_recall: 0.6872\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.6882 - accuracy: 0.5248 - precision: 0.4674 - recall: 0.2775 - val_loss: 0.7035 - val_accuracy: 0.5373 - val_precision: 0.5000 - val_recall: 0.3081\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6937 - accuracy: 0.5589 - precision: 0.5466 - recall: 0.2093 - val_loss: 0.7080 - val_accuracy: 0.5548 - val_precision: 0.5392 - val_recall: 0.2607\n",
      "Epoch 12/50\n",
      " 8/12 [===================>..........] - ETA: 0s - loss: 0.6837 - accuracy: 0.5713 - precision: 0.6127 - recall: 0.1847Restoring model weights from the end of the best epoch: 2.\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6839 - accuracy: 0.5638 - precision: 0.5682 - recall: 0.1938 - val_loss: 0.7140 - val_accuracy: 0.5592 - val_precision: 0.5463 - val_recall: 0.2796\n",
      "Epoch 12: early stopping\n",
      "Now fitting model: LSTM_model_arch_12\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Dense_start_1 (Dense)       (None, 21, 199)           39800     \n",
      "                                                                 \n",
      " Dense_start_2 (Dense)       (None, 21, 40)            8000      \n",
      "                                                                 \n",
      " LSTM1 (LSTM)                (None, 10)                2040      \n",
      "                                                                 \n",
      " Dropout1 (Dropout)          (None, 10)                0         \n",
      "                                                                 \n",
      " Dense_end_1 (Dense)         (None, 5)                 55        \n",
      "                                                                 \n",
      " Output (Dense)              (None, 1)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 49901 (194.93 KB)\n",
      "Trainable params: 49901 (194.93 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 1s 25ms/step - loss: 0.8345 - accuracy: 0.5028 - precision: 0.4571 - recall: 0.4620 - val_loss: 0.6917 - val_accuracy: 0.5175 - val_precision: 0.3953 - val_recall: 0.0806\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6977 - accuracy: 0.5369 - precision: 0.4879 - recall: 0.2496 - val_loss: 0.6940 - val_accuracy: 0.5373 - val_precision: 0.5000 - val_recall: 0.0190\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.6942 - accuracy: 0.5440 - precision: 0.5030 - recall: 0.2589 - val_loss: 0.6910 - val_accuracy: 0.5439 - val_precision: 0.5484 - val_recall: 0.0806\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6915 - accuracy: 0.5511 - precision: 0.5169 - recall: 0.2837 - val_loss: 0.6881 - val_accuracy: 0.5570 - val_precision: 0.6364 - val_recall: 0.0995\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5426 - precision: 0.5000 - recall: 0.3473 - val_loss: 0.6892 - val_accuracy: 0.5461 - val_precision: 0.5909 - val_recall: 0.0616\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.6782 - accuracy: 0.5702 - precision: 0.5379 - recall: 0.4295 - val_loss: 0.6891 - val_accuracy: 0.5592 - val_precision: 0.5258 - val_recall: 0.4834\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.6849 - accuracy: 0.5532 - precision: 0.5178 - recall: 0.3380 - val_loss: 0.6927 - val_accuracy: 0.5526 - val_precision: 0.7333 - val_recall: 0.0521\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.6823 - accuracy: 0.5709 - precision: 0.5585 - recall: 0.2961 - val_loss: 0.6901 - val_accuracy: 0.5526 - val_precision: 0.5340 - val_recall: 0.2607\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.6767 - accuracy: 0.5787 - precision: 0.5669 - recall: 0.3349 - val_loss: 0.6858 - val_accuracy: 0.5899 - val_precision: 0.7143 - val_recall: 0.1896\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.6741 - accuracy: 0.5908 - precision: 0.5872 - recall: 0.3550 - val_loss: 0.6848 - val_accuracy: 0.5943 - val_precision: 0.6250 - val_recall: 0.3081\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.6888 - accuracy: 0.5865 - precision: 0.5620 - recall: 0.4357 - val_loss: 0.6896 - val_accuracy: 0.5570 - val_precision: 0.5542 - val_recall: 0.2180\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.6763 - accuracy: 0.5752 - precision: 0.5498 - recall: 0.3938 - val_loss: 0.6771 - val_accuracy: 0.5965 - val_precision: 0.5882 - val_recall: 0.4265\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6613 - accuracy: 0.6050 - precision: 0.6053 - recall: 0.3922 - val_loss: 0.6980 - val_accuracy: 0.5395 - val_precision: 0.5017 - val_recall: 0.7109\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.6789 - accuracy: 0.5844 - precision: 0.5688 - recall: 0.3783 - val_loss: 0.6936 - val_accuracy: 0.5570 - val_precision: 0.5315 - val_recall: 0.3602\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6851 - accuracy: 0.5773 - precision: 0.5380 - recall: 0.5380 - val_loss: 0.6893 - val_accuracy: 0.5658 - val_precision: 0.5496 - val_recall: 0.3412\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6677 - accuracy: 0.5936 - precision: 0.6915 - recall: 0.2016 - val_loss: 0.6876 - val_accuracy: 0.5921 - val_precision: 0.6404 - val_recall: 0.2701\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6572 - accuracy: 0.5894 - precision: 0.5809 - recall: 0.3674 - val_loss: 0.6844 - val_accuracy: 0.5921 - val_precision: 0.5806 - val_recall: 0.4265\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6582 - accuracy: 0.6007 - precision: 0.5774 - recall: 0.4744 - val_loss: 0.6820 - val_accuracy: 0.5965 - val_precision: 0.6015 - val_recall: 0.3791\n",
      "Epoch 19/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.6578 - accuracy: 0.6007 - precision: 0.6444 - recall: 0.2837 - val_loss: 0.6905 - val_accuracy: 0.5768 - val_precision: 0.5517 - val_recall: 0.4550\n",
      "Epoch 20/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6578 - accuracy: 0.6170 - precision: 0.6134 - recall: 0.4403 - val_loss: 0.6924 - val_accuracy: 0.5702 - val_precision: 0.5330 - val_recall: 0.5735\n",
      "Epoch 21/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.6623 - accuracy: 0.5986 - precision: 0.5857 - recall: 0.4186 - val_loss: 0.6734 - val_accuracy: 0.5811 - val_precision: 0.6042 - val_recall: 0.2749\n",
      "Epoch 22/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6567 - accuracy: 0.6064 - precision: 0.6380 - recall: 0.3225 - val_loss: 0.6838 - val_accuracy: 0.5811 - val_precision: 0.5568 - val_recall: 0.4645\n",
      "Epoch 23/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6494 - accuracy: 0.6071 - precision: 0.5958 - recall: 0.4388 - val_loss: 0.6882 - val_accuracy: 0.5811 - val_precision: 0.5549 - val_recall: 0.4787\n",
      "Epoch 24/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.6333 - accuracy: 0.6348 - precision: 0.6275 - recall: 0.4961 - val_loss: 0.6893 - val_accuracy: 0.6096 - val_precision: 0.6279 - val_recall: 0.3839\n",
      "Epoch 25/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.6510 - accuracy: 0.6447 - precision: 0.6698 - recall: 0.4403 - val_loss: 0.7021 - val_accuracy: 0.5702 - val_precision: 0.5369 - val_recall: 0.5166\n",
      "Epoch 26/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6277 - accuracy: 0.6355 - precision: 0.6229 - recall: 0.5147 - val_loss: 0.6891 - val_accuracy: 0.5789 - val_precision: 0.5442 - val_recall: 0.5545\n",
      "Epoch 27/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.6272 - accuracy: 0.6305 - precision: 0.6211 - recall: 0.4930 - val_loss: 0.6757 - val_accuracy: 0.6118 - val_precision: 0.5904 - val_recall: 0.5261\n",
      "Epoch 28/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.6198 - accuracy: 0.6511 - precision: 0.6571 - recall: 0.4961 - val_loss: 0.6869 - val_accuracy: 0.5987 - val_precision: 0.5761 - val_recall: 0.5024\n",
      "Epoch 29/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.6219 - accuracy: 0.6546 - precision: 0.6688 - recall: 0.4853 - val_loss: 0.6914 - val_accuracy: 0.5833 - val_precision: 0.5459 - val_recall: 0.5924\n",
      "Epoch 30/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.6242 - accuracy: 0.6362 - precision: 0.6236 - recall: 0.5163 - val_loss: 0.6926 - val_accuracy: 0.6009 - val_precision: 0.5838 - val_recall: 0.4787\n",
      "Epoch 31/50\n",
      " 8/12 [===================>..........] - ETA: 0s - loss: 0.6206 - accuracy: 0.6523 - precision: 0.7032 - recall: 0.4225Restoring model weights from the end of the best epoch: 21.\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.6219 - accuracy: 0.6440 - precision: 0.6674 - recall: 0.4419 - val_loss: 0.6805 - val_accuracy: 0.5746 - val_precision: 0.5459 - val_recall: 0.4787\n",
      "Epoch 31: early stopping\n",
      "Now fitting model: LSTM_model_arch_12\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Dense_start_1 (Dense)       (None, 21, 96)            9312      \n",
      "                                                                 \n",
      " Dense_start_2 (Dense)       (None, 21, 40)            3880      \n",
      "                                                                 \n",
      " LSTM1 (LSTM)                (None, 10)                2040      \n",
      "                                                                 \n",
      " Dropout1 (Dropout)          (None, 10)                0         \n",
      "                                                                 \n",
      " Dense_end_1 (Dense)         (None, 5)                 55        \n",
      "                                                                 \n",
      " Output (Dense)              (None, 1)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15293 (59.74 KB)\n",
      "Trainable params: 15293 (59.74 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 1s 22ms/step - loss: 0.7651 - accuracy: 0.5085 - precision: 0.4683 - recall: 0.5504 - val_loss: 0.6984 - val_accuracy: 0.5241 - val_precision: 0.4828 - val_recall: 0.3981\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.7027 - accuracy: 0.5248 - precision: 0.4703 - recall: 0.3070 - val_loss: 0.6999 - val_accuracy: 0.5110 - val_precision: 0.4302 - val_recall: 0.1754\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6910 - accuracy: 0.5489 - precision: 0.5152 - recall: 0.2372 - val_loss: 0.7121 - val_accuracy: 0.5175 - val_precision: 0.4634 - val_recall: 0.2701\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6963 - accuracy: 0.5489 - precision: 0.5127 - recall: 0.2822 - val_loss: 0.7141 - val_accuracy: 0.5373 - val_precision: 0.5000 - val_recall: 0.3365\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6807 - accuracy: 0.5745 - precision: 0.5486 - recall: 0.3938 - val_loss: 0.7220 - val_accuracy: 0.5175 - val_precision: 0.4734 - val_recall: 0.3791\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6805 - accuracy: 0.5723 - precision: 0.5453 - recall: 0.3922 - val_loss: 0.7344 - val_accuracy: 0.4978 - val_precision: 0.4612 - val_recall: 0.5071\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6826 - accuracy: 0.5518 - precision: 0.5105 - recall: 0.4884 - val_loss: 0.7417 - val_accuracy: 0.4890 - val_precision: 0.4590 - val_recall: 0.5829\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6818 - accuracy: 0.5702 - precision: 0.5404 - recall: 0.4047 - val_loss: 0.7191 - val_accuracy: 0.5329 - val_precision: 0.4919 - val_recall: 0.2891\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6773 - accuracy: 0.5965 - precision: 0.6011 - recall: 0.3504 - val_loss: 0.7475 - val_accuracy: 0.5351 - val_precision: 0.4971 - val_recall: 0.4123\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6721 - accuracy: 0.5837 - precision: 0.5537 - recall: 0.4636 - val_loss: 0.7469 - val_accuracy: 0.5241 - val_precision: 0.4833 - val_recall: 0.4123\n",
      "Epoch 11/50\n",
      " 9/12 [=====================>........] - ETA: 0s - loss: 0.6715 - accuracy: 0.5964 - precision: 0.5670 - recall: 0.4905Restoring model weights from the end of the best epoch: 1.\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6696 - accuracy: 0.6050 - precision: 0.5794 - recall: 0.4977 - val_loss: 0.7322 - val_accuracy: 0.5219 - val_precision: 0.4840 - val_recall: 0.5024\n",
      "Epoch 11: early stopping\n",
      "Now fitting model: LSTM_model_arch_13\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Dense_start_1 (Dense)       (None, 21, 199)           39800     \n",
      "                                                                 \n",
      " Dense_start_2 (Dense)       (None, 21, 80)            16000     \n",
      "                                                                 \n",
      " Dense_start_3 (Dense)       (None, 21, 40)            3240      \n",
      "                                                                 \n",
      " LSTM1 (LSTM)                (None, 10)                2040      \n",
      "                                                                 \n",
      " Dropout1 (Dropout)          (None, 10)                0         \n",
      "                                                                 \n",
      " Dense_end_1 (Dense)         (None, 5)                 55        \n",
      "                                                                 \n",
      " Output (Dense)              (None, 1)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 61141 (238.83 KB)\n",
      "Trainable params: 61141 (238.83 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 1s 25ms/step - loss: 0.8657 - accuracy: 0.4929 - precision: 0.4303 - recall: 0.3349 - val_loss: 0.6911 - val_accuracy: 0.5373 - val_precision: 0.5000 - val_recall: 0.2844\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.7019 - accuracy: 0.5319 - precision: 0.4869 - recall: 0.4310 - val_loss: 0.6908 - val_accuracy: 0.5329 - val_precision: 0.4815 - val_recall: 0.1232\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.6976 - accuracy: 0.5163 - precision: 0.4701 - recall: 0.4512 - val_loss: 0.6904 - val_accuracy: 0.5263 - val_precision: 0.4627 - val_recall: 0.1469\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.6996 - accuracy: 0.5050 - precision: 0.4577 - recall: 0.4450 - val_loss: 0.6883 - val_accuracy: 0.5285 - val_precision: 0.4767 - val_recall: 0.1943\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.6975 - accuracy: 0.4993 - precision: 0.4577 - recall: 0.5116 - val_loss: 0.6918 - val_accuracy: 0.5197 - val_precision: 0.4661 - val_recall: 0.2607\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.6948 - accuracy: 0.5262 - precision: 0.4746 - recall: 0.3333 - val_loss: 0.6930 - val_accuracy: 0.5329 - val_precision: 0.4896 - val_recall: 0.2227\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.6932 - accuracy: 0.5475 - precision: 0.5232 - recall: 0.1225 - val_loss: 0.6928 - val_accuracy: 0.5373 - val_precision: 0.5000 - val_recall: 0.0190\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.6955 - accuracy: 0.5489 - precision: 0.5634 - recall: 0.0620 - val_loss: 0.6896 - val_accuracy: 0.5351 - val_precision: 0.4800 - val_recall: 0.0569\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.6913 - accuracy: 0.5461 - precision: 0.5143 - recall: 0.1395 - val_loss: 0.6890 - val_accuracy: 0.5439 - val_precision: 0.5333 - val_recall: 0.1137\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.6899 - accuracy: 0.5695 - precision: 0.6092 - recall: 0.1643 - val_loss: 0.6916 - val_accuracy: 0.5592 - val_precision: 0.5431 - val_recall: 0.2986\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.6963 - accuracy: 0.5333 - precision: 0.4769 - recall: 0.2078 - val_loss: 0.6922 - val_accuracy: 0.5351 - val_precision: 0.4865 - val_recall: 0.0853\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.6911 - accuracy: 0.5567 - precision: 0.5926 - recall: 0.0992 - val_loss: 0.6916 - val_accuracy: 0.5329 - val_precision: 0.4833 - val_recall: 0.1374\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.6852 - accuracy: 0.5546 - precision: 0.5455 - recall: 0.1581 - val_loss: 0.6920 - val_accuracy: 0.5504 - val_precision: 0.5789 - val_recall: 0.1043\n",
      "Epoch 14/50\n",
      " 7/12 [================>.............] - ETA: 0s - loss: 0.6859 - accuracy: 0.5703 - precision: 0.6528 - recall: 0.1155Restoring model weights from the end of the best epoch: 4.\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.6853 - accuracy: 0.5674 - precision: 0.5978 - recall: 0.1659 - val_loss: 0.7050 - val_accuracy: 0.5439 - val_precision: 0.5273 - val_recall: 0.1374\n",
      "Epoch 14: early stopping\n",
      "Now fitting model: LSTM_model_arch_13\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Dense_start_1 (Dense)       (None, 21, 96)            9312      \n",
      "                                                                 \n",
      " Dense_start_2 (Dense)       (None, 21, 80)            7760      \n",
      "                                                                 \n",
      " Dense_start_3 (Dense)       (None, 21, 40)            3240      \n",
      "                                                                 \n",
      " LSTM1 (LSTM)                (None, 10)                2040      \n",
      "                                                                 \n",
      " Dropout1 (Dropout)          (None, 10)                0         \n",
      "                                                                 \n",
      " Dense_end_1 (Dense)         (None, 5)                 55        \n",
      "                                                                 \n",
      " Output (Dense)              (None, 1)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 22413 (87.55 KB)\n",
      "Trainable params: 22413 (87.55 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 1s 24ms/step - loss: 0.7742 - accuracy: 0.5000 - precision: 0.4580 - recall: 0.5070 - val_loss: 0.7030 - val_accuracy: 0.5154 - val_precision: 0.4790 - val_recall: 0.5403\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.7187 - accuracy: 0.5064 - precision: 0.4666 - recall: 0.5519 - val_loss: 0.6962 - val_accuracy: 0.5373 - val_precision: 0.5000 - val_recall: 0.4028\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.7056 - accuracy: 0.5291 - precision: 0.4794 - recall: 0.3426 - val_loss: 0.6964 - val_accuracy: 0.5570 - val_precision: 0.5672 - val_recall: 0.1801\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6911 - accuracy: 0.5574 - precision: 0.5347 - recall: 0.2512 - val_loss: 0.6993 - val_accuracy: 0.5482 - val_precision: 0.5397 - val_recall: 0.1611\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6918 - accuracy: 0.5567 - precision: 0.5265 - recall: 0.3085 - val_loss: 0.6979 - val_accuracy: 0.5307 - val_precision: 0.4882 - val_recall: 0.2938\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6853 - accuracy: 0.5511 - precision: 0.5146 - recall: 0.3271 - val_loss: 0.7088 - val_accuracy: 0.5285 - val_precision: 0.4875 - val_recall: 0.3697\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6836 - accuracy: 0.5787 - precision: 0.5606 - recall: 0.3659 - val_loss: 0.7045 - val_accuracy: 0.5417 - val_precision: 0.5068 - val_recall: 0.3555\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6737 - accuracy: 0.5787 - precision: 0.5507 - recall: 0.4295 - val_loss: 0.7074 - val_accuracy: 0.5461 - val_precision: 0.5130 - val_recall: 0.3744\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6724 - accuracy: 0.5787 - precision: 0.5488 - recall: 0.4450 - val_loss: 0.7151 - val_accuracy: 0.5263 - val_precision: 0.4869 - val_recall: 0.4408\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6687 - accuracy: 0.5816 - precision: 0.5483 - recall: 0.4837 - val_loss: 0.6984 - val_accuracy: 0.5592 - val_precision: 0.5312 - val_recall: 0.4028\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6760 - accuracy: 0.5837 - precision: 0.5697 - recall: 0.3674 - val_loss: 0.7063 - val_accuracy: 0.5329 - val_precision: 0.4931 - val_recall: 0.3365\n",
      "Epoch 12/50\n",
      " 8/12 [===================>..........] - ETA: 0s - loss: 0.6709 - accuracy: 0.5918 - precision: 0.5836 - recall: 0.3928Restoring model weights from the end of the best epoch: 2.\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.6713 - accuracy: 0.5908 - precision: 0.5769 - recall: 0.3953 - val_loss: 0.7134 - val_accuracy: 0.5329 - val_precision: 0.4929 - val_recall: 0.3270\n",
      "Epoch 12: early stopping\n",
      "Now fitting model: LSTM_model_arch_14\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Dense_start_1 (Dense)       (None, 21, 199)           39800     \n",
      "                                                                 \n",
      " Dense_start_2 (Dense)       (None, 21, 40)            8000      \n",
      "                                                                 \n",
      " LSTM1 (LSTM)                (None, 10)                2040      \n",
      "                                                                 \n",
      " Dropout1 (Dropout)          (None, 10)                0         \n",
      "                                                                 \n",
      " Dense_end_1 (Dense)         (None, 7)                 77        \n",
      "                                                                 \n",
      " Dense_end_2 (Dense)         (None, 5)                 40        \n",
      "                                                                 \n",
      " Output (Dense)              (None, 1)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 49963 (195.17 KB)\n",
      "Trainable params: 49963 (195.17 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 1s 24ms/step - loss: 0.8215 - accuracy: 0.4929 - precision: 0.4386 - recall: 0.3876 - val_loss: 0.6941 - val_accuracy: 0.4978 - val_precision: 0.4536 - val_recall: 0.4171\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6959 - accuracy: 0.5064 - precision: 0.4522 - recall: 0.3736 - val_loss: 0.6961 - val_accuracy: 0.5307 - val_precision: 0.3636 - val_recall: 0.0190\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.7043 - accuracy: 0.5390 - precision: 0.4895 - recall: 0.1798 - val_loss: 0.7020 - val_accuracy: 0.4978 - val_precision: 0.4308 - val_recall: 0.2654\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6981 - accuracy: 0.5348 - precision: 0.4852 - recall: 0.2791 - val_loss: 0.6944 - val_accuracy: 0.5373 - val_precision: 0.5000 - val_recall: 0.0047\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6941 - accuracy: 0.5454 - precision: 0.5286 - recall: 0.0574 - val_loss: 0.6916 - val_accuracy: 0.5373 - val_precision: 0.5000 - val_recall: 0.0047\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6930 - accuracy: 0.5504 - precision: 0.6667 - recall: 0.0341 - val_loss: 0.6943 - val_accuracy: 0.5329 - val_precision: 0.4167 - val_recall: 0.0237\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.6896 - accuracy: 0.5496 - precision: 0.5134 - recall: 0.2977 - val_loss: 0.6987 - val_accuracy: 0.4759 - val_precision: 0.4041 - val_recall: 0.2796\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6882 - accuracy: 0.5433 - precision: 0.5008 - recall: 0.4682 - val_loss: 0.6985 - val_accuracy: 0.5197 - val_precision: 0.4565 - val_recall: 0.1991\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6874 - accuracy: 0.5404 - precision: 0.4975 - recall: 0.4713 - val_loss: 0.6972 - val_accuracy: 0.5307 - val_precision: 0.4769 - val_recall: 0.1469\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6877 - accuracy: 0.5518 - precision: 0.5108 - recall: 0.4760 - val_loss: 0.6966 - val_accuracy: 0.4978 - val_precision: 0.4408 - val_recall: 0.3175\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6904 - accuracy: 0.5688 - precision: 0.5366 - recall: 0.4202 - val_loss: 0.6883 - val_accuracy: 0.5439 - val_precision: 0.5055 - val_recall: 0.6540\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6919 - accuracy: 0.5305 - precision: 0.4902 - recall: 0.6574 - val_loss: 0.6907 - val_accuracy: 0.5110 - val_precision: 0.4143 - val_recall: 0.1374\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.6882 - accuracy: 0.5674 - precision: 0.5365 - recall: 0.3984 - val_loss: 0.6854 - val_accuracy: 0.5702 - val_precision: 0.6471 - val_recall: 0.1564\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.6674 - accuracy: 0.6064 - precision: 0.5996 - recall: 0.4202 - val_loss: 0.7245 - val_accuracy: 0.5768 - val_precision: 0.5360 - val_recall: 0.6351\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.6697 - accuracy: 0.5858 - precision: 0.5486 - recall: 0.5333 - val_loss: 0.6922 - val_accuracy: 0.5658 - val_precision: 0.5302 - val_recall: 0.5403\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6515 - accuracy: 0.6213 - precision: 0.5989 - recall: 0.5209 - val_loss: 0.7323 - val_accuracy: 0.5899 - val_precision: 0.5682 - val_recall: 0.4739\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 0.6850 - accuracy: 0.5667 - precision: 0.5257 - recall: 0.5395 - val_loss: 0.7319 - val_accuracy: 0.4934 - val_precision: 0.4689 - val_recall: 0.7156\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6635 - accuracy: 0.5723 - precision: 0.5284 - recall: 0.6062 - val_loss: 0.7315 - val_accuracy: 0.5768 - val_precision: 0.5469 - val_recall: 0.4976\n",
      "Epoch 19/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.6657 - accuracy: 0.5745 - precision: 0.5351 - recall: 0.5318 - val_loss: 0.7372 - val_accuracy: 0.5044 - val_precision: 0.4752 - val_recall: 0.6825\n",
      "Epoch 20/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.6677 - accuracy: 0.5816 - precision: 0.5377 - recall: 0.6078 - val_loss: 0.7444 - val_accuracy: 0.6031 - val_precision: 0.6071 - val_recall: 0.4028\n",
      "Epoch 21/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.6671 - accuracy: 0.5986 - precision: 0.5559 - recall: 0.6093 - val_loss: 0.7015 - val_accuracy: 0.5000 - val_precision: 0.4755 - val_recall: 0.7820\n",
      "Epoch 22/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.6751 - accuracy: 0.5716 - precision: 0.5293 - recall: 0.5736 - val_loss: 0.7129 - val_accuracy: 0.5241 - val_precision: 0.4893 - val_recall: 0.6493\n",
      "Epoch 23/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6454 - accuracy: 0.6106 - precision: 0.5630 - recall: 0.6651 - val_loss: 0.7508 - val_accuracy: 0.5921 - val_precision: 0.5598 - val_recall: 0.5545\n",
      "Epoch 24/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6391 - accuracy: 0.6113 - precision: 0.5634 - recall: 0.6682 - val_loss: 0.7305 - val_accuracy: 0.5965 - val_precision: 0.5622 - val_recall: 0.5782\n",
      "Epoch 25/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.6331 - accuracy: 0.6213 - precision: 0.5979 - recall: 0.5256 - val_loss: 0.7592 - val_accuracy: 0.5526 - val_precision: 0.5131 - val_recall: 0.6493\n",
      "Epoch 26/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.6297 - accuracy: 0.6411 - precision: 0.5913 - recall: 0.6977 - val_loss: 0.7811 - val_accuracy: 0.5417 - val_precision: 0.5039 - val_recall: 0.6066\n",
      "Epoch 27/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6125 - accuracy: 0.6433 - precision: 0.6011 - recall: 0.6543 - val_loss: 0.8370 - val_accuracy: 0.5789 - val_precision: 0.5450 - val_recall: 0.5450\n",
      "Epoch 28/50\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.6217 - accuracy: 0.6227 - precision: 0.5857 - recall: 0.5984 - val_loss: 0.7938 - val_accuracy: 0.5592 - val_precision: 0.5229 - val_recall: 0.5403\n",
      "Epoch 29/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.6308 - accuracy: 0.6262 - precision: 0.5946 - recall: 0.5752 - val_loss: 0.7928 - val_accuracy: 0.5044 - val_precision: 0.4775 - val_recall: 0.7536\n",
      "Epoch 30/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.6614 - accuracy: 0.5858 - precision: 0.5350 - recall: 0.7225 - val_loss: 0.7590 - val_accuracy: 0.5833 - val_precision: 0.6265 - val_recall: 0.2464\n",
      "Epoch 31/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6558 - accuracy: 0.5901 - precision: 0.5674 - recall: 0.4372 - val_loss: 0.7199 - val_accuracy: 0.4890 - val_precision: 0.4665 - val_recall: 0.7251\n",
      "Epoch 32/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6309 - accuracy: 0.6284 - precision: 0.5913 - recall: 0.6078 - val_loss: 0.7624 - val_accuracy: 0.5219 - val_precision: 0.4887 - val_recall: 0.7156\n",
      "Epoch 33/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.6356 - accuracy: 0.6092 - precision: 0.5481 - recall: 0.8310 - val_loss: 0.7924 - val_accuracy: 0.5417 - val_precision: 0.5037 - val_recall: 0.6398\n",
      "Epoch 34/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6256 - accuracy: 0.6149 - precision: 0.5596 - recall: 0.7426 - val_loss: 0.7717 - val_accuracy: 0.5285 - val_precision: 0.4938 - val_recall: 0.7488\n",
      "Epoch 35/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.6233 - accuracy: 0.6333 - precision: 0.6019 - recall: 0.5860 - val_loss: 0.7572 - val_accuracy: 0.5285 - val_precision: 0.4937 - val_recall: 0.7441\n",
      "Epoch 36/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.6054 - accuracy: 0.6475 - precision: 0.6048 - recall: 0.6620 - val_loss: 0.8369 - val_accuracy: 0.5592 - val_precision: 0.5179 - val_recall: 0.6872\n",
      "Epoch 37/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.5941 - accuracy: 0.6518 - precision: 0.6132 - recall: 0.6465 - val_loss: 0.8016 - val_accuracy: 0.5417 - val_precision: 0.5034 - val_recall: 0.7109\n",
      "Epoch 38/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.6008 - accuracy: 0.6468 - precision: 0.5971 - recall: 0.7008 - val_loss: 0.8045 - val_accuracy: 0.5373 - val_precision: 0.5000 - val_recall: 0.6540\n",
      "Epoch 39/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.5997 - accuracy: 0.6433 - precision: 0.6038 - recall: 0.6403 - val_loss: 0.7974 - val_accuracy: 0.5132 - val_precision: 0.4835 - val_recall: 0.7630\n",
      "Epoch 40/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6156 - accuracy: 0.6546 - precision: 0.6262 - recall: 0.6078 - val_loss: 0.8262 - val_accuracy: 0.5570 - val_precision: 0.5161 - val_recall: 0.6825\n",
      "Epoch 41/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.6037 - accuracy: 0.6418 - precision: 0.5938 - recall: 0.6868 - val_loss: 0.7651 - val_accuracy: 0.5636 - val_precision: 0.5353 - val_recall: 0.4313\n",
      "Epoch 42/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6252 - accuracy: 0.6199 - precision: 0.6276 - recall: 0.4155 - val_loss: 0.8187 - val_accuracy: 0.5636 - val_precision: 0.5221 - val_recall: 0.6730\n",
      "Epoch 43/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.5963 - accuracy: 0.6376 - precision: 0.5863 - recall: 0.7054 - val_loss: 0.8636 - val_accuracy: 0.5329 - val_precision: 0.4967 - val_recall: 0.7204\n",
      "Epoch 44/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.6041 - accuracy: 0.6156 - precision: 0.5542 - recall: 0.8171 - val_loss: 0.7918 - val_accuracy: 0.5154 - val_precision: 0.4852 - val_recall: 0.7773\n",
      "Epoch 45/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.5875 - accuracy: 0.6532 - precision: 0.6127 - recall: 0.6574 - val_loss: 0.8731 - val_accuracy: 0.5614 - val_precision: 0.5209 - val_recall: 0.6493\n",
      "Epoch 46/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.5942 - accuracy: 0.6404 - precision: 0.5940 - recall: 0.6760 - val_loss: 0.7981 - val_accuracy: 0.5329 - val_precision: 0.4970 - val_recall: 0.7915\n",
      "Epoch 47/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.6123 - accuracy: 0.6050 - precision: 0.5509 - recall: 0.7380 - val_loss: 0.7880 - val_accuracy: 0.5241 - val_precision: 0.4908 - val_recall: 0.7583\n",
      "Epoch 48/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.5949 - accuracy: 0.6390 - precision: 0.5821 - recall: 0.7473 - val_loss: 0.7699 - val_accuracy: 0.4978 - val_precision: 0.4777 - val_recall: 0.9147\n",
      "Epoch 49/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.6430 - accuracy: 0.6000 - precision: 0.5428 - recall: 0.7969 - val_loss: 0.7849 - val_accuracy: 0.5987 - val_precision: 0.6014 - val_recall: 0.3934\n",
      "Epoch 50/50\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.6154 - accuracy: 0.6539 - precision: 0.6892 - recall: 0.4434 - val_loss: 0.7738 - val_accuracy: 0.5439 - val_precision: 0.5054 - val_recall: 0.6635\n",
      "Now fitting model: LSTM_model_arch_14\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Dense_start_1 (Dense)       (None, 21, 96)            9312      \n",
      "                                                                 \n",
      " Dense_start_2 (Dense)       (None, 21, 40)            3880      \n",
      "                                                                 \n",
      " LSTM1 (LSTM)                (None, 10)                2040      \n",
      "                                                                 \n",
      " Dropout1 (Dropout)          (None, 10)                0         \n",
      "                                                                 \n",
      " Dense_end_1 (Dense)         (None, 7)                 77        \n",
      "                                                                 \n",
      " Dense_end_2 (Dense)         (None, 5)                 40        \n",
      "                                                                 \n",
      " Output (Dense)              (None, 1)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15355 (59.98 KB)\n",
      "Trainable params: 15355 (59.98 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 1s 23ms/step - loss: 0.7361 - accuracy: 0.4894 - precision: 0.4597 - recall: 0.6636 - val_loss: 0.7306 - val_accuracy: 0.4912 - val_precision: 0.4711 - val_recall: 0.8104\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.7099 - accuracy: 0.5071 - precision: 0.4700 - recall: 0.6062 - val_loss: 0.6961 - val_accuracy: 0.4825 - val_precision: 0.4498 - val_recall: 0.5308\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6909 - accuracy: 0.5447 - precision: 0.5030 - recall: 0.3938 - val_loss: 0.6923 - val_accuracy: 0.5132 - val_precision: 0.4678 - val_recall: 0.3791\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.7019 - accuracy: 0.5447 - precision: 0.5033 - recall: 0.3597 - val_loss: 0.6993 - val_accuracy: 0.5219 - val_precision: 0.4706 - val_recall: 0.2654\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 0.6906 - accuracy: 0.5631 - precision: 0.5360 - recall: 0.3349 - val_loss: 0.6992 - val_accuracy: 0.5175 - val_precision: 0.4713 - val_recall: 0.3507\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6852 - accuracy: 0.5660 - precision: 0.5305 - recall: 0.4450 - val_loss: 0.7100 - val_accuracy: 0.5132 - val_precision: 0.4751 - val_recall: 0.4976\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6821 - accuracy: 0.5574 - precision: 0.5174 - recall: 0.4837 - val_loss: 0.7101 - val_accuracy: 0.5088 - val_precision: 0.4692 - val_recall: 0.4692\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6760 - accuracy: 0.5858 - precision: 0.5532 - recall: 0.4915 - val_loss: 0.7181 - val_accuracy: 0.5132 - val_precision: 0.4788 - val_recall: 0.5877\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6795 - accuracy: 0.5674 - precision: 0.5286 - recall: 0.5008 - val_loss: 0.7217 - val_accuracy: 0.5066 - val_precision: 0.4731 - val_recall: 0.5829\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6655 - accuracy: 0.5943 - precision: 0.5539 - recall: 0.5814 - val_loss: 0.7311 - val_accuracy: 0.4868 - val_precision: 0.4542 - val_recall: 0.5403\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6682 - accuracy: 0.5865 - precision: 0.5503 - recall: 0.5256 - val_loss: 0.7301 - val_accuracy: 0.5241 - val_precision: 0.4896 - val_recall: 0.6682\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6650 - accuracy: 0.5957 - precision: 0.5632 - recall: 0.5178 - val_loss: 0.7219 - val_accuracy: 0.5197 - val_precision: 0.4853 - val_recall: 0.6256\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6446 - accuracy: 0.6142 - precision: 0.5746 - recall: 0.6031 - val_loss: 0.7432 - val_accuracy: 0.5088 - val_precision: 0.4778 - val_recall: 0.6635\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6464 - accuracy: 0.6113 - precision: 0.5747 - recall: 0.5783 - val_loss: 0.7791 - val_accuracy: 0.4912 - val_precision: 0.4671 - val_recall: 0.7062\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6391 - accuracy: 0.6078 - precision: 0.5697 - recall: 0.5829 - val_loss: 0.7880 - val_accuracy: 0.4671 - val_precision: 0.4339 - val_recall: 0.4976\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6424 - accuracy: 0.6142 - precision: 0.5996 - recall: 0.4713 - val_loss: 0.8040 - val_accuracy: 0.4956 - val_precision: 0.4684 - val_recall: 0.6682\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6411 - accuracy: 0.6099 - precision: 0.5574 - recall: 0.7147 - val_loss: 0.7376 - val_accuracy: 0.5044 - val_precision: 0.4737 - val_recall: 0.6398\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6314 - accuracy: 0.6418 - precision: 0.6070 - recall: 0.6155 - val_loss: 0.7623 - val_accuracy: 0.4715 - val_precision: 0.4540 - val_recall: 0.7014\n",
      "Epoch 19/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6216 - accuracy: 0.6333 - precision: 0.5858 - recall: 0.6775 - val_loss: 0.8436 - val_accuracy: 0.4868 - val_precision: 0.4582 - val_recall: 0.5972\n",
      "Epoch 20/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6311 - accuracy: 0.6504 - precision: 0.6083 - recall: 0.6620 - val_loss: 0.9115 - val_accuracy: 0.5000 - val_precision: 0.4647 - val_recall: 0.5308\n",
      "Epoch 21/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6461 - accuracy: 0.6149 - precision: 0.5630 - recall: 0.7070 - val_loss: 0.7802 - val_accuracy: 0.4649 - val_precision: 0.4396 - val_recall: 0.5687\n",
      "Epoch 22/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6337 - accuracy: 0.6404 - precision: 0.6102 - recall: 0.5922 - val_loss: 0.8239 - val_accuracy: 0.4912 - val_precision: 0.4604 - val_recall: 0.5782\n",
      "Epoch 23/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6305 - accuracy: 0.6298 - precision: 0.5887 - recall: 0.6326 - val_loss: 0.8091 - val_accuracy: 0.5154 - val_precision: 0.4781 - val_recall: 0.5166\n",
      "Epoch 24/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6207 - accuracy: 0.6489 - precision: 0.6143 - recall: 0.6248 - val_loss: 0.8347 - val_accuracy: 0.4825 - val_precision: 0.4494 - val_recall: 0.5261\n",
      "Epoch 25/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6113 - accuracy: 0.6461 - precision: 0.6049 - recall: 0.6527 - val_loss: 0.8950 - val_accuracy: 0.4868 - val_precision: 0.4623 - val_recall: 0.6682\n",
      "Epoch 26/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6186 - accuracy: 0.6376 - precision: 0.5898 - recall: 0.6822 - val_loss: 0.8137 - val_accuracy: 0.5022 - val_precision: 0.4739 - val_recall: 0.6872\n",
      "Epoch 27/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6111 - accuracy: 0.6539 - precision: 0.6195 - recall: 0.6310 - val_loss: 0.8422 - val_accuracy: 0.5066 - val_precision: 0.4777 - val_recall: 0.7109\n",
      "Epoch 28/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6063 - accuracy: 0.6716 - precision: 0.6260 - recall: 0.7008 - val_loss: 0.8648 - val_accuracy: 0.5175 - val_precision: 0.4831 - val_recall: 0.6114\n",
      "Epoch 29/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.5963 - accuracy: 0.6816 - precision: 0.6476 - recall: 0.6667 - val_loss: 0.8837 - val_accuracy: 0.4825 - val_precision: 0.4535 - val_recall: 0.5782\n",
      "Epoch 30/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.5946 - accuracy: 0.6730 - precision: 0.6292 - recall: 0.6946 - val_loss: 0.8969 - val_accuracy: 0.5000 - val_precision: 0.4677 - val_recall: 0.5829\n",
      "Epoch 31/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.5692 - accuracy: 0.6844 - precision: 0.6587 - recall: 0.6434 - val_loss: 0.9401 - val_accuracy: 0.5088 - val_precision: 0.4749 - val_recall: 0.5829\n",
      "Epoch 32/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.5847 - accuracy: 0.6851 - precision: 0.6459 - recall: 0.6899 - val_loss: 0.9263 - val_accuracy: 0.4912 - val_precision: 0.4634 - val_recall: 0.6303\n",
      "Epoch 33/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.5838 - accuracy: 0.6766 - precision: 0.6425 - recall: 0.6605 - val_loss: 0.8809 - val_accuracy: 0.4781 - val_precision: 0.4545 - val_recall: 0.6398\n",
      "Epoch 34/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.5838 - accuracy: 0.6730 - precision: 0.6264 - recall: 0.7070 - val_loss: 1.0133 - val_accuracy: 0.5175 - val_precision: 0.4821 - val_recall: 0.5735\n",
      "Epoch 35/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.5985 - accuracy: 0.6816 - precision: 0.6503 - recall: 0.6574 - val_loss: 0.9607 - val_accuracy: 0.4803 - val_precision: 0.4572 - val_recall: 0.6588\n",
      "Epoch 36/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.5916 - accuracy: 0.6610 - precision: 0.6086 - recall: 0.7256 - val_loss: 0.9089 - val_accuracy: 0.4803 - val_precision: 0.4488 - val_recall: 0.5403\n",
      "Epoch 37/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.5960 - accuracy: 0.6660 - precision: 0.6394 - recall: 0.6186 - val_loss: 0.8776 - val_accuracy: 0.4934 - val_precision: 0.4630 - val_recall: 0.5924\n",
      "Epoch 38/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.5659 - accuracy: 0.6979 - precision: 0.6627 - recall: 0.6915 - val_loss: 0.9297 - val_accuracy: 0.5175 - val_precision: 0.4826 - val_recall: 0.5924\n",
      "Epoch 39/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.5573 - accuracy: 0.7028 - precision: 0.6794 - recall: 0.6636 - val_loss: 0.9499 - val_accuracy: 0.5044 - val_precision: 0.4749 - val_recall: 0.6730\n",
      "Epoch 40/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.5939 - accuracy: 0.6738 - precision: 0.6235 - recall: 0.7240 - val_loss: 0.9403 - val_accuracy: 0.5197 - val_precision: 0.4835 - val_recall: 0.5545\n",
      "Epoch 41/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.5948 - accuracy: 0.6660 - precision: 0.6359 - recall: 0.6310 - val_loss: 1.0601 - val_accuracy: 0.4737 - val_precision: 0.4480 - val_recall: 0.5924\n",
      "Epoch 42/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.5739 - accuracy: 0.6567 - precision: 0.6010 - recall: 0.7426 - val_loss: 1.1090 - val_accuracy: 0.4825 - val_precision: 0.4611 - val_recall: 0.7014\n",
      "Epoch 43/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.5518 - accuracy: 0.6957 - precision: 0.6492 - recall: 0.7287 - val_loss: 1.1605 - val_accuracy: 0.5241 - val_precision: 0.4895 - val_recall: 0.6635\n",
      "Epoch 44/50\n",
      "12/12 [==============================] - 0s 26ms/step - loss: 0.5457 - accuracy: 0.7014 - precision: 0.6657 - recall: 0.6977 - val_loss: 1.2881 - val_accuracy: 0.5197 - val_precision: 0.4847 - val_recall: 0.6019\n",
      "Epoch 45/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.5395 - accuracy: 0.7113 - precision: 0.6705 - recall: 0.7256 - val_loss: 1.0756 - val_accuracy: 0.5263 - val_precision: 0.4910 - val_recall: 0.6445\n",
      "Epoch 46/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.5562 - accuracy: 0.6915 - precision: 0.6419 - recall: 0.7364 - val_loss: 1.0689 - val_accuracy: 0.5417 - val_precision: 0.5041 - val_recall: 0.5877\n",
      "Epoch 47/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.5631 - accuracy: 0.6993 - precision: 0.6785 - recall: 0.6512 - val_loss: 0.9579 - val_accuracy: 0.4868 - val_precision: 0.4582 - val_recall: 0.5972\n",
      "Epoch 48/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.5728 - accuracy: 0.6915 - precision: 0.6332 - recall: 0.7736 - val_loss: 1.0536 - val_accuracy: 0.4912 - val_precision: 0.4615 - val_recall: 0.5972\n",
      "Epoch 49/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.5524 - accuracy: 0.7078 - precision: 0.6876 - recall: 0.6620 - val_loss: 1.1209 - val_accuracy: 0.4693 - val_precision: 0.4440 - val_recall: 0.5829\n",
      "Epoch 50/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.5624 - accuracy: 0.7050 - precision: 0.6652 - recall: 0.7147 - val_loss: 1.0845 - val_accuracy: 0.4956 - val_precision: 0.4636 - val_recall: 0.5735\n",
      "Now fitting model: LSTM_model_arch_15\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Dense_start_1 (Dense)       (None, 21, 199)           39800     \n",
      "                                                                 \n",
      " Dense_start_2 (Dense)       (None, 21, 80)            16000     \n",
      "                                                                 \n",
      " Dense_start_3 (Dense)       (None, 21, 40)            3240      \n",
      "                                                                 \n",
      " LSTM1 (LSTM)                (None, 20)                4880      \n",
      "                                                                 \n",
      " Dropout1 (Dropout)          (None, 20)                0         \n",
      "                                                                 \n",
      " Dense_end_1 (Dense)         (None, 7)                 147       \n",
      "                                                                 \n",
      " Dense_end_2 (Dense)         (None, 5)                 40        \n",
      "                                                                 \n",
      " Output (Dense)              (None, 1)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 64113 (250.44 KB)\n",
      "Trainable params: 64113 (250.44 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 1s 28ms/step - loss: 0.7802 - accuracy: 0.5113 - precision: 0.4690 - recall: 0.5163 - val_loss: 0.6941 - val_accuracy: 0.5329 - val_precision: 0.4900 - val_recall: 0.2322\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.7070 - accuracy: 0.5355 - precision: 0.4800 - recall: 0.1860 - val_loss: 0.6964 - val_accuracy: 0.5088 - val_precision: 0.4558 - val_recall: 0.3175\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.6966 - accuracy: 0.5291 - precision: 0.4831 - recall: 0.4202 - val_loss: 0.7042 - val_accuracy: 0.5175 - val_precision: 0.4767 - val_recall: 0.4360\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.6958 - accuracy: 0.5369 - precision: 0.4921 - recall: 0.3876 - val_loss: 0.6904 - val_accuracy: 0.5373 - val_precision: 0.5000 - val_recall: 0.2796\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.6963 - accuracy: 0.5348 - precision: 0.4887 - recall: 0.3690 - val_loss: 0.6916 - val_accuracy: 0.5395 - val_precision: 0.5556 - val_recall: 0.0237\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.7081 - accuracy: 0.5433 - precision: 0.5067 - recall: 0.0589 - val_loss: 0.6953 - val_accuracy: 0.5395 - val_precision: 1.0000 - val_recall: 0.0047\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.6926 - accuracy: 0.5489 - precision: 0.5193 - recall: 0.1876 - val_loss: 0.7203 - val_accuracy: 0.5395 - val_precision: 0.5294 - val_recall: 0.0427\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.6969 - accuracy: 0.5376 - precision: 0.4941 - recall: 0.4543 - val_loss: 0.6886 - val_accuracy: 0.5482 - val_precision: 0.6667 - val_recall: 0.0474\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.7052 - accuracy: 0.5532 - precision: 0.5158 - recall: 0.3798 - val_loss: 0.6907 - val_accuracy: 0.5526 - val_precision: 0.5185 - val_recall: 0.4645\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.6956 - accuracy: 0.4993 - precision: 0.4708 - recall: 0.7612 - val_loss: 0.6963 - val_accuracy: 0.4715 - val_precision: 0.4650 - val_recall: 0.9431\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 0.6943 - accuracy: 0.5234 - precision: 0.4752 - recall: 0.4016 - val_loss: 0.6917 - val_accuracy: 0.5307 - val_precision: 0.4348 - val_recall: 0.0474\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.6975 - accuracy: 0.5411 - precision: 0.4922 - recall: 0.0977 - val_loss: 0.6901 - val_accuracy: 0.5373 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.6980 - accuracy: 0.5390 - precision: 0.4757 - recall: 0.0760 - val_loss: 0.6896 - val_accuracy: 0.5373 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.6947 - accuracy: 0.5468 - precision: 0.5170 - recall: 0.1411 - val_loss: 0.6901 - val_accuracy: 0.5504 - val_precision: 0.6364 - val_recall: 0.0664\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.6952 - accuracy: 0.5397 - precision: 0.4919 - recall: 0.1891 - val_loss: 0.6898 - val_accuracy: 0.5395 - val_precision: 0.5152 - val_recall: 0.0806\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.6923 - accuracy: 0.5532 - precision: 0.5227 - recall: 0.2682 - val_loss: 0.6905 - val_accuracy: 0.5373 - val_precision: 0.5000 - val_recall: 0.0047\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.6934 - accuracy: 0.5255 - precision: 0.4698 - recall: 0.2899 - val_loss: 0.6920 - val_accuracy: 0.5373 - val_precision: 0.5000 - val_recall: 0.0047\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.6970 - accuracy: 0.5397 - precision: 0.4937 - recall: 0.2419 - val_loss: 0.6911 - val_accuracy: 0.5395 - val_precision: 1.0000 - val_recall: 0.0047\n",
      "Epoch 19/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.6950 - accuracy: 0.5390 - precision: 0.4924 - recall: 0.2512 - val_loss: 0.7402 - val_accuracy: 0.5329 - val_precision: 0.3750 - val_recall: 0.0142\n",
      "Epoch 20/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.7023 - accuracy: 0.5418 - precision: 0.4989 - recall: 0.3581 - val_loss: 0.6883 - val_accuracy: 0.5592 - val_precision: 0.5735 - val_recall: 0.1848\n",
      "Epoch 21/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.6889 - accuracy: 0.5645 - precision: 0.5330 - recall: 0.3876 - val_loss: 0.6867 - val_accuracy: 0.5592 - val_precision: 0.7083 - val_recall: 0.0806\n",
      "Epoch 22/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.6900 - accuracy: 0.5688 - precision: 0.5521 - recall: 0.3039 - val_loss: 0.6922 - val_accuracy: 0.5263 - val_precision: 0.4873 - val_recall: 0.4550\n",
      "Epoch 23/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.6893 - accuracy: 0.5567 - precision: 0.5124 - recall: 0.6403 - val_loss: 0.6896 - val_accuracy: 0.5504 - val_precision: 0.5484 - val_recall: 0.1611\n",
      "Epoch 24/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.6903 - accuracy: 0.5787 - precision: 0.5876 - recall: 0.2651 - val_loss: 0.6903 - val_accuracy: 0.5636 - val_precision: 0.6250 - val_recall: 0.1422\n",
      "Epoch 25/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.6892 - accuracy: 0.5468 - precision: 0.5054 - recall: 0.4341 - val_loss: 0.6885 - val_accuracy: 0.5482 - val_precision: 0.5210 - val_recall: 0.2938\n",
      "Epoch 26/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.6792 - accuracy: 0.5766 - precision: 0.5449 - recall: 0.4512 - val_loss: 0.6853 - val_accuracy: 0.5614 - val_precision: 0.5545 - val_recall: 0.2654\n",
      "Epoch 27/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.6803 - accuracy: 0.5773 - precision: 0.5410 - recall: 0.5008 - val_loss: 0.6902 - val_accuracy: 0.5570 - val_precision: 0.5542 - val_recall: 0.2180\n",
      "Epoch 28/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.6722 - accuracy: 0.5894 - precision: 0.5602 - recall: 0.4760 - val_loss: 0.6875 - val_accuracy: 0.5592 - val_precision: 0.5260 - val_recall: 0.4787\n",
      "Epoch 29/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.6811 - accuracy: 0.5667 - precision: 0.5258 - recall: 0.5380 - val_loss: 0.6904 - val_accuracy: 0.5636 - val_precision: 0.5600 - val_recall: 0.2654\n",
      "Epoch 30/50\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.6747 - accuracy: 0.6021 - precision: 0.5732 - recall: 0.5101 - val_loss: 0.6924 - val_accuracy: 0.5592 - val_precision: 0.5203 - val_recall: 0.6066\n",
      "Epoch 31/50\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.6702 - accuracy: 0.6099 - precision: 0.5683 - recall: 0.6124 - val_loss: 0.6862 - val_accuracy: 0.5658 - val_precision: 0.5619 - val_recall: 0.2796\n",
      "Epoch 32/50\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 0.6787 - accuracy: 0.5809 - precision: 0.5475 - recall: 0.4822 - val_loss: 0.6805 - val_accuracy: 0.5921 - val_precision: 0.6190 - val_recall: 0.3081\n",
      "Epoch 33/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.6735 - accuracy: 0.6213 - precision: 0.6357 - recall: 0.4031 - val_loss: 0.6978 - val_accuracy: 0.5658 - val_precision: 0.5890 - val_recall: 0.2038\n",
      "Epoch 34/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.6619 - accuracy: 0.6213 - precision: 0.5945 - recall: 0.5411 - val_loss: 0.7137 - val_accuracy: 0.5724 - val_precision: 0.6053 - val_recall: 0.2180\n",
      "Epoch 35/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.6786 - accuracy: 0.5901 - precision: 0.5730 - recall: 0.4078 - val_loss: 0.6883 - val_accuracy: 0.5658 - val_precision: 0.5274 - val_recall: 0.5924\n",
      "Epoch 36/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.6713 - accuracy: 0.5759 - precision: 0.5245 - recall: 0.7814 - val_loss: 0.7300 - val_accuracy: 0.5307 - val_precision: 0.4948 - val_recall: 0.6730\n",
      "Epoch 37/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.6596 - accuracy: 0.6135 - precision: 0.5710 - recall: 0.6233 - val_loss: 0.7286 - val_accuracy: 0.5461 - val_precision: 0.5070 - val_recall: 0.6825\n",
      "Epoch 38/50\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.8403 - accuracy: 0.5879 - precision: 0.5476 - recall: 0.5705 - val_loss: 0.7817 - val_accuracy: 0.5417 - val_precision: 0.5083 - val_recall: 0.2891\n",
      "Epoch 39/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.8599 - accuracy: 0.5184 - precision: 0.4520 - recall: 0.2481 - val_loss: 0.7070 - val_accuracy: 0.5329 - val_precision: 0.4545 - val_recall: 0.0474\n",
      "Epoch 40/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.7285 - accuracy: 0.5312 - precision: 0.4494 - recall: 0.1101 - val_loss: 0.6936 - val_accuracy: 0.5395 - val_precision: 0.5385 - val_recall: 0.0332\n",
      "Epoch 41/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.7137 - accuracy: 0.5277 - precision: 0.4305 - recall: 0.1008 - val_loss: 0.6888 - val_accuracy: 0.5373 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 42/50\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.6964 - accuracy: 0.5355 - precision: 0.4444 - recall: 0.0620 - val_loss: 0.6896 - val_accuracy: 0.5373 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 43/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.6939 - accuracy: 0.5433 - precision: 0.5294 - recall: 0.0140 - val_loss: 0.6894 - val_accuracy: 0.5373 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 44/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.6965 - accuracy: 0.5411 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6895 - val_accuracy: 0.5373 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 45/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.6983 - accuracy: 0.5426 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6897 - val_accuracy: 0.5373 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 46/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.6936 - accuracy: 0.5418 - precision: 0.3333 - recall: 0.0016 - val_loss: 0.6898 - val_accuracy: 0.5373 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 47/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.6937 - accuracy: 0.5489 - precision: 0.5556 - recall: 0.0698 - val_loss: 0.6902 - val_accuracy: 0.5373 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 48/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.6946 - accuracy: 0.5426 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6899 - val_accuracy: 0.5373 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 49/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.6953 - accuracy: 0.5426 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6902 - val_accuracy: 0.5373 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 50/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.6953 - accuracy: 0.5426 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6900 - val_accuracy: 0.5373 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Now fitting model: LSTM_model_arch_15\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Dense_start_1 (Dense)       (None, 21, 96)            9312      \n",
      "                                                                 \n",
      " Dense_start_2 (Dense)       (None, 21, 80)            7760      \n",
      "                                                                 \n",
      " Dense_start_3 (Dense)       (None, 21, 40)            3240      \n",
      "                                                                 \n",
      " LSTM1 (LSTM)                (None, 20)                4880      \n",
      "                                                                 \n",
      " Dropout1 (Dropout)          (None, 20)                0         \n",
      "                                                                 \n",
      " Dense_end_1 (Dense)         (None, 7)                 147       \n",
      "                                                                 \n",
      " Dense_end_2 (Dense)         (None, 5)                 40        \n",
      "                                                                 \n",
      " Output (Dense)              (None, 1)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25385 (99.16 KB)\n",
      "Trainable params: 25385 (99.16 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 1s 26ms/step - loss: 0.9469 - accuracy: 0.5191 - precision: 0.4656 - recall: 0.3457 - val_loss: 0.7641 - val_accuracy: 0.5110 - val_precision: 0.4250 - val_recall: 0.1611\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.7609 - accuracy: 0.5142 - precision: 0.4512 - recall: 0.2868 - val_loss: 0.7075 - val_accuracy: 0.5219 - val_precision: 0.4711 - val_recall: 0.2701\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.6995 - accuracy: 0.5305 - precision: 0.4838 - recall: 0.3938 - val_loss: 0.7101 - val_accuracy: 0.5088 - val_precision: 0.4633 - val_recall: 0.3886\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.6950 - accuracy: 0.5411 - precision: 0.4984 - recall: 0.4806 - val_loss: 0.7119 - val_accuracy: 0.5197 - val_precision: 0.4661 - val_recall: 0.2607\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5532 - precision: 0.5146 - recall: 0.4093 - val_loss: 0.7153 - val_accuracy: 0.5175 - val_precision: 0.4656 - val_recall: 0.2891\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6832 - accuracy: 0.5652 - precision: 0.5321 - recall: 0.4109 - val_loss: 0.7215 - val_accuracy: 0.5088 - val_precision: 0.4586 - val_recall: 0.3412\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6796 - accuracy: 0.5730 - precision: 0.5410 - recall: 0.4403 - val_loss: 0.7154 - val_accuracy: 0.5088 - val_precision: 0.4624 - val_recall: 0.3791\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.6667 - accuracy: 0.5957 - precision: 0.5712 - recall: 0.4667 - val_loss: 0.7196 - val_accuracy: 0.5110 - val_precision: 0.4605 - val_recall: 0.3318\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.6735 - accuracy: 0.5787 - precision: 0.5429 - recall: 0.5008 - val_loss: 0.7199 - val_accuracy: 0.4978 - val_precision: 0.4609 - val_recall: 0.5024\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.6659 - accuracy: 0.5823 - precision: 0.5520 - recall: 0.4605 - val_loss: 0.7252 - val_accuracy: 0.5154 - val_precision: 0.4802 - val_recall: 0.5735\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.6654 - accuracy: 0.5986 - precision: 0.5624 - recall: 0.5519 - val_loss: 0.7142 - val_accuracy: 0.5307 - val_precision: 0.4898 - val_recall: 0.3412\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.6633 - accuracy: 0.5908 - precision: 0.5614 - recall: 0.4822 - val_loss: 0.7443 - val_accuracy: 0.5175 - val_precision: 0.4840 - val_recall: 0.6445\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.6634 - accuracy: 0.6071 - precision: 0.5800 - recall: 0.5116 - val_loss: 0.7348 - val_accuracy: 0.5263 - val_precision: 0.4719 - val_recall: 0.1991\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.6732 - accuracy: 0.6000 - precision: 0.6025 - recall: 0.3690 - val_loss: 0.7405 - val_accuracy: 0.5022 - val_precision: 0.4695 - val_recall: 0.5829\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.6517 - accuracy: 0.6057 - precision: 0.5640 - recall: 0.6078 - val_loss: 0.7558 - val_accuracy: 0.4868 - val_precision: 0.4569 - val_recall: 0.5782\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.6801 - accuracy: 0.5723 - precision: 0.5315 - recall: 0.5488 - val_loss: 0.7344 - val_accuracy: 0.5263 - val_precision: 0.4852 - val_recall: 0.3886\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.6920 - accuracy: 0.5858 - precision: 0.6419 - recall: 0.2140 - val_loss: 0.7489 - val_accuracy: 0.5175 - val_precision: 0.4685 - val_recall: 0.3175\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.6780 - accuracy: 0.5901 - precision: 0.5994 - recall: 0.3132 - val_loss: 0.7295 - val_accuracy: 0.5307 - val_precision: 0.4909 - val_recall: 0.3839\n",
      "Epoch 19/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.6712 - accuracy: 0.5879 - precision: 0.5847 - recall: 0.3426 - val_loss: 0.7646 - val_accuracy: 0.4956 - val_precision: 0.4589 - val_recall: 0.5024\n",
      "Epoch 20/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.6642 - accuracy: 0.5929 - precision: 0.5605 - recall: 0.5101 - val_loss: 0.7662 - val_accuracy: 0.4759 - val_precision: 0.4462 - val_recall: 0.5498\n",
      "Epoch 21/50\n",
      "12/12 [==============================] - 0s 27ms/step - loss: 0.6465 - accuracy: 0.6177 - precision: 0.6095 - recall: 0.4574 - val_loss: 0.7826 - val_accuracy: 0.5088 - val_precision: 0.4711 - val_recall: 0.5024\n",
      "Epoch 22/50\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.6476 - accuracy: 0.6128 - precision: 0.6122 - recall: 0.4186 - val_loss: 0.7566 - val_accuracy: 0.4934 - val_precision: 0.4580 - val_recall: 0.5166\n",
      "Epoch 23/50\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.6388 - accuracy: 0.6433 - precision: 0.6455 - recall: 0.4884 - val_loss: 0.7987 - val_accuracy: 0.4978 - val_precision: 0.4631 - val_recall: 0.5355\n",
      "Epoch 24/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.6397 - accuracy: 0.6404 - precision: 0.6162 - recall: 0.5674 - val_loss: 0.8030 - val_accuracy: 0.4868 - val_precision: 0.4559 - val_recall: 0.5640\n",
      "Epoch 25/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.6186 - accuracy: 0.6525 - precision: 0.6412 - recall: 0.5457 - val_loss: 0.8425 - val_accuracy: 0.5088 - val_precision: 0.4733 - val_recall: 0.5450\n",
      "Epoch 26/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.6204 - accuracy: 0.6468 - precision: 0.6354 - recall: 0.5349 - val_loss: 0.8257 - val_accuracy: 0.4956 - val_precision: 0.4659 - val_recall: 0.6161\n",
      "Epoch 27/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.6393 - accuracy: 0.6113 - precision: 0.5698 - recall: 0.6140 - val_loss: 0.8261 - val_accuracy: 0.4890 - val_precision: 0.4636 - val_recall: 0.6635\n",
      "Epoch 28/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.6157 - accuracy: 0.6411 - precision: 0.6112 - recall: 0.5922 - val_loss: 0.8501 - val_accuracy: 0.5044 - val_precision: 0.4727 - val_recall: 0.6161\n",
      "Epoch 29/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.6022 - accuracy: 0.6709 - precision: 0.6501 - recall: 0.6078 - val_loss: 0.8282 - val_accuracy: 0.4890 - val_precision: 0.4500 - val_recall: 0.4692\n",
      "Epoch 30/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.6189 - accuracy: 0.6475 - precision: 0.6221 - recall: 0.5845 - val_loss: 0.8527 - val_accuracy: 0.4890 - val_precision: 0.4658 - val_recall: 0.7109\n",
      "Epoch 31/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.5983 - accuracy: 0.6596 - precision: 0.6283 - recall: 0.6264 - val_loss: 0.8851 - val_accuracy: 0.5088 - val_precision: 0.4785 - val_recall: 0.6872\n",
      "Epoch 32/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.6393 - accuracy: 0.6426 - precision: 0.6248 - recall: 0.5473 - val_loss: 0.8364 - val_accuracy: 0.5175 - val_precision: 0.4749 - val_recall: 0.4028\n",
      "Epoch 33/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.6382 - accuracy: 0.6199 - precision: 0.5932 - recall: 0.5380 - val_loss: 0.8621 - val_accuracy: 0.5066 - val_precision: 0.4701 - val_recall: 0.5213\n",
      "Epoch 34/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.6415 - accuracy: 0.6291 - precision: 0.6142 - recall: 0.5085 - val_loss: 0.7966 - val_accuracy: 0.5044 - val_precision: 0.4684 - val_recall: 0.5261\n",
      "Epoch 35/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.6170 - accuracy: 0.6298 - precision: 0.6041 - recall: 0.5535 - val_loss: 0.8366 - val_accuracy: 0.5022 - val_precision: 0.4579 - val_recall: 0.4123\n",
      "Epoch 36/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.6408 - accuracy: 0.6326 - precision: 0.6196 - recall: 0.5101 - val_loss: 0.8276 - val_accuracy: 0.5022 - val_precision: 0.4710 - val_recall: 0.6161\n",
      "Epoch 37/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.6403 - accuracy: 0.6128 - precision: 0.5677 - recall: 0.6434 - val_loss: 0.8309 - val_accuracy: 0.5263 - val_precision: 0.4896 - val_recall: 0.5592\n",
      "Epoch 38/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.5996 - accuracy: 0.6610 - precision: 0.6371 - recall: 0.6016 - val_loss: 0.8677 - val_accuracy: 0.5197 - val_precision: 0.4813 - val_recall: 0.4882\n",
      "Epoch 39/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.5756 - accuracy: 0.6801 - precision: 0.6570 - recall: 0.6295 - val_loss: 0.9208 - val_accuracy: 0.4956 - val_precision: 0.4603 - val_recall: 0.5213\n",
      "Epoch 40/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.5965 - accuracy: 0.6702 - precision: 0.6515 - recall: 0.6000 - val_loss: 0.8444 - val_accuracy: 0.5307 - val_precision: 0.4928 - val_recall: 0.4834\n",
      "Epoch 41/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.6337 - accuracy: 0.6468 - precision: 0.6637 - recall: 0.4620 - val_loss: 0.8584 - val_accuracy: 0.5241 - val_precision: 0.4817 - val_recall: 0.3744\n",
      "Epoch 42/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.6133 - accuracy: 0.6454 - precision: 0.6270 - recall: 0.5550 - val_loss: 0.8070 - val_accuracy: 0.5022 - val_precision: 0.4570 - val_recall: 0.4028\n",
      "Epoch 43/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.6296 - accuracy: 0.6369 - precision: 0.6207 - recall: 0.5302 - val_loss: 0.8315 - val_accuracy: 0.5461 - val_precision: 0.5122 - val_recall: 0.3981\n",
      "Epoch 44/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.6272 - accuracy: 0.6426 - precision: 0.6230 - recall: 0.5535 - val_loss: 0.8344 - val_accuracy: 0.5219 - val_precision: 0.4815 - val_recall: 0.4313\n",
      "Epoch 45/50\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 0.6171 - accuracy: 0.6298 - precision: 0.6104 - recall: 0.5271 - val_loss: 0.8246 - val_accuracy: 0.5197 - val_precision: 0.4813 - val_recall: 0.4882\n",
      "Epoch 46/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6044 - accuracy: 0.6596 - precision: 0.6440 - recall: 0.5721 - val_loss: 0.8831 - val_accuracy: 0.5154 - val_precision: 0.4737 - val_recall: 0.4265\n",
      "Epoch 47/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.5994 - accuracy: 0.6766 - precision: 0.6728 - recall: 0.5705 - val_loss: 0.8260 - val_accuracy: 0.5373 - val_precision: 0.5000 - val_recall: 0.4645\n",
      "Epoch 48/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.5968 - accuracy: 0.6638 - precision: 0.6635 - recall: 0.5380 - val_loss: 0.8094 - val_accuracy: 0.5702 - val_precision: 0.5366 - val_recall: 0.5213\n",
      "Epoch 49/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.5695 - accuracy: 0.6780 - precision: 0.6528 - recall: 0.6326 - val_loss: 0.8849 - val_accuracy: 0.5417 - val_precision: 0.5052 - val_recall: 0.4645\n",
      "Epoch 50/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.5705 - accuracy: 0.6957 - precision: 0.7118 - recall: 0.5628 - val_loss: 0.9230 - val_accuracy: 0.5022 - val_precision: 0.4675 - val_recall: 0.5450\n",
      "Now fitting model: LSTM_model_arch_16\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Dense_start_1 (Dense)       (None, 21, 199)           39800     \n",
      "                                                                 \n",
      " Dense_start_2 (Dense)       (None, 21, 40)            8000      \n",
      "                                                                 \n",
      " LSTM1 (LSTM)                (None, 21, 20)            4880      \n",
      "                                                                 \n",
      " Dropout1 (Dropout)          (None, 21, 20)            0         \n",
      "                                                                 \n",
      " LSTM2 (LSTM)                (None, 10)                1240      \n",
      "                                                                 \n",
      " Output (Dense)              (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 53931 (210.67 KB)\n",
      "Trainable params: 53931 (210.67 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 1s 36ms/step - loss: 0.7598 - accuracy: 0.5319 - precision: 0.4873 - recall: 0.4465 - val_loss: 0.6881 - val_accuracy: 0.5263 - val_precision: 0.4576 - val_recall: 0.1280\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.6977 - accuracy: 0.5390 - precision: 0.4939 - recall: 0.3116 - val_loss: 0.6930 - val_accuracy: 0.5132 - val_precision: 0.4267 - val_recall: 0.1517\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.6980 - accuracy: 0.5333 - precision: 0.4865 - recall: 0.3628 - val_loss: 0.6927 - val_accuracy: 0.5351 - val_precision: 0.4944 - val_recall: 0.2085\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.6945 - accuracy: 0.5468 - precision: 0.5188 - recall: 0.1287 - val_loss: 0.6937 - val_accuracy: 0.5395 - val_precision: 0.5152 - val_recall: 0.0806\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.6972 - accuracy: 0.5411 - precision: 0.4958 - recall: 0.1829 - val_loss: 0.6929 - val_accuracy: 0.5154 - val_precision: 0.4038 - val_recall: 0.0995\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.6844 - accuracy: 0.5837 - precision: 0.5771 - recall: 0.3364 - val_loss: 0.7011 - val_accuracy: 0.5088 - val_precision: 0.4532 - val_recall: 0.2986\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.6904 - accuracy: 0.5688 - precision: 0.5410 - recall: 0.3783 - val_loss: 0.6989 - val_accuracy: 0.5219 - val_precision: 0.4615 - val_recall: 0.1991\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 0.6824 - accuracy: 0.5631 - precision: 0.5230 - recall: 0.5116 - val_loss: 0.7013 - val_accuracy: 0.5263 - val_precision: 0.4194 - val_recall: 0.0616\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.6771 - accuracy: 0.5773 - precision: 0.5398 - recall: 0.5147 - val_loss: 0.7016 - val_accuracy: 0.5351 - val_precision: 0.4925 - val_recall: 0.1564\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.6706 - accuracy: 0.5979 - precision: 0.5641 - recall: 0.5318 - val_loss: 0.6965 - val_accuracy: 0.5768 - val_precision: 0.6286 - val_recall: 0.2085\n",
      "Epoch 11/50\n",
      " 9/12 [=====================>........] - ETA: 0s - loss: 0.6710 - accuracy: 0.5894 - precision: 0.5521 - recall: 0.5342Restoring model weights from the end of the best epoch: 1.\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.6793 - accuracy: 0.5787 - precision: 0.5456 - recall: 0.4729 - val_loss: 0.6914 - val_accuracy: 0.5680 - val_precision: 0.5700 - val_recall: 0.2701\n",
      "Epoch 11: early stopping\n",
      "Now fitting model: LSTM_model_arch_16\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Dense_start_1 (Dense)       (None, 21, 96)            9312      \n",
      "                                                                 \n",
      " Dense_start_2 (Dense)       (None, 21, 40)            3880      \n",
      "                                                                 \n",
      " LSTM1 (LSTM)                (None, 21, 20)            4880      \n",
      "                                                                 \n",
      " Dropout1 (Dropout)          (None, 21, 20)            0         \n",
      "                                                                 \n",
      " LSTM2 (LSTM)                (None, 10)                1240      \n",
      "                                                                 \n",
      " Output (Dense)              (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19323 (75.48 KB)\n",
      "Trainable params: 19323 (75.48 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 1s 33ms/step - loss: 0.7554 - accuracy: 0.5021 - precision: 0.4595 - recall: 0.5008 - val_loss: 0.6916 - val_accuracy: 0.5263 - val_precision: 0.4793 - val_recall: 0.2749\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.7206 - accuracy: 0.5376 - precision: 0.4905 - recall: 0.2806 - val_loss: 0.7018 - val_accuracy: 0.5219 - val_precision: 0.4706 - val_recall: 0.2654\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.7251 - accuracy: 0.5149 - precision: 0.4537 - recall: 0.2961 - val_loss: 0.6993 - val_accuracy: 0.5000 - val_precision: 0.4615 - val_recall: 0.4834\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.7007 - accuracy: 0.4879 - precision: 0.4448 - recall: 0.4806 - val_loss: 0.6985 - val_accuracy: 0.4934 - val_precision: 0.4612 - val_recall: 0.5640\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.7013 - accuracy: 0.5255 - precision: 0.4804 - recall: 0.4558 - val_loss: 0.7155 - val_accuracy: 0.5022 - val_precision: 0.4412 - val_recall: 0.2844\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.6974 - accuracy: 0.5574 - precision: 0.5192 - recall: 0.4403 - val_loss: 0.7236 - val_accuracy: 0.4978 - val_precision: 0.4516 - val_recall: 0.3981\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.7023 - accuracy: 0.5319 - precision: 0.4837 - recall: 0.3457 - val_loss: 0.7372 - val_accuracy: 0.5132 - val_precision: 0.4779 - val_recall: 0.5640\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 0.7130 - accuracy: 0.5518 - precision: 0.5129 - recall: 0.4016 - val_loss: 0.7183 - val_accuracy: 0.4803 - val_precision: 0.4500 - val_recall: 0.5545\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.6945 - accuracy: 0.5163 - precision: 0.4638 - recall: 0.3674 - val_loss: 0.7195 - val_accuracy: 0.4825 - val_precision: 0.4454 - val_recall: 0.4834\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.6857 - accuracy: 0.5468 - precision: 0.5058 - recall: 0.4031 - val_loss: 0.7233 - val_accuracy: 0.4759 - val_precision: 0.4307 - val_recall: 0.4123\n",
      "Epoch 11/50\n",
      "11/12 [==========================>...] - ETA: 0s - loss: 0.6784 - accuracy: 0.5788 - precision: 0.5464 - recall: 0.4744Restoring model weights from the end of the best epoch: 1.\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.6775 - accuracy: 0.5794 - precision: 0.5464 - recall: 0.4744 - val_loss: 0.7294 - val_accuracy: 0.4737 - val_precision: 0.4361 - val_recall: 0.4692\n",
      "Epoch 11: early stopping\n",
      "Now fitting model: LSTM_model_arch_17\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Dense_start_1 (Dense)       (None, 21, 199)           39800     \n",
      "                                                                 \n",
      " Dense_start_2 (Dense)       (None, 21, 80)            16000     \n",
      "                                                                 \n",
      " Dense_start_3 (Dense)       (None, 21, 40)            3240      \n",
      "                                                                 \n",
      " LSTM1 (LSTM)                (None, 21, 20)            4880      \n",
      "                                                                 \n",
      " Dropout1 (Dropout)          (None, 21, 20)            0         \n",
      "                                                                 \n",
      " LSTM2 (LSTM)                (None, 10)                1240      \n",
      "                                                                 \n",
      " Output (Dense)              (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65171 (254.57 KB)\n",
      "Trainable params: 65171 (254.57 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 1s 38ms/step - loss: 0.7355 - accuracy: 0.5057 - precision: 0.4641 - recall: 0.5209 - val_loss: 0.6996 - val_accuracy: 0.5110 - val_precision: 0.4722 - val_recall: 0.4834\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.7039 - accuracy: 0.5362 - precision: 0.4850 - recall: 0.2264 - val_loss: 0.6948 - val_accuracy: 0.5263 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.7161 - accuracy: 0.5333 - precision: 0.4800 - recall: 0.2419 - val_loss: 0.6929 - val_accuracy: 0.5329 - val_precision: 0.4737 - val_recall: 0.0853\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.6942 - accuracy: 0.5291 - precision: 0.4706 - recall: 0.2357 - val_loss: 0.6989 - val_accuracy: 0.5241 - val_precision: 0.4286 - val_recall: 0.0853\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.7025 - accuracy: 0.5397 - precision: 0.4953 - recall: 0.3240 - val_loss: 0.6930 - val_accuracy: 0.5395 - val_precision: 0.5050 - val_recall: 0.2417\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.6954 - accuracy: 0.5121 - precision: 0.4653 - recall: 0.4465 - val_loss: 0.6882 - val_accuracy: 0.5307 - val_precision: 0.4762 - val_recall: 0.1422\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 0.6941 - accuracy: 0.5390 - precision: 0.4806 - recall: 0.0961 - val_loss: 0.6903 - val_accuracy: 0.5373 - val_precision: 0.5000 - val_recall: 0.0427\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 0.6927 - accuracy: 0.5504 - precision: 0.5230 - recall: 0.1938 - val_loss: 0.6915 - val_accuracy: 0.5439 - val_precision: 0.5600 - val_recall: 0.0664\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.6932 - accuracy: 0.5383 - precision: 0.4937 - recall: 0.3628 - val_loss: 0.6923 - val_accuracy: 0.5219 - val_precision: 0.4533 - val_recall: 0.1611\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.6938 - accuracy: 0.5213 - precision: 0.4775 - recall: 0.4946 - val_loss: 0.7013 - val_accuracy: 0.5263 - val_precision: 0.4886 - val_recall: 0.5071\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.6920 - accuracy: 0.5433 - precision: 0.5009 - recall: 0.4248 - val_loss: 0.6853 - val_accuracy: 0.5570 - val_precision: 0.5349 - val_recall: 0.3270\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 0.6926 - accuracy: 0.5369 - precision: 0.4932 - recall: 0.4527 - val_loss: 0.7176 - val_accuracy: 0.5702 - val_precision: 0.5926 - val_recall: 0.2275\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.6953 - accuracy: 0.5411 - precision: 0.4976 - recall: 0.3225 - val_loss: 0.7648 - val_accuracy: 0.5417 - val_precision: 0.5106 - val_recall: 0.2275\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.6938 - accuracy: 0.5468 - precision: 0.5046 - recall: 0.5101 - val_loss: 0.6917 - val_accuracy: 0.5066 - val_precision: 0.4735 - val_recall: 0.5924\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.7264 - accuracy: 0.4908 - precision: 0.4559 - recall: 0.5845 - val_loss: 0.6851 - val_accuracy: 0.5592 - val_precision: 0.5362 - val_recall: 0.3507\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 0.7000 - accuracy: 0.5376 - precision: 0.4839 - recall: 0.1628 - val_loss: 0.6918 - val_accuracy: 0.5263 - val_precision: 0.4860 - val_recall: 0.4123\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.6952 - accuracy: 0.5489 - precision: 0.5224 - recall: 0.1628 - val_loss: 0.6878 - val_accuracy: 0.5482 - val_precision: 0.5333 - val_recall: 0.1896\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.6973 - accuracy: 0.5426 - precision: 0.5000 - recall: 0.0326 - val_loss: 0.6906 - val_accuracy: 0.5482 - val_precision: 1.0000 - val_recall: 0.0237\n",
      "Epoch 19/50\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.7078 - accuracy: 0.5326 - precision: 0.4239 - recall: 0.0605 - val_loss: 0.6902 - val_accuracy: 0.5439 - val_precision: 0.6364 - val_recall: 0.0332\n",
      "Epoch 20/50\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.7040 - accuracy: 0.5227 - precision: 0.4478 - recall: 0.1860 - val_loss: 0.6891 - val_accuracy: 0.5461 - val_precision: 0.5208 - val_recall: 0.2370\n",
      "Epoch 21/50\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.6987 - accuracy: 0.5369 - precision: 0.4623 - recall: 0.0760 - val_loss: 0.6906 - val_accuracy: 0.5373 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 22/50\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.6979 - accuracy: 0.5426 - precision: 0.5000 - recall: 0.0109 - val_loss: 0.6905 - val_accuracy: 0.5373 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 23/50\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.6957 - accuracy: 0.5369 - precision: 0.4429 - recall: 0.0481 - val_loss: 0.6912 - val_accuracy: 0.5373 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 24/50\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.6972 - accuracy: 0.5220 - precision: 0.4088 - recall: 0.1008 - val_loss: 0.6910 - val_accuracy: 0.5373 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 25/50\n",
      " 9/12 [=====================>........] - ETA: 0s - loss: 0.6962 - accuracy: 0.5391 - precision: 0.3333 - recall: 0.0095Restoring model weights from the end of the best epoch: 15.\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.6968 - accuracy: 0.5390 - precision: 0.3333 - recall: 0.0078 - val_loss: 0.6912 - val_accuracy: 0.5373 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 25: early stopping\n",
      "Now fitting model: LSTM_model_arch_17\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Dense_start_1 (Dense)       (None, 21, 96)            9312      \n",
      "                                                                 \n",
      " Dense_start_2 (Dense)       (None, 21, 80)            7760      \n",
      "                                                                 \n",
      " Dense_start_3 (Dense)       (None, 21, 40)            3240      \n",
      "                                                                 \n",
      " LSTM1 (LSTM)                (None, 21, 20)            4880      \n",
      "                                                                 \n",
      " Dropout1 (Dropout)          (None, 21, 20)            0         \n",
      "                                                                 \n",
      " LSTM2 (LSTM)                (None, 10)                1240      \n",
      "                                                                 \n",
      " Output (Dense)              (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 26443 (103.29 KB)\n",
      "Trainable params: 26443 (103.29 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 2s 35ms/step - loss: 0.7942 - accuracy: 0.4965 - precision: 0.4468 - recall: 0.4233 - val_loss: 0.6962 - val_accuracy: 0.5285 - val_precision: 0.4900 - val_recall: 0.4645\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.7070 - accuracy: 0.5369 - precision: 0.4912 - recall: 0.3457 - val_loss: 1.4083 - val_accuracy: 0.5461 - val_precision: 0.6250 - val_recall: 0.0474\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.8975 - accuracy: 0.5177 - precision: 0.4335 - recall: 0.1767 - val_loss: 0.6971 - val_accuracy: 0.5154 - val_precision: 0.4138 - val_recall: 0.1137\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.7008 - accuracy: 0.5241 - precision: 0.4611 - recall: 0.2388 - val_loss: 0.6985 - val_accuracy: 0.5329 - val_precision: 0.4583 - val_recall: 0.0521\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.6953 - accuracy: 0.5348 - precision: 0.4810 - recall: 0.2155 - val_loss: 0.7001 - val_accuracy: 0.5263 - val_precision: 0.4324 - val_recall: 0.0758\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.6929 - accuracy: 0.5567 - precision: 0.5303 - recall: 0.2713 - val_loss: 0.7407 - val_accuracy: 0.5088 - val_precision: 0.4270 - val_recall: 0.1801\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.6913 - accuracy: 0.5617 - precision: 0.5242 - recall: 0.4527 - val_loss: 0.6967 - val_accuracy: 0.5285 - val_precision: 0.4821 - val_recall: 0.2559\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 0.6963 - accuracy: 0.5397 - precision: 0.4959 - recall: 0.3767 - val_loss: 0.7032 - val_accuracy: 0.5175 - val_precision: 0.4211 - val_recall: 0.1137\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.7016 - accuracy: 0.5532 - precision: 0.5188 - recall: 0.3209 - val_loss: 0.7080 - val_accuracy: 0.5373 - val_precision: 0.5000 - val_recall: 0.1943\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.6984 - accuracy: 0.5383 - precision: 0.4943 - recall: 0.4047 - val_loss: 0.7155 - val_accuracy: 0.4693 - val_precision: 0.4083 - val_recall: 0.3270\n",
      "Epoch 11/50\n",
      " 9/12 [=====================>........] - ETA: 0s - loss: 0.7006 - accuracy: 0.5095 - precision: 0.4714 - recall: 0.6103Restoring model weights from the end of the best epoch: 1.\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.6997 - accuracy: 0.5099 - precision: 0.4712 - recall: 0.5829 - val_loss: 0.6995 - val_accuracy: 0.4956 - val_precision: 0.4252 - val_recall: 0.2559\n",
      "Epoch 11: early stopping\n",
      "Now fitting model: LSTM_model_arch_18\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Dense_start_1 (Dense)       (None, 21, 199)           39800     \n",
      "                                                                 \n",
      " Dense_start_2 (Dense)       (None, 21, 40)            8000      \n",
      "                                                                 \n",
      " LSTM1 (LSTM)                (None, 21, 20)            4880      \n",
      "                                                                 \n",
      " Dropout1 (Dropout)          (None, 21, 20)            0         \n",
      "                                                                 \n",
      " LSTM2 (LSTM)                (None, 10)                1240      \n",
      "                                                                 \n",
      " Dense_end_1 (Dense)         (None, 7)                 77        \n",
      "                                                                 \n",
      " Output (Dense)              (None, 1)                 8         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 54005 (210.96 KB)\n",
      "Trainable params: 54005 (210.96 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 1s 36ms/step - loss: 0.9945 - accuracy: 0.5163 - precision: 0.4696 - recall: 0.4434 - val_loss: 0.8033 - val_accuracy: 0.5132 - val_precision: 0.4689 - val_recall: 0.3934\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.8348 - accuracy: 0.4950 - precision: 0.4130 - recall: 0.2465 - val_loss: 0.6891 - val_accuracy: 0.5307 - val_precision: 0.4571 - val_recall: 0.0758\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.7853 - accuracy: 0.5348 - precision: 0.4768 - recall: 0.1752 - val_loss: 0.6916 - val_accuracy: 0.5395 - val_precision: 0.5116 - val_recall: 0.1043\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.7178 - accuracy: 0.4993 - precision: 0.4187 - recall: 0.2434 - val_loss: 0.6927 - val_accuracy: 0.5526 - val_precision: 0.5259 - val_recall: 0.3365\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.7081 - accuracy: 0.5099 - precision: 0.4613 - recall: 0.4248 - val_loss: 0.6942 - val_accuracy: 0.5285 - val_precision: 0.4896 - val_recall: 0.4455\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.7008 - accuracy: 0.5170 - precision: 0.4612 - recall: 0.3318 - val_loss: 0.6915 - val_accuracy: 0.5351 - val_precision: 0.4941 - val_recall: 0.1991\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 0.6988 - accuracy: 0.5390 - precision: 0.4916 - recall: 0.2279 - val_loss: 0.6911 - val_accuracy: 0.5373 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.7061 - accuracy: 0.5404 - precision: 0.4925 - recall: 0.1535 - val_loss: 0.6911 - val_accuracy: 0.5044 - val_precision: 0.4324 - val_recall: 0.2275\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.7033 - accuracy: 0.5234 - precision: 0.4384 - recall: 0.1488 - val_loss: 0.6907 - val_accuracy: 0.5285 - val_precision: 0.3750 - val_recall: 0.0284\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.7047 - accuracy: 0.5262 - precision: 0.4378 - recall: 0.1256 - val_loss: 0.6898 - val_accuracy: 0.5263 - val_precision: 0.4706 - val_recall: 0.1896\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.6988 - accuracy: 0.5390 - precision: 0.4937 - recall: 0.3023 - val_loss: 0.6884 - val_accuracy: 0.5351 - val_precision: 0.4972 - val_recall: 0.4265\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.6980 - accuracy: 0.5383 - precision: 0.4955 - recall: 0.5163 - val_loss: 0.6883 - val_accuracy: 0.5395 - val_precision: 0.5022 - val_recall: 0.5498\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.6945 - accuracy: 0.5440 - precision: 0.5016 - recall: 0.4806 - val_loss: 0.6903 - val_accuracy: 0.5373 - val_precision: 0.5000 - val_recall: 0.3839\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.6937 - accuracy: 0.5433 - precision: 0.5010 - recall: 0.3969 - val_loss: 0.6880 - val_accuracy: 0.5307 - val_precision: 0.4897 - val_recall: 0.3365\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.6892 - accuracy: 0.5709 - precision: 0.5407 - recall: 0.4124 - val_loss: 0.6868 - val_accuracy: 0.5373 - val_precision: 0.5000 - val_recall: 0.3175\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.6916 - accuracy: 0.5496 - precision: 0.5106 - recall: 0.3736 - val_loss: 0.6887 - val_accuracy: 0.5154 - val_precision: 0.4490 - val_recall: 0.2085\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.6885 - accuracy: 0.5518 - precision: 0.5147 - recall: 0.3519 - val_loss: 0.6896 - val_accuracy: 0.5132 - val_precision: 0.4421 - val_recall: 0.1991\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.6924 - accuracy: 0.5475 - precision: 0.5065 - recall: 0.4217 - val_loss: 0.6906 - val_accuracy: 0.5526 - val_precision: 0.5229 - val_recall: 0.3791\n",
      "Epoch 19/50\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.7010 - accuracy: 0.5255 - precision: 0.4837 - recall: 0.5519 - val_loss: 0.6924 - val_accuracy: 0.5373 - val_precision: 0.5000 - val_recall: 0.3981\n",
      "Epoch 20/50\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.6915 - accuracy: 0.5468 - precision: 0.5040 - recall: 0.5798 - val_loss: 0.6957 - val_accuracy: 0.5241 - val_precision: 0.4831 - val_recall: 0.4076\n",
      "Epoch 21/50\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.6872 - accuracy: 0.5638 - precision: 0.5211 - recall: 0.5736 - val_loss: 0.6962 - val_accuracy: 0.5219 - val_precision: 0.4774 - val_recall: 0.3507\n",
      "Epoch 22/50\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.6868 - accuracy: 0.5645 - precision: 0.5252 - recall: 0.5008 - val_loss: 0.6955 - val_accuracy: 0.5285 - val_precision: 0.4851 - val_recall: 0.3081\n",
      "Epoch 23/50\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 0.6917 - accuracy: 0.5461 - precision: 0.5036 - recall: 0.5442 - val_loss: 0.6949 - val_accuracy: 0.5285 - val_precision: 0.4885 - val_recall: 0.4028\n",
      "Epoch 24/50\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.6874 - accuracy: 0.5624 - precision: 0.5213 - recall: 0.5302 - val_loss: 0.6975 - val_accuracy: 0.5066 - val_precision: 0.4657 - val_recall: 0.4502\n",
      "Epoch 25/50\n",
      " 9/12 [=====================>........] - ETA: 0s - loss: 0.6934 - accuracy: 0.5425 - precision: 0.4991 - recall: 0.5418Restoring model weights from the end of the best epoch: 15.\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.6946 - accuracy: 0.5362 - precision: 0.4935 - recall: 0.5302 - val_loss: 0.7124 - val_accuracy: 0.4978 - val_precision: 0.4526 - val_recall: 0.4076\n",
      "Epoch 25: early stopping\n",
      "Now fitting model: LSTM_model_arch_18\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Dense_start_1 (Dense)       (None, 21, 96)            9312      \n",
      "                                                                 \n",
      " Dense_start_2 (Dense)       (None, 21, 40)            3880      \n",
      "                                                                 \n",
      " LSTM1 (LSTM)                (None, 21, 20)            4880      \n",
      "                                                                 \n",
      " Dropout1 (Dropout)          (None, 21, 20)            0         \n",
      "                                                                 \n",
      " LSTM2 (LSTM)                (None, 10)                1240      \n",
      "                                                                 \n",
      " Dense_end_1 (Dense)         (None, 7)                 77        \n",
      "                                                                 \n",
      " Output (Dense)              (None, 1)                 8         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19397 (75.77 KB)\n",
      "Trainable params: 19397 (75.77 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 1s 33ms/step - loss: 0.7262 - accuracy: 0.5121 - precision: 0.4703 - recall: 0.5287 - val_loss: 0.7138 - val_accuracy: 0.5000 - val_precision: 0.4605 - val_recall: 0.4692\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 27ms/step - loss: 0.7022 - accuracy: 0.5128 - precision: 0.4668 - recall: 0.4574 - val_loss: 0.6933 - val_accuracy: 0.5263 - val_precision: 0.4775 - val_recall: 0.2512\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.6978 - accuracy: 0.5369 - precision: 0.4882 - recall: 0.2558 - val_loss: 0.7051 - val_accuracy: 0.4934 - val_precision: 0.4419 - val_recall: 0.3602\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.6968 - accuracy: 0.5461 - precision: 0.5060 - recall: 0.3256 - val_loss: 0.7081 - val_accuracy: 0.4759 - val_precision: 0.4041 - val_recall: 0.2796\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.6911 - accuracy: 0.5574 - precision: 0.5167 - recall: 0.5023 - val_loss: 0.7134 - val_accuracy: 0.5088 - val_precision: 0.4673 - val_recall: 0.4408\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.6848 - accuracy: 0.5667 - precision: 0.5371 - recall: 0.3814 - val_loss: 0.7500 - val_accuracy: 0.4715 - val_precision: 0.4419 - val_recall: 0.5403\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.6844 - accuracy: 0.5603 - precision: 0.5191 - recall: 0.5271 - val_loss: 0.7091 - val_accuracy: 0.5197 - val_precision: 0.4767 - val_recall: 0.3886\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.6843 - accuracy: 0.5511 - precision: 0.5095 - recall: 0.4992 - val_loss: 0.7198 - val_accuracy: 0.4605 - val_precision: 0.4324 - val_recall: 0.5308\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.6681 - accuracy: 0.5830 - precision: 0.5434 - recall: 0.5535 - val_loss: 0.7402 - val_accuracy: 0.4693 - val_precision: 0.4402 - val_recall: 0.5403\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.6744 - accuracy: 0.5780 - precision: 0.5407 - recall: 0.5147 - val_loss: 0.7714 - val_accuracy: 0.4934 - val_precision: 0.4650 - val_recall: 0.6303\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.6699 - accuracy: 0.5695 - precision: 0.5266 - recall: 0.5829 - val_loss: 0.7520 - val_accuracy: 0.4956 - val_precision: 0.4570 - val_recall: 0.4787\n",
      "Epoch 12/50\n",
      "10/12 [========================>.....] - ETA: 0s - loss: 0.6751 - accuracy: 0.5648 - precision: 0.5244 - recall: 0.6000Restoring model weights from the end of the best epoch: 2.\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.6761 - accuracy: 0.5631 - precision: 0.5191 - recall: 0.6109 - val_loss: 0.7444 - val_accuracy: 0.4649 - val_precision: 0.4476 - val_recall: 0.6682\n",
      "Epoch 12: early stopping\n",
      "Now fitting model: LSTM_model_arch_19\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Dense_start_1 (Dense)       (None, 21, 199)           39800     \n",
      "                                                                 \n",
      " Dense_start_2 (Dense)       (None, 21, 80)            16000     \n",
      "                                                                 \n",
      " Dense_start_3 (Dense)       (None, 21, 40)            3240      \n",
      "                                                                 \n",
      " LSTM1 (LSTM)                (None, 21, 20)            4880      \n",
      "                                                                 \n",
      " Dropout1 (Dropout)          (None, 21, 20)            0         \n",
      "                                                                 \n",
      " LSTM2 (LSTM)                (None, 10)                1240      \n",
      "                                                                 \n",
      " Dense_end_1 (Dense)         (None, 5)                 55        \n",
      "                                                                 \n",
      " Output (Dense)              (None, 1)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65221 (254.77 KB)\n",
      "Trainable params: 65221 (254.77 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 1s 37ms/step - loss: 1.2691 - accuracy: 0.5099 - precision: 0.4398 - recall: 0.2605 - val_loss: 0.6997 - val_accuracy: 0.4978 - val_precision: 0.4731 - val_recall: 0.7488\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.6992 - accuracy: 0.5106 - precision: 0.4589 - recall: 0.3891 - val_loss: 0.7123 - val_accuracy: 0.4781 - val_precision: 0.4389 - val_recall: 0.4597\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.7137 - accuracy: 0.5014 - precision: 0.4534 - recall: 0.4372 - val_loss: 0.6973 - val_accuracy: 0.4781 - val_precision: 0.4372 - val_recall: 0.4455\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 4.1229 - accuracy: 0.5177 - precision: 0.4679 - recall: 0.3953 - val_loss: 2.6811 - val_accuracy: 0.4737 - val_precision: 0.4617 - val_recall: 0.8294\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 3.6455 - accuracy: 0.5078 - precision: 0.4677 - recall: 0.5504 - val_loss: 1.2861 - val_accuracy: 0.5285 - val_precision: 0.4825 - val_recall: 0.2607\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 1.6611 - accuracy: 0.5099 - precision: 0.4410 - recall: 0.2667 - val_loss: 1.3061 - val_accuracy: 0.4781 - val_precision: 0.4322 - val_recall: 0.4076\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 1.1024 - accuracy: 0.5213 - precision: 0.4779 - recall: 0.5039 - val_loss: 0.6945 - val_accuracy: 0.4978 - val_precision: 0.4631 - val_recall: 0.5355\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.7591 - accuracy: 0.4773 - precision: 0.4465 - recall: 0.5953 - val_loss: 0.6976 - val_accuracy: 0.4781 - val_precision: 0.4462 - val_recall: 0.5308\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.7514 - accuracy: 0.4901 - precision: 0.4553 - recall: 0.5845 - val_loss: 0.6934 - val_accuracy: 0.5022 - val_precision: 0.4716 - val_recall: 0.6303\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.7237 - accuracy: 0.4766 - precision: 0.4577 - recall: 0.7798 - val_loss: 0.6935 - val_accuracy: 0.4978 - val_precision: 0.4700 - val_recall: 0.6682\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.6974 - accuracy: 0.5092 - precision: 0.4601 - recall: 0.4202 - val_loss: 0.6934 - val_accuracy: 0.5373 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.7146 - accuracy: 0.5340 - precision: 0.4474 - recall: 0.0791 - val_loss: 0.6924 - val_accuracy: 0.5307 - val_precision: 0.3846 - val_recall: 0.0237\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.6956 - accuracy: 0.5255 - precision: 0.4528 - recall: 0.1783 - val_loss: 0.6902 - val_accuracy: 0.5263 - val_precision: 0.1429 - val_recall: 0.0047\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.7069 - accuracy: 0.5270 - precision: 0.4225 - recall: 0.0930 - val_loss: 0.6907 - val_accuracy: 0.5373 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.7097 - accuracy: 0.5447 - precision: 0.5211 - recall: 0.0574 - val_loss: 0.6919 - val_accuracy: 0.5373 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.7114 - accuracy: 0.5284 - precision: 0.4123 - recall: 0.0729 - val_loss: 0.6903 - val_accuracy: 0.5373 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.7140 - accuracy: 0.5340 - precision: 0.3125 - recall: 0.0155 - val_loss: 0.6905 - val_accuracy: 0.5373 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.7073 - accuracy: 0.5390 - precision: 0.4684 - recall: 0.0574 - val_loss: 0.6905 - val_accuracy: 0.5351 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 19/50\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.7070 - accuracy: 0.5291 - precision: 0.4286 - recall: 0.0884 - val_loss: 0.6907 - val_accuracy: 0.5351 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 20/50\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.6998 - accuracy: 0.5397 - precision: 0.4877 - recall: 0.1225 - val_loss: 0.6912 - val_accuracy: 0.5373 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 21/50\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 0.7020 - accuracy: 0.5383 - precision: 0.4815 - recall: 0.1209 - val_loss: 0.6889 - val_accuracy: 0.5351 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 22/50\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.7077 - accuracy: 0.5142 - precision: 0.3837 - recall: 0.1023 - val_loss: 0.6903 - val_accuracy: 0.5351 - val_precision: 0.3333 - val_recall: 0.0047\n",
      "Epoch 23/50\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.6982 - accuracy: 0.5404 - precision: 0.4892 - recall: 0.1054 - val_loss: 0.6910 - val_accuracy: 0.5351 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 24/50\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.6997 - accuracy: 0.5277 - precision: 0.4071 - recall: 0.0713 - val_loss: 0.6915 - val_accuracy: 0.5329 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 25/50\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.7001 - accuracy: 0.5418 - precision: 0.4947 - recall: 0.0729 - val_loss: 0.6915 - val_accuracy: 0.5373 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 26/50\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.6967 - accuracy: 0.5433 - precision: 0.5031 - recall: 0.1256 - val_loss: 0.6932 - val_accuracy: 0.5373 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 27/50\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.6940 - accuracy: 0.5447 - precision: 0.5077 - recall: 0.1535 - val_loss: 0.6902 - val_accuracy: 0.5373 - val_precision: 0.5000 - val_recall: 0.0047\n",
      "Epoch 28/50\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.6994 - accuracy: 0.5156 - precision: 0.3978 - recall: 0.1147 - val_loss: 0.6906 - val_accuracy: 0.5329 - val_precision: 0.3750 - val_recall: 0.0142\n",
      "Epoch 29/50\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.7043 - accuracy: 0.5397 - precision: 0.4815 - recall: 0.0806 - val_loss: 0.6900 - val_accuracy: 0.5373 - val_precision: 0.5000 - val_recall: 0.0142\n",
      "Epoch 30/50\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.6958 - accuracy: 0.5475 - precision: 0.5200 - recall: 0.1411 - val_loss: 0.6902 - val_accuracy: 0.5351 - val_precision: 0.4000 - val_recall: 0.0095\n",
      "Epoch 31/50\n",
      " 9/12 [=====================>........] - ETA: 0s - loss: 0.6997 - accuracy: 0.5417 - precision: 0.4946 - recall: 0.1730Restoring model weights from the end of the best epoch: 21.\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.7027 - accuracy: 0.5362 - precision: 0.4805 - recall: 0.1721 - val_loss: 0.6902 - val_accuracy: 0.5351 - val_precision: 0.4000 - val_recall: 0.0095\n",
      "Epoch 31: early stopping\n",
      "Now fitting model: LSTM_model_arch_19\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Dense_start_1 (Dense)       (None, 21, 96)            9312      \n",
      "                                                                 \n",
      " Dense_start_2 (Dense)       (None, 21, 80)            7760      \n",
      "                                                                 \n",
      " Dense_start_3 (Dense)       (None, 21, 40)            3240      \n",
      "                                                                 \n",
      " LSTM1 (LSTM)                (None, 21, 20)            4880      \n",
      "                                                                 \n",
      " Dropout1 (Dropout)          (None, 21, 20)            0         \n",
      "                                                                 \n",
      " LSTM2 (LSTM)                (None, 10)                1240      \n",
      "                                                                 \n",
      " Dense_end_1 (Dense)         (None, 5)                 55        \n",
      "                                                                 \n",
      " Output (Dense)              (None, 1)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 26493 (103.49 KB)\n",
      "Trainable params: 26493 (103.49 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 2s 47ms/step - loss: 0.7250 - accuracy: 0.4894 - precision: 0.4540 - recall: 0.5736 - val_loss: 0.7018 - val_accuracy: 0.4605 - val_precision: 0.4564 - val_recall: 0.8673\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.6937 - accuracy: 0.5057 - precision: 0.4685 - recall: 0.6000 - val_loss: 0.6951 - val_accuracy: 0.4978 - val_precision: 0.4640 - val_recall: 0.5498\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.7012 - accuracy: 0.5468 - precision: 0.5063 - recall: 0.3721 - val_loss: 0.6956 - val_accuracy: 0.5241 - val_precision: 0.4792 - val_recall: 0.3270\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.6895 - accuracy: 0.5638 - precision: 0.5379 - recall: 0.3302 - val_loss: 0.6995 - val_accuracy: 0.4956 - val_precision: 0.4444 - val_recall: 0.3602\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.6914 - accuracy: 0.5532 - precision: 0.5240 - recall: 0.2543 - val_loss: 0.7029 - val_accuracy: 0.4781 - val_precision: 0.4322 - val_recall: 0.4076\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 0.6846 - accuracy: 0.5766 - precision: 0.5498 - recall: 0.4109 - val_loss: 0.7009 - val_accuracy: 0.4956 - val_precision: 0.4592 - val_recall: 0.5071\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.6806 - accuracy: 0.5730 - precision: 0.5358 - recall: 0.4992 - val_loss: 0.7212 - val_accuracy: 0.5000 - val_precision: 0.4745 - val_recall: 0.7488\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.6830 - accuracy: 0.5652 - precision: 0.5201 - recall: 0.6434 - val_loss: 0.7115 - val_accuracy: 0.4912 - val_precision: 0.4626 - val_recall: 0.6161\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.6983 - accuracy: 0.5723 - precision: 0.5284 - recall: 0.6062 - val_loss: 0.7238 - val_accuracy: 0.5044 - val_precision: 0.4762 - val_recall: 0.7109\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.6865 - accuracy: 0.5348 - precision: 0.4944 - recall: 0.7581 - val_loss: 0.7214 - val_accuracy: 0.5022 - val_precision: 0.4753 - val_recall: 0.7299\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.6852 - accuracy: 0.5645 - precision: 0.5199 - recall: 0.6279 - val_loss: 0.6904 - val_accuracy: 0.5263 - val_precision: 0.4919 - val_recall: 0.7156\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.6863 - accuracy: 0.5957 - precision: 0.5581 - recall: 0.5581 - val_loss: 0.7105 - val_accuracy: 0.5022 - val_precision: 0.4777 - val_recall: 0.8104\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.6818 - accuracy: 0.5525 - precision: 0.5074 - recall: 0.7473 - val_loss: 0.7312 - val_accuracy: 0.4956 - val_precision: 0.4630 - val_recall: 0.5640\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.6851 - accuracy: 0.5418 - precision: 0.4994 - recall: 0.6791 - val_loss: 0.7168 - val_accuracy: 0.4956 - val_precision: 0.4753 - val_recall: 0.8673\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 0.6862 - accuracy: 0.5532 - precision: 0.5091 - recall: 0.6527 - val_loss: 0.7137 - val_accuracy: 0.5044 - val_precision: 0.4723 - val_recall: 0.6066\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.6851 - accuracy: 0.5638 - precision: 0.5198 - recall: 0.6109 - val_loss: 0.7208 - val_accuracy: 0.4890 - val_precision: 0.4680 - val_recall: 0.7630\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.6813 - accuracy: 0.5546 - precision: 0.5093 - recall: 0.7225 - val_loss: 0.7091 - val_accuracy: 0.5241 - val_precision: 0.4889 - val_recall: 0.6256\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.6939 - accuracy: 0.5709 - precision: 0.5302 - recall: 0.5442 - val_loss: 0.7033 - val_accuracy: 0.4978 - val_precision: 0.4761 - val_recall: 0.8483\n",
      "Epoch 19/50\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.6792 - accuracy: 0.5624 - precision: 0.5154 - recall: 0.7256 - val_loss: 0.6982 - val_accuracy: 0.5044 - val_precision: 0.4768 - val_recall: 0.7299\n",
      "Epoch 20/50\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.6781 - accuracy: 0.5716 - precision: 0.5320 - recall: 0.5287 - val_loss: 0.7208 - val_accuracy: 0.4846 - val_precision: 0.4689 - val_recall: 0.8578\n",
      "Epoch 21/50\n",
      " 9/12 [=====================>........] - ETA: 0s - loss: 0.6734 - accuracy: 0.5573 - precision: 0.5099 - recall: 0.7871Restoring model weights from the end of the best epoch: 11.\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.6755 - accuracy: 0.5660 - precision: 0.5172 - recall: 0.7690 - val_loss: 0.7114 - val_accuracy: 0.5088 - val_precision: 0.4796 - val_recall: 0.7251\n",
      "Epoch 21: early stopping\n",
      "Now fitting model: LSTM_model_arch_20\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Dense_start_1 (Dense)       (None, 21, 199)           39800     \n",
      "                                                                 \n",
      " Dense_start_2 (Dense)       (None, 21, 40)            8000      \n",
      "                                                                 \n",
      " LSTM1 (LSTM)                (None, 21, 20)            4880      \n",
      "                                                                 \n",
      " Dropout1 (Dropout)          (None, 21, 20)            0         \n",
      "                                                                 \n",
      " LSTM2 (LSTM)                (None, 10)                1240      \n",
      "                                                                 \n",
      " Dense_end_1 (Dense)         (None, 7)                 77        \n",
      "                                                                 \n",
      " Dense_end_2 (Dense)         (None, 5)                 40        \n",
      "                                                                 \n",
      " Output (Dense)              (None, 1)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 54043 (211.11 KB)\n",
      "Trainable params: 54043 (211.11 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 1s 36ms/step - loss: 0.7298 - accuracy: 0.5184 - precision: 0.4763 - recall: 0.5287 - val_loss: 0.6926 - val_accuracy: 0.5548 - val_precision: 0.6176 - val_recall: 0.0995\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.7163 - accuracy: 0.5504 - precision: 0.5266 - recall: 0.1690 - val_loss: 0.7010 - val_accuracy: 0.5197 - val_precision: 0.3571 - val_recall: 0.0474\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.7059 - accuracy: 0.5277 - precision: 0.4601 - recall: 0.1876 - val_loss: 0.6924 - val_accuracy: 0.5154 - val_precision: 0.2727 - val_recall: 0.0284\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 0.7004 - accuracy: 0.5170 - precision: 0.4400 - recall: 0.2047 - val_loss: 0.7005 - val_accuracy: 0.4781 - val_precision: 0.3846 - val_recall: 0.2133\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.6982 - accuracy: 0.5113 - precision: 0.4484 - recall: 0.2961 - val_loss: 0.6992 - val_accuracy: 0.4649 - val_precision: 0.3590 - val_recall: 0.1991\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.6945 - accuracy: 0.5348 - precision: 0.4891 - recall: 0.3814 - val_loss: 0.6962 - val_accuracy: 0.5395 - val_precision: 0.5098 - val_recall: 0.1232\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.6998 - accuracy: 0.5489 - precision: 0.5446 - recall: 0.0853 - val_loss: 0.6990 - val_accuracy: 0.5307 - val_precision: 0.3636 - val_recall: 0.0190\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.6925 - accuracy: 0.5440 - precision: 0.5028 - recall: 0.2791 - val_loss: 0.6948 - val_accuracy: 0.5395 - val_precision: 0.5051 - val_recall: 0.2370\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 0.6974 - accuracy: 0.5383 - precision: 0.4940 - recall: 0.3845 - val_loss: 0.6955 - val_accuracy: 0.5307 - val_precision: 0.4800 - val_recall: 0.1706\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 0.6893 - accuracy: 0.5291 - precision: 0.4877 - recall: 0.5860 - val_loss: 0.6969 - val_accuracy: 0.5154 - val_precision: 0.4583 - val_recall: 0.2607\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.6863 - accuracy: 0.5617 - precision: 0.5273 - recall: 0.4047 - val_loss: 0.6956 - val_accuracy: 0.5066 - val_precision: 0.4635 - val_recall: 0.4218\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.6803 - accuracy: 0.5475 - precision: 0.5042 - recall: 0.6543 - val_loss: 0.6958 - val_accuracy: 0.5636 - val_precision: 0.6304 - val_recall: 0.1374\n",
      "Epoch 13/50\n",
      " 9/12 [=====================>........] - ETA: 0s - loss: 0.6967 - accuracy: 0.5677 - precision: 0.5437 - recall: 0.3308Restoring model weights from the end of the best epoch: 3.\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.6964 - accuracy: 0.5723 - precision: 0.5522 - recall: 0.3442 - val_loss: 0.7172 - val_accuracy: 0.5197 - val_precision: 0.4636 - val_recall: 0.2417\n",
      "Epoch 13: early stopping\n",
      "Now fitting model: LSTM_model_arch_20\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Dense_start_1 (Dense)       (None, 21, 96)            9312      \n",
      "                                                                 \n",
      " Dense_start_2 (Dense)       (None, 21, 40)            3880      \n",
      "                                                                 \n",
      " LSTM1 (LSTM)                (None, 21, 20)            4880      \n",
      "                                                                 \n",
      " Dropout1 (Dropout)          (None, 21, 20)            0         \n",
      "                                                                 \n",
      " LSTM2 (LSTM)                (None, 10)                1240      \n",
      "                                                                 \n",
      " Dense_end_1 (Dense)         (None, 7)                 77        \n",
      "                                                                 \n",
      " Dense_end_2 (Dense)         (None, 5)                 40        \n",
      "                                                                 \n",
      " Output (Dense)              (None, 1)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19435 (75.92 KB)\n",
      "Trainable params: 19435 (75.92 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 2s 56ms/step - loss: 0.7121 - accuracy: 0.4979 - precision: 0.4463 - recall: 0.4062 - val_loss: 0.6986 - val_accuracy: 0.4978 - val_precision: 0.4598 - val_recall: 0.4882\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.7120 - accuracy: 0.5277 - precision: 0.4662 - recall: 0.2248 - val_loss: 0.6912 - val_accuracy: 0.5482 - val_precision: 0.6667 - val_recall: 0.0474\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.7191 - accuracy: 0.5248 - precision: 0.4598 - recall: 0.2217 - val_loss: 0.6886 - val_accuracy: 0.5439 - val_precision: 0.6667 - val_recall: 0.0284\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.7067 - accuracy: 0.5284 - precision: 0.4667 - recall: 0.2171 - val_loss: 0.6902 - val_accuracy: 0.5395 - val_precision: 0.5714 - val_recall: 0.0190\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.7127 - accuracy: 0.5305 - precision: 0.4622 - recall: 0.1612 - val_loss: 0.6898 - val_accuracy: 0.5461 - val_precision: 0.5500 - val_recall: 0.1043\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 1s 45ms/step - loss: 0.6981 - accuracy: 0.5369 - precision: 0.4753 - recall: 0.1194 - val_loss: 0.6879 - val_accuracy: 0.5504 - val_precision: 0.5833 - val_recall: 0.0995\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.6977 - accuracy: 0.5312 - precision: 0.4596 - recall: 0.1411 - val_loss: 0.6921 - val_accuracy: 0.5022 - val_precision: 0.4344 - val_recall: 0.2512\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.6970 - accuracy: 0.5305 - precision: 0.4536 - recall: 0.1287 - val_loss: 0.6891 - val_accuracy: 0.5263 - val_precision: 0.4545 - val_recall: 0.1185\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.6941 - accuracy: 0.5426 - precision: 0.5000 - recall: 0.1814 - val_loss: 0.6926 - val_accuracy: 0.5285 - val_precision: 0.4846 - val_recall: 0.2986\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.6929 - accuracy: 0.5262 - precision: 0.4766 - recall: 0.3628 - val_loss: 0.6985 - val_accuracy: 0.5110 - val_precision: 0.4737 - val_recall: 0.5118\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 0.6928 - accuracy: 0.5404 - precision: 0.4969 - recall: 0.3721 - val_loss: 0.7037 - val_accuracy: 0.4890 - val_precision: 0.4466 - val_recall: 0.4360\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.6873 - accuracy: 0.5525 - precision: 0.5125 - recall: 0.4465 - val_loss: 0.7010 - val_accuracy: 0.5066 - val_precision: 0.4754 - val_recall: 0.6398\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.6845 - accuracy: 0.5610 - precision: 0.5222 - recall: 0.4744 - val_loss: 0.7140 - val_accuracy: 0.4868 - val_precision: 0.4688 - val_recall: 0.8199\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.6797 - accuracy: 0.5652 - precision: 0.5223 - recall: 0.5814 - val_loss: 0.7117 - val_accuracy: 0.4934 - val_precision: 0.4541 - val_recall: 0.4692\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.6880 - accuracy: 0.5674 - precision: 0.5302 - recall: 0.4760 - val_loss: 0.7412 - val_accuracy: 0.4825 - val_precision: 0.4680 - val_recall: 0.8673\n",
      "Epoch 16/50\n",
      " 9/12 [=====================>........] - ETA: 0s - loss: 0.6864 - accuracy: 0.5503 - precision: 0.5064 - recall: 0.5989Restoring model weights from the end of the best epoch: 6.\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 0.6873 - accuracy: 0.5496 - precision: 0.5069 - recall: 0.5705 - val_loss: 0.6973 - val_accuracy: 0.5241 - val_precision: 0.4872 - val_recall: 0.5403\n",
      "Epoch 16: early stopping\n",
      "Now fitting model: LSTM_model_arch_21\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Dense_start_1 (Dense)       (None, 21, 199)           39800     \n",
      "                                                                 \n",
      " Dense_start_2 (Dense)       (None, 21, 80)            16000     \n",
      "                                                                 \n",
      " Dense_start_3 (Dense)       (None, 21, 40)            3240      \n",
      "                                                                 \n",
      " LSTM1 (LSTM)                (None, 21, 20)            4880      \n",
      "                                                                 \n",
      " Dropout1 (Dropout)          (None, 21, 20)            0         \n",
      "                                                                 \n",
      " LSTM2 (LSTM)                (None, 10)                1240      \n",
      "                                                                 \n",
      " Dense_end_1 (Dense)         (None, 7)                 77        \n",
      "                                                                 \n",
      " Dense_end_2 (Dense)         (None, 5)                 40        \n",
      "                                                                 \n",
      " Output (Dense)              (None, 1)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65283 (255.01 KB)\n",
      "Trainable params: 65283 (255.01 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 2s 44ms/step - loss: 0.8125 - accuracy: 0.5234 - precision: 0.4796 - recall: 0.4915 - val_loss: 0.6997 - val_accuracy: 0.4803 - val_precision: 0.4369 - val_recall: 0.4265\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.7176 - accuracy: 0.5433 - precision: 0.5022 - recall: 0.1767 - val_loss: 0.6926 - val_accuracy: 0.5329 - val_precision: 0.3750 - val_recall: 0.0142\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.7073 - accuracy: 0.5270 - precision: 0.3804 - recall: 0.0543 - val_loss: 0.6910 - val_accuracy: 0.5307 - val_precision: 0.4667 - val_recall: 0.0995\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 0.7988 - accuracy: 0.5284 - precision: 0.4590 - recall: 0.1736 - val_loss: 0.8577 - val_accuracy: 0.5110 - val_precision: 0.4455 - val_recall: 0.2322\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.7687 - accuracy: 0.5348 - precision: 0.4631 - recall: 0.1070 - val_loss: 0.7814 - val_accuracy: 0.5285 - val_precision: 0.4767 - val_recall: 0.1943\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.7323 - accuracy: 0.5383 - precision: 0.4890 - recall: 0.2062 - val_loss: 0.6959 - val_accuracy: 0.5395 - val_precision: 0.5152 - val_recall: 0.0806\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.6990 - accuracy: 0.5248 - precision: 0.4481 - recall: 0.1674 - val_loss: 0.6935 - val_accuracy: 0.5329 - val_precision: 0.3333 - val_recall: 0.0095\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.6980 - accuracy: 0.5277 - precision: 0.3562 - recall: 0.0403 - val_loss: 0.6927 - val_accuracy: 0.5373 - val_precision: 0.5000 - val_recall: 0.0190\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 0.7003 - accuracy: 0.5362 - precision: 0.4483 - recall: 0.0605 - val_loss: 0.6948 - val_accuracy: 0.5373 - val_precision: 0.5000 - val_recall: 0.0142\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.6975 - accuracy: 0.5404 - precision: 0.4727 - recall: 0.0403 - val_loss: 0.6959 - val_accuracy: 0.5351 - val_precision: 0.4286 - val_recall: 0.0142\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.7055 - accuracy: 0.5333 - precision: 0.4198 - recall: 0.0527 - val_loss: 0.6966 - val_accuracy: 0.5307 - val_precision: 0.4348 - val_recall: 0.0474\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.7031 - accuracy: 0.5234 - precision: 0.4606 - recall: 0.2450 - val_loss: 0.6954 - val_accuracy: 0.5329 - val_precision: 0.4615 - val_recall: 0.0569\n",
      "Epoch 13/50\n",
      " 9/12 [=====================>........] - ETA: 0s - loss: 0.6967 - accuracy: 0.4991 - precision: 0.4432 - recall: 0.3783Restoring model weights from the end of the best epoch: 3.\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.6944 - accuracy: 0.5085 - precision: 0.4559 - recall: 0.3845 - val_loss: 0.6953 - val_accuracy: 0.4846 - val_precision: 0.4348 - val_recall: 0.3791\n",
      "Epoch 13: early stopping\n",
      "Now fitting model: LSTM_model_arch_21\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Dense_start_1 (Dense)       (None, 21, 96)            9312      \n",
      "                                                                 \n",
      " Dense_start_2 (Dense)       (None, 21, 80)            7760      \n",
      "                                                                 \n",
      " Dense_start_3 (Dense)       (None, 21, 40)            3240      \n",
      "                                                                 \n",
      " LSTM1 (LSTM)                (None, 21, 20)            4880      \n",
      "                                                                 \n",
      " Dropout1 (Dropout)          (None, 21, 20)            0         \n",
      "                                                                 \n",
      " LSTM2 (LSTM)                (None, 10)                1240      \n",
      "                                                                 \n",
      " Dense_end_1 (Dense)         (None, 7)                 77        \n",
      "                                                                 \n",
      " Dense_end_2 (Dense)         (None, 5)                 40        \n",
      "                                                                 \n",
      " Output (Dense)              (None, 1)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 26555 (103.73 KB)\n",
      "Trainable params: 26555 (103.73 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 2s 35ms/step - loss: 0.7090 - accuracy: 0.5028 - precision: 0.4399 - recall: 0.3178 - val_loss: 0.6929 - val_accuracy: 0.5110 - val_precision: 0.4189 - val_recall: 0.1469\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.6960 - accuracy: 0.5369 - precision: 0.4840 - recall: 0.1876 - val_loss: 0.6951 - val_accuracy: 0.5263 - val_precision: 0.4490 - val_recall: 0.1043\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.6928 - accuracy: 0.5454 - precision: 0.5049 - recall: 0.3225 - val_loss: 0.6897 - val_accuracy: 0.5373 - val_precision: 0.5000 - val_recall: 0.2891\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.6964 - accuracy: 0.5426 - precision: 0.5000 - recall: 0.3597 - val_loss: 0.6993 - val_accuracy: 0.4890 - val_precision: 0.4353 - val_recall: 0.3507\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.7063 - accuracy: 0.5532 - precision: 0.5228 - recall: 0.2667 - val_loss: 0.6986 - val_accuracy: 0.5329 - val_precision: 0.4545 - val_recall: 0.0474\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 0.6993 - accuracy: 0.5383 - precision: 0.4865 - recall: 0.1674 - val_loss: 0.6937 - val_accuracy: 0.4781 - val_precision: 0.4140 - val_recall: 0.3081\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.6953 - accuracy: 0.5248 - precision: 0.4751 - recall: 0.3705 - val_loss: 0.6915 - val_accuracy: 0.5395 - val_precision: 0.5088 - val_recall: 0.1374\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.6995 - accuracy: 0.5560 - precision: 0.5473 - recall: 0.1705 - val_loss: 0.6921 - val_accuracy: 0.5241 - val_precision: 0.4766 - val_recall: 0.2891\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.7078 - accuracy: 0.5035 - precision: 0.4116 - recall: 0.1984 - val_loss: 0.6919 - val_accuracy: 0.5373 - val_precision: 0.5000 - val_recall: 0.1185\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.7019 - accuracy: 0.5369 - precision: 0.4740 - recall: 0.1132 - val_loss: 0.6935 - val_accuracy: 0.5241 - val_precision: 0.4516 - val_recall: 0.1327\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 1s 16ms/step - loss: 0.6967 - accuracy: 0.5135 - precision: 0.4617 - recall: 0.3829 - val_loss: 0.6928 - val_accuracy: 0.5088 - val_precision: 0.4620 - val_recall: 0.3744\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.7014 - accuracy: 0.5007 - precision: 0.4201 - recall: 0.2403 - val_loss: 0.6908 - val_accuracy: 0.5197 - val_precision: 0.4310 - val_recall: 0.1185\n",
      "Epoch 13/50\n",
      " 9/12 [=====================>........] - ETA: 0s - loss: 0.6979 - accuracy: 0.5347 - precision: 0.4836 - recall: 0.2795Restoring model weights from the end of the best epoch: 3.\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.6978 - accuracy: 0.5305 - precision: 0.4784 - recall: 0.2915 - val_loss: 0.6942 - val_accuracy: 0.5132 - val_precision: 0.4658 - val_recall: 0.3555\n",
      "Epoch 13: early stopping\n",
      "Now fitting model: LSTM_model_arch_22\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Dense_start_1 (Dense)       (None, 21, 199)           39800     \n",
      "                                                                 \n",
      " Dense_start_2 (Dense)       (None, 21, 40)            8000      \n",
      "                                                                 \n",
      " LSTM1 (LSTM)                (None, 21, 20)            4880      \n",
      "                                                                 \n",
      " Dropout1 (Dropout)          (None, 21, 20)            0         \n",
      "                                                                 \n",
      " LSTM2 (LSTM)                (None, 21, 10)            1240      \n",
      "                                                                 \n",
      " Dropout2 (Dropout)          (None, 21, 10)            0         \n",
      "                                                                 \n",
      " LSTM3 (LSTM)                (None, 10)                840       \n",
      "                                                                 \n",
      " Output (Dense)              (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 54771 (213.95 KB)\n",
      "Trainable params: 54771 (213.95 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 2s 60ms/step - loss: 0.7287 - accuracy: 0.5014 - precision: 0.4648 - recall: 0.5938 - val_loss: 0.7156 - val_accuracy: 0.4605 - val_precision: 0.4564 - val_recall: 0.8673\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.6943 - accuracy: 0.5170 - precision: 0.4738 - recall: 0.5039 - val_loss: 0.9232 - val_accuracy: 0.4825 - val_precision: 0.4648 - val_recall: 0.7820\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.7188 - accuracy: 0.5035 - precision: 0.3954 - recall: 0.1612 - val_loss: 0.6923 - val_accuracy: 0.5219 - val_precision: 0.4054 - val_recall: 0.0711\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.7052 - accuracy: 0.5376 - precision: 0.4533 - recall: 0.0527 - val_loss: 0.6915 - val_accuracy: 0.5307 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 27ms/step - loss: 0.6946 - accuracy: 0.5433 - precision: 0.5385 - recall: 0.0109 - val_loss: 0.6916 - val_accuracy: 0.5351 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.6960 - accuracy: 0.5440 - precision: 0.5556 - recall: 0.0155 - val_loss: 0.6930 - val_accuracy: 0.5417 - val_precision: 0.5833 - val_recall: 0.0332\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.6984 - accuracy: 0.5404 - precision: 0.3846 - recall: 0.0078 - val_loss: 0.6911 - val_accuracy: 0.5373 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.6953 - accuracy: 0.5426 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6909 - val_accuracy: 0.5373 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 0.6960 - accuracy: 0.5426 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6908 - val_accuracy: 0.5373 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 0.6964 - accuracy: 0.5426 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6907 - val_accuracy: 0.5373 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 0.6957 - accuracy: 0.5426 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6907 - val_accuracy: 0.5373 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 0.6967 - accuracy: 0.5426 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6910 - val_accuracy: 0.5373 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 0.6960 - accuracy: 0.5418 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6913 - val_accuracy: 0.5373 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 0.6959 - accuracy: 0.5418 - precision: 0.3333 - recall: 0.0016 - val_loss: 0.6912 - val_accuracy: 0.5373 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 0.6952 - accuracy: 0.5390 - precision: 0.2727 - recall: 0.0047 - val_loss: 0.6912 - val_accuracy: 0.5351 - val_precision: 0.4000 - val_recall: 0.0095\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 0.6969 - accuracy: 0.5411 - precision: 0.4500 - recall: 0.0140 - val_loss: 0.6913 - val_accuracy: 0.5351 - val_precision: 0.4000 - val_recall: 0.0095\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 0.6957 - accuracy: 0.5340 - precision: 0.4032 - recall: 0.0388 - val_loss: 0.6924 - val_accuracy: 0.5263 - val_precision: 0.4528 - val_recall: 0.1137\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 0.6946 - accuracy: 0.5468 - precision: 0.5138 - recall: 0.1736 - val_loss: 0.7024 - val_accuracy: 0.4671 - val_precision: 0.4429 - val_recall: 0.5877\n",
      "Epoch 19/50\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 0.6944 - accuracy: 0.5496 - precision: 0.5128 - recall: 0.3116 - val_loss: 0.7000 - val_accuracy: 0.4956 - val_precision: 0.4589 - val_recall: 0.5024\n",
      "Epoch 20/50\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.6942 - accuracy: 0.5426 - precision: 0.5000 - recall: 0.3101 - val_loss: 0.7427 - val_accuracy: 0.4781 - val_precision: 0.4577 - val_recall: 0.6919\n",
      "Epoch 21/50\n",
      "10/12 [========================>.....] - ETA: 0s - loss: 0.6937 - accuracy: 0.5430 - precision: 0.5055 - recall: 0.3881Restoring model weights from the end of the best epoch: 11.\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 0.6914 - accuracy: 0.5489 - precision: 0.5087 - recall: 0.4078 - val_loss: 0.7470 - val_accuracy: 0.4825 - val_precision: 0.4593 - val_recall: 0.6682\n",
      "Epoch 21: early stopping\n",
      "Now fitting model: LSTM_model_arch_22\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Dense_start_1 (Dense)       (None, 21, 96)            9312      \n",
      "                                                                 \n",
      " Dense_start_2 (Dense)       (None, 21, 40)            3880      \n",
      "                                                                 \n",
      " LSTM1 (LSTM)                (None, 21, 20)            4880      \n",
      "                                                                 \n",
      " Dropout1 (Dropout)          (None, 21, 20)            0         \n",
      "                                                                 \n",
      " LSTM2 (LSTM)                (None, 21, 10)            1240      \n",
      "                                                                 \n",
      " Dropout2 (Dropout)          (None, 21, 10)            0         \n",
      "                                                                 \n",
      " LSTM3 (LSTM)                (None, 10)                840       \n",
      "                                                                 \n",
      " Output (Dense)              (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20163 (78.76 KB)\n",
      "Trainable params: 20163 (78.76 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 2s 60ms/step - loss: 0.7057 - accuracy: 0.4844 - precision: 0.4458 - recall: 0.5225 - val_loss: 0.7084 - val_accuracy: 0.4868 - val_precision: 0.4268 - val_recall: 0.3175\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.7037 - accuracy: 0.5319 - precision: 0.4780 - recall: 0.2527 - val_loss: 0.7080 - val_accuracy: 0.4868 - val_precision: 0.4493 - val_recall: 0.4834\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.7019 - accuracy: 0.5014 - precision: 0.4361 - recall: 0.3070 - val_loss: 0.7212 - val_accuracy: 0.5241 - val_precision: 0.4835 - val_recall: 0.4171\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.7325 - accuracy: 0.5348 - precision: 0.4902 - recall: 0.4264 - val_loss: 0.7032 - val_accuracy: 0.5088 - val_precision: 0.4785 - val_recall: 0.6872\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 1s 26ms/step - loss: 0.7226 - accuracy: 0.5092 - precision: 0.4673 - recall: 0.5209 - val_loss: 0.6928 - val_accuracy: 0.5241 - val_precision: 0.4860 - val_recall: 0.4929\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.7038 - accuracy: 0.5028 - precision: 0.4595 - recall: 0.4930 - val_loss: 0.6947 - val_accuracy: 0.5285 - val_precision: 0.4762 - val_recall: 0.1896\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.7184 - accuracy: 0.5262 - precision: 0.4637 - recall: 0.2279 - val_loss: 0.6936 - val_accuracy: 0.5417 - val_precision: 0.5122 - val_recall: 0.1991\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 1s 41ms/step - loss: 0.6993 - accuracy: 0.5305 - precision: 0.4638 - recall: 0.1690 - val_loss: 0.6907 - val_accuracy: 0.5285 - val_precision: 0.4474 - val_recall: 0.0806\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.6997 - accuracy: 0.5333 - precision: 0.4532 - recall: 0.0977 - val_loss: 0.6895 - val_accuracy: 0.5307 - val_precision: 0.4571 - val_recall: 0.0758\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.7063 - accuracy: 0.5156 - precision: 0.4040 - recall: 0.1240 - val_loss: 0.6897 - val_accuracy: 0.5417 - val_precision: 0.5263 - val_recall: 0.0948\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.7174 - accuracy: 0.5411 - precision: 0.4947 - recall: 0.1442 - val_loss: 0.6900 - val_accuracy: 0.5592 - val_precision: 0.5962 - val_recall: 0.1469\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 0.6949 - accuracy: 0.5355 - precision: 0.4747 - recall: 0.1457 - val_loss: 0.6907 - val_accuracy: 0.5570 - val_precision: 0.5616 - val_recall: 0.1943\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 0.6978 - accuracy: 0.5213 - precision: 0.4318 - recall: 0.1473 - val_loss: 0.6911 - val_accuracy: 0.5504 - val_precision: 0.5500 - val_recall: 0.1564\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.6967 - accuracy: 0.5362 - precision: 0.4789 - recall: 0.1581 - val_loss: 0.6927 - val_accuracy: 0.5482 - val_precision: 0.5342 - val_recall: 0.1848\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.7011 - accuracy: 0.5319 - precision: 0.4713 - recall: 0.1907 - val_loss: 0.6942 - val_accuracy: 0.5307 - val_precision: 0.4867 - val_recall: 0.2607\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 0.6979 - accuracy: 0.5340 - precision: 0.4844 - recall: 0.2884 - val_loss: 0.7008 - val_accuracy: 0.5329 - val_precision: 0.4931 - val_recall: 0.3365\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.6989 - accuracy: 0.5397 - precision: 0.4948 - recall: 0.2961 - val_loss: 0.6966 - val_accuracy: 0.5219 - val_precision: 0.4748 - val_recall: 0.3128\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.6960 - accuracy: 0.5262 - precision: 0.4759 - recall: 0.3519 - val_loss: 0.6947 - val_accuracy: 0.5088 - val_precision: 0.4673 - val_recall: 0.4408\n",
      "Epoch 19/50\n",
      "11/12 [==========================>...] - ETA: 0s - loss: 0.6996 - accuracy: 0.5447 - precision: 0.5054 - recall: 0.2915Restoring model weights from the end of the best epoch: 9.\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.6988 - accuracy: 0.5454 - precision: 0.5054 - recall: 0.2915 - val_loss: 0.7021 - val_accuracy: 0.4890 - val_precision: 0.4545 - val_recall: 0.5213\n",
      "Epoch 19: early stopping\n",
      "Now fitting model: LSTM_model_arch_23\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Dense_start_1 (Dense)       (None, 21, 199)           39800     \n",
      "                                                                 \n",
      " Dense_start_2 (Dense)       (None, 21, 80)            16000     \n",
      "                                                                 \n",
      " Dense_start_3 (Dense)       (None, 21, 40)            3240      \n",
      "                                                                 \n",
      " LSTM1 (LSTM)                (None, 21, 20)            4880      \n",
      "                                                                 \n",
      " Dropout1 (Dropout)          (None, 21, 20)            0         \n",
      "                                                                 \n",
      " LSTM2 (LSTM)                (None, 21, 10)            1240      \n",
      "                                                                 \n",
      " Dropout2 (Dropout)          (None, 21, 10)            0         \n",
      "                                                                 \n",
      " LSTM3 (LSTM)                (None, 10)                840       \n",
      "                                                                 \n",
      " Output (Dense)              (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66011 (257.86 KB)\n",
      "Trainable params: 66011 (257.86 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 2s 45ms/step - loss: 0.8397 - accuracy: 0.4943 - precision: 0.4500 - recall: 0.4744 - val_loss: 0.7495 - val_accuracy: 0.5197 - val_precision: 0.4835 - val_recall: 0.5545\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 1.1854 - accuracy: 0.5170 - precision: 0.4782 - recall: 0.6124 - val_loss: 0.7156 - val_accuracy: 0.4671 - val_precision: 0.4583 - val_recall: 0.8341\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 42ms/step - loss: 0.7661 - accuracy: 0.4809 - precision: 0.4460 - recall: 0.5566 - val_loss: 0.6990 - val_accuracy: 0.4649 - val_precision: 0.4622 - val_recall: 0.9573\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 0.7081 - accuracy: 0.5305 - precision: 0.4397 - recall: 0.0961 - val_loss: 0.6941 - val_accuracy: 0.5066 - val_precision: 0.4660 - val_recall: 0.4550\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 0.7031 - accuracy: 0.5355 - precision: 0.3864 - recall: 0.0264 - val_loss: 0.6925 - val_accuracy: 0.5219 - val_precision: 0.4407 - val_recall: 0.1232\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 42ms/step - loss: 0.6994 - accuracy: 0.5376 - precision: 0.4255 - recall: 0.0310 - val_loss: 0.6927 - val_accuracy: 0.5175 - val_precision: 0.4262 - val_recall: 0.1232\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 0.7000 - accuracy: 0.5369 - precision: 0.4310 - recall: 0.0388 - val_loss: 0.6926 - val_accuracy: 0.5351 - val_precision: 0.4884 - val_recall: 0.0995\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.6987 - accuracy: 0.5348 - precision: 0.4225 - recall: 0.0465 - val_loss: 0.6922 - val_accuracy: 0.5241 - val_precision: 0.2500 - val_recall: 0.0142\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.6974 - accuracy: 0.5355 - precision: 0.4405 - recall: 0.0574 - val_loss: 0.6925 - val_accuracy: 0.5263 - val_precision: 0.3333 - val_recall: 0.0237\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 1s 44ms/step - loss: 0.6986 - accuracy: 0.5234 - precision: 0.3714 - recall: 0.0605 - val_loss: 0.6926 - val_accuracy: 0.5329 - val_precision: 0.4444 - val_recall: 0.0379\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 0.6972 - accuracy: 0.5333 - precision: 0.4532 - recall: 0.0977 - val_loss: 0.6931 - val_accuracy: 0.5197 - val_precision: 0.3750 - val_recall: 0.0569\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 0.6970 - accuracy: 0.5426 - precision: 0.5000 - recall: 0.1535 - val_loss: 0.6938 - val_accuracy: 0.5285 - val_precision: 0.4474 - val_recall: 0.0806\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 0s 26ms/step - loss: 0.6981 - accuracy: 0.5220 - precision: 0.4367 - recall: 0.1550 - val_loss: 0.6936 - val_accuracy: 0.5285 - val_precision: 0.4565 - val_recall: 0.0995\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 0.6956 - accuracy: 0.5362 - precision: 0.4848 - recall: 0.2233 - val_loss: 0.6931 - val_accuracy: 0.5219 - val_precision: 0.4286 - val_recall: 0.0995\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 0.6972 - accuracy: 0.5433 - precision: 0.5016 - recall: 0.2465 - val_loss: 0.7035 - val_accuracy: 0.5241 - val_precision: 0.4605 - val_recall: 0.1659\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 0s 26ms/step - loss: 0.7287 - accuracy: 0.5199 - precision: 0.4560 - recall: 0.2574 - val_loss: 0.6921 - val_accuracy: 0.5504 - val_precision: 0.5625 - val_recall: 0.1280\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 1s 48ms/step - loss: 0.7038 - accuracy: 0.5340 - precision: 0.4250 - recall: 0.0527 - val_loss: 0.6915 - val_accuracy: 0.5373 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 0.6999 - accuracy: 0.5390 - precision: 0.3529 - recall: 0.0093 - val_loss: 0.6906 - val_accuracy: 0.5373 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 19/50\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 0.6971 - accuracy: 0.5355 - precision: 0.3214 - recall: 0.0140 - val_loss: 0.6905 - val_accuracy: 0.5373 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 20/50\n",
      "12/12 [==============================] - 1s 48ms/step - loss: 0.6958 - accuracy: 0.5418 - precision: 0.4940 - recall: 0.0636 - val_loss: 0.6909 - val_accuracy: 0.5351 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 21/50\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 0.6968 - accuracy: 0.5312 - precision: 0.4429 - recall: 0.0961 - val_loss: 0.6911 - val_accuracy: 0.5329 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 22/50\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 0.6962 - accuracy: 0.5390 - precision: 0.4818 - recall: 0.1023 - val_loss: 0.6909 - val_accuracy: 0.5373 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 23/50\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 0.6957 - accuracy: 0.5355 - precision: 0.4561 - recall: 0.0806 - val_loss: 0.6914 - val_accuracy: 0.5329 - val_precision: 0.2500 - val_recall: 0.0047\n",
      "Epoch 24/50\n",
      "12/12 [==============================] - 0s 42ms/step - loss: 0.6955 - accuracy: 0.5390 - precision: 0.4884 - recall: 0.1628 - val_loss: 0.6925 - val_accuracy: 0.5263 - val_precision: 0.4324 - val_recall: 0.0758\n",
      "Epoch 25/50\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 0.6986 - accuracy: 0.5135 - precision: 0.4238 - recall: 0.1767 - val_loss: 0.6920 - val_accuracy: 0.5263 - val_precision: 0.2222 - val_recall: 0.0095\n",
      "Epoch 26/50\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 0.6987 - accuracy: 0.5227 - precision: 0.4157 - recall: 0.1070 - val_loss: 0.6916 - val_accuracy: 0.5329 - val_precision: 0.2500 - val_recall: 0.0047\n",
      "Epoch 27/50\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 0.6958 - accuracy: 0.5567 - precision: 0.5481 - recall: 0.1767 - val_loss: 0.6920 - val_accuracy: 0.5263 - val_precision: 0.2222 - val_recall: 0.0095\n",
      "Epoch 28/50\n",
      "12/12 [==============================] - 0s 26ms/step - loss: 0.6958 - accuracy: 0.5411 - precision: 0.4947 - recall: 0.1442 - val_loss: 0.6917 - val_accuracy: 0.5307 - val_precision: 0.2000 - val_recall: 0.0047\n",
      "Epoch 29/50\n",
      "10/12 [========================>.....] - ETA: 0s - loss: 0.6988 - accuracy: 0.5305 - precision: 0.4706 - recall: 0.1492Restoring model weights from the end of the best epoch: 19.\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 0.6976 - accuracy: 0.5326 - precision: 0.4646 - recall: 0.1426 - val_loss: 0.6911 - val_accuracy: 0.5285 - val_precision: 0.1667 - val_recall: 0.0047\n",
      "Epoch 29: early stopping\n",
      "Now fitting model: LSTM_model_arch_23\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Dense_start_1 (Dense)       (None, 21, 96)            9312      \n",
      "                                                                 \n",
      " Dense_start_2 (Dense)       (None, 21, 80)            7760      \n",
      "                                                                 \n",
      " Dense_start_3 (Dense)       (None, 21, 40)            3240      \n",
      "                                                                 \n",
      " LSTM1 (LSTM)                (None, 21, 20)            4880      \n",
      "                                                                 \n",
      " Dropout1 (Dropout)          (None, 21, 20)            0         \n",
      "                                                                 \n",
      " LSTM2 (LSTM)                (None, 21, 10)            1240      \n",
      "                                                                 \n",
      " Dropout2 (Dropout)          (None, 21, 10)            0         \n",
      "                                                                 \n",
      " LSTM3 (LSTM)                (None, 10)                840       \n",
      "                                                                 \n",
      " Output (Dense)              (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 27283 (106.57 KB)\n",
      "Trainable params: 27283 (106.57 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 3s 69ms/step - loss: 1.9469 - accuracy: 0.5241 - precision: 0.4780 - recall: 0.4388 - val_loss: 0.6930 - val_accuracy: 0.5175 - val_precision: 0.4676 - val_recall: 0.3081\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.7092 - accuracy: 0.5184 - precision: 0.4497 - recall: 0.2357 - val_loss: 0.6924 - val_accuracy: 0.5395 - val_precision: 0.5200 - val_recall: 0.0616\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 0.6938 - accuracy: 0.5397 - precision: 0.4885 - recall: 0.1318 - val_loss: 0.6917 - val_accuracy: 0.5175 - val_precision: 0.4211 - val_recall: 0.1137\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.6984 - accuracy: 0.5241 - precision: 0.4409 - recall: 0.1504 - val_loss: 0.6954 - val_accuracy: 0.5110 - val_precision: 0.3800 - val_recall: 0.0900\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.6965 - accuracy: 0.5482 - precision: 0.5152 - recall: 0.2109 - val_loss: 0.6905 - val_accuracy: 0.5263 - val_precision: 0.4603 - val_recall: 0.1374\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.7061 - accuracy: 0.5177 - precision: 0.4465 - recall: 0.2264 - val_loss: 0.6977 - val_accuracy: 0.5285 - val_precision: 0.4787 - val_recall: 0.2133\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 0.6946 - accuracy: 0.5050 - precision: 0.4672 - recall: 0.5845 - val_loss: 0.6930 - val_accuracy: 0.4912 - val_precision: 0.4407 - val_recall: 0.3697\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 0.6906 - accuracy: 0.5184 - precision: 0.4743 - recall: 0.4868 - val_loss: 0.6952 - val_accuracy: 0.4956 - val_precision: 0.4228 - val_recall: 0.2464\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.6900 - accuracy: 0.5305 - precision: 0.4887 - recall: 0.5705 - val_loss: 0.6902 - val_accuracy: 0.4934 - val_precision: 0.4524 - val_recall: 0.4502\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.6936 - accuracy: 0.5284 - precision: 0.4869 - recall: 0.5752 - val_loss: 0.6955 - val_accuracy: 0.4912 - val_precision: 0.4529 - val_recall: 0.4787\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 0.6939 - accuracy: 0.5262 - precision: 0.4857 - recall: 0.6062 - val_loss: 0.6912 - val_accuracy: 0.4846 - val_precision: 0.4348 - val_recall: 0.3791\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 1s 41ms/step - loss: 0.6925 - accuracy: 0.5525 - precision: 0.5147 - recall: 0.3798 - val_loss: 0.7022 - val_accuracy: 0.5000 - val_precision: 0.4514 - val_recall: 0.3744\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 0.6863 - accuracy: 0.5518 - precision: 0.5086 - recall: 0.5938 - val_loss: 0.7154 - val_accuracy: 0.5110 - val_precision: 0.4694 - val_recall: 0.4360\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 0.6940 - accuracy: 0.5312 - precision: 0.4881 - recall: 0.5085 - val_loss: 0.7270 - val_accuracy: 0.5110 - val_precision: 0.4659 - val_recall: 0.3886\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 0.6867 - accuracy: 0.5262 - precision: 0.4831 - recall: 0.5101 - val_loss: 0.7085 - val_accuracy: 0.5132 - val_precision: 0.4709 - val_recall: 0.4218\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.6879 - accuracy: 0.5532 - precision: 0.5132 - recall: 0.4527 - val_loss: 0.7204 - val_accuracy: 0.5175 - val_precision: 0.4816 - val_recall: 0.5592\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 0.6810 - accuracy: 0.5631 - precision: 0.5253 - recall: 0.4667 - val_loss: 0.7292 - val_accuracy: 0.5175 - val_precision: 0.4749 - val_recall: 0.4028\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 0.7039 - accuracy: 0.5567 - precision: 0.5209 - recall: 0.3860 - val_loss: 0.7580 - val_accuracy: 0.5088 - val_precision: 0.4663 - val_recall: 0.4265\n",
      "Epoch 19/50\n",
      "10/12 [========================>.....] - ETA: 0s - loss: 0.6988 - accuracy: 0.5445 - precision: 0.5142 - recall: 0.2153Restoring model weights from the end of the best epoch: 9.\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 0.7160 - accuracy: 0.5539 - precision: 0.5278 - recall: 0.2357 - val_loss: 0.6944 - val_accuracy: 0.5197 - val_precision: 0.4843 - val_recall: 0.5829\n",
      "Epoch 19: early stopping\n",
      "Now fitting model: LSTM_model_arch_24\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Dense_start_1 (Dense)       (None, 21, 199)           39800     \n",
      "                                                                 \n",
      " Dense_start_2 (Dense)       (None, 21, 40)            8000      \n",
      "                                                                 \n",
      " LSTM1 (LSTM)                (None, 21, 20)            4880      \n",
      "                                                                 \n",
      " Dropout1 (Dropout)          (None, 21, 20)            0         \n",
      "                                                                 \n",
      " LSTM2 (LSTM)                (None, 21, 10)            1240      \n",
      "                                                                 \n",
      " Dropout2 (Dropout)          (None, 21, 10)            0         \n",
      "                                                                 \n",
      " LSTM3 (LSTM)                (None, 7)                 504       \n",
      "                                                                 \n",
      " Dense_end_1 (Dense)         (None, 5)                 40        \n",
      "                                                                 \n",
      " Output (Dense)              (None, 1)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 54470 (212.77 KB)\n",
      "Trainable params: 54470 (212.77 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 2s 44ms/step - loss: 1.3049 - accuracy: 0.5199 - precision: 0.4689 - recall: 0.3736 - val_loss: 0.6956 - val_accuracy: 0.5066 - val_precision: 0.4814 - val_recall: 0.8578\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 0.7272 - accuracy: 0.5050 - precision: 0.4514 - recall: 0.3814 - val_loss: 0.7046 - val_accuracy: 0.4649 - val_precision: 0.4489 - val_recall: 0.6872\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.7071 - accuracy: 0.5305 - precision: 0.4841 - recall: 0.4000 - val_loss: 0.7050 - val_accuracy: 0.4627 - val_precision: 0.4388 - val_recall: 0.5782\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.7055 - accuracy: 0.5348 - precision: 0.4848 - recall: 0.2713 - val_loss: 0.7098 - val_accuracy: 0.5044 - val_precision: 0.4607 - val_recall: 0.4171\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.7781 - accuracy: 0.4965 - precision: 0.4129 - recall: 0.2388 - val_loss: 0.7302 - val_accuracy: 0.4649 - val_precision: 0.4267 - val_recall: 0.4550\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.7974 - accuracy: 0.5340 - precision: 0.4776 - recall: 0.1984 - val_loss: 0.6994 - val_accuracy: 0.5263 - val_precision: 0.4886 - val_recall: 0.5071\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.7025 - accuracy: 0.5241 - precision: 0.4398 - recall: 0.1473 - val_loss: 0.6942 - val_accuracy: 0.5044 - val_precision: 0.4664 - val_recall: 0.4929\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.7002 - accuracy: 0.5262 - precision: 0.4588 - recall: 0.1984 - val_loss: 0.6933 - val_accuracy: 0.5088 - val_precision: 0.4703 - val_recall: 0.4882\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 0.7071 - accuracy: 0.5149 - precision: 0.4438 - recall: 0.2388 - val_loss: 0.6919 - val_accuracy: 0.5044 - val_precision: 0.4651 - val_recall: 0.4739\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 0.7079 - accuracy: 0.5064 - precision: 0.4220 - recall: 0.2140 - val_loss: 0.6947 - val_accuracy: 0.5132 - val_precision: 0.4729 - val_recall: 0.4550\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 1s 44ms/step - loss: 0.7167 - accuracy: 0.5163 - precision: 0.4337 - recall: 0.1876 - val_loss: 0.6858 - val_accuracy: 0.5395 - val_precision: 0.5043 - val_recall: 0.2796\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 0.7059 - accuracy: 0.5319 - precision: 0.4634 - recall: 0.1473 - val_loss: 0.6896 - val_accuracy: 0.5461 - val_precision: 0.5357 - val_recall: 0.1422\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 0.7177 - accuracy: 0.5255 - precision: 0.4250 - recall: 0.1054 - val_loss: 0.6969 - val_accuracy: 0.5482 - val_precision: 0.5258 - val_recall: 0.2417\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 0.7085 - accuracy: 0.5411 - precision: 0.4954 - recall: 0.1674 - val_loss: 0.7144 - val_accuracy: 0.5197 - val_precision: 0.4412 - val_recall: 0.1422\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 0.7054 - accuracy: 0.5355 - precision: 0.4671 - recall: 0.1101 - val_loss: 0.6944 - val_accuracy: 0.5373 - val_precision: 0.5000 - val_recall: 0.0190\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 0.7338 - accuracy: 0.5312 - precision: 0.4506 - recall: 0.1132 - val_loss: 0.6904 - val_accuracy: 0.5373 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 0.7371 - accuracy: 0.5277 - precision: 0.4255 - recall: 0.0930 - val_loss: 0.6905 - val_accuracy: 0.5395 - val_precision: 1.0000 - val_recall: 0.0047\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - 0s 27ms/step - loss: 0.7065 - accuracy: 0.5156 - precision: 0.3967 - recall: 0.1132 - val_loss: 0.6907 - val_accuracy: 0.5417 - val_precision: 1.0000 - val_recall: 0.0095\n",
      "Epoch 19/50\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.6983 - accuracy: 0.5213 - precision: 0.4235 - recall: 0.1287 - val_loss: 0.6893 - val_accuracy: 0.5417 - val_precision: 1.0000 - val_recall: 0.0095\n",
      "Epoch 20/50\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 0.6997 - accuracy: 0.5461 - precision: 0.5238 - recall: 0.0853 - val_loss: 0.6903 - val_accuracy: 0.5417 - val_precision: 1.0000 - val_recall: 0.0095\n",
      "Epoch 21/50\n",
      "10/12 [========================>.....] - ETA: 0s - loss: 0.6950 - accuracy: 0.5484 - precision: 0.5714 - recall: 0.0814Restoring model weights from the end of the best epoch: 11.\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 0.6974 - accuracy: 0.5454 - precision: 0.5200 - recall: 0.0806 - val_loss: 0.6902 - val_accuracy: 0.5395 - val_precision: 1.0000 - val_recall: 0.0047\n",
      "Epoch 21: early stopping\n",
      "Now fitting model: LSTM_model_arch_24\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Dense_start_1 (Dense)       (None, 21, 96)            9312      \n",
      "                                                                 \n",
      " Dense_start_2 (Dense)       (None, 21, 40)            3880      \n",
      "                                                                 \n",
      " LSTM1 (LSTM)                (None, 21, 20)            4880      \n",
      "                                                                 \n",
      " Dropout1 (Dropout)          (None, 21, 20)            0         \n",
      "                                                                 \n",
      " LSTM2 (LSTM)                (None, 21, 10)            1240      \n",
      "                                                                 \n",
      " Dropout2 (Dropout)          (None, 21, 10)            0         \n",
      "                                                                 \n",
      " LSTM3 (LSTM)                (None, 7)                 504       \n",
      "                                                                 \n",
      " Dense_end_1 (Dense)         (None, 5)                 40        \n",
      "                                                                 \n",
      " Output (Dense)              (None, 1)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19862 (77.59 KB)\n",
      "Trainable params: 19862 (77.59 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 2s 42ms/step - loss: 0.7054 - accuracy: 0.4922 - precision: 0.4441 - recall: 0.4372 - val_loss: 0.6975 - val_accuracy: 0.4825 - val_precision: 0.4454 - val_recall: 0.4834\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 0.6940 - accuracy: 0.5326 - precision: 0.4802 - recall: 0.2636 - val_loss: 0.6955 - val_accuracy: 0.5000 - val_precision: 0.4573 - val_recall: 0.4313\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.6941 - accuracy: 0.5411 - precision: 0.4979 - recall: 0.3643 - val_loss: 0.6968 - val_accuracy: 0.5132 - val_precision: 0.4455 - val_recall: 0.2133\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.6968 - accuracy: 0.5362 - precision: 0.4878 - recall: 0.2791 - val_loss: 0.7127 - val_accuracy: 0.4298 - val_precision: 0.4241 - val_recall: 0.6493\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.7020 - accuracy: 0.5461 - precision: 0.5031 - recall: 0.6248 - val_loss: 0.7157 - val_accuracy: 0.4408 - val_precision: 0.4447 - val_recall: 0.8389\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 0.6862 - accuracy: 0.5234 - precision: 0.4843 - recall: 0.6450 - val_loss: 0.7004 - val_accuracy: 0.4934 - val_precision: 0.4635 - val_recall: 0.6019\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.7034 - accuracy: 0.5411 - precision: 0.4981 - recall: 0.4031 - val_loss: 0.7002 - val_accuracy: 0.5044 - val_precision: 0.4157 - val_recall: 0.1754\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.7000 - accuracy: 0.5553 - precision: 0.5280 - recall: 0.2636 - val_loss: 0.6998 - val_accuracy: 0.5044 - val_precision: 0.4672 - val_recall: 0.5071\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.7006 - accuracy: 0.5603 - precision: 0.5264 - recall: 0.3860 - val_loss: 0.7012 - val_accuracy: 0.5439 - val_precision: 0.5118 - val_recall: 0.3081\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.6928 - accuracy: 0.5362 - precision: 0.4933 - recall: 0.5116 - val_loss: 0.7462 - val_accuracy: 0.5175 - val_precision: 0.4651 - val_recall: 0.2844\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 0.7183 - accuracy: 0.5433 - precision: 0.5008 - recall: 0.5163 - val_loss: 0.7293 - val_accuracy: 0.5373 - val_precision: 0.5000 - val_recall: 0.2180\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 0.7121 - accuracy: 0.5156 - precision: 0.4720 - recall: 0.4961 - val_loss: 0.6951 - val_accuracy: 0.5132 - val_precision: 0.4732 - val_recall: 0.4597\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.7003 - accuracy: 0.5085 - precision: 0.4652 - recall: 0.4977 - val_loss: 0.6945 - val_accuracy: 0.5088 - val_precision: 0.4611 - val_recall: 0.3649\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.7193 - accuracy: 0.5000 - precision: 0.4488 - recall: 0.4078 - val_loss: 0.7006 - val_accuracy: 0.5000 - val_precision: 0.4479 - val_recall: 0.3460\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.6982 - accuracy: 0.5156 - precision: 0.4597 - recall: 0.3364 - val_loss: 0.6976 - val_accuracy: 0.5241 - val_precision: 0.4837 - val_recall: 0.4218\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 0.7454 - accuracy: 0.5390 - precision: 0.4967 - recall: 0.5829 - val_loss: 0.8740 - val_accuracy: 0.5197 - val_precision: 0.4556 - val_recall: 0.1943\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.7210 - accuracy: 0.4837 - precision: 0.4359 - recall: 0.4372 - val_loss: 0.6911 - val_accuracy: 0.5395 - val_precision: 0.5044 - val_recall: 0.2701\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.6989 - accuracy: 0.5319 - precision: 0.4483 - recall: 0.1008 - val_loss: 0.6909 - val_accuracy: 0.5373 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 19/50\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.6997 - accuracy: 0.5411 - precision: 0.4000 - recall: 0.0062 - val_loss: 0.6905 - val_accuracy: 0.5373 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 20/50\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.6993 - accuracy: 0.5447 - precision: 0.5556 - recall: 0.0233 - val_loss: 0.6903 - val_accuracy: 0.5373 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 21/50\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.6977 - accuracy: 0.5390 - precision: 0.4545 - recall: 0.0388 - val_loss: 0.6902 - val_accuracy: 0.5373 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 22/50\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.6981 - accuracy: 0.5397 - precision: 0.4762 - recall: 0.0620 - val_loss: 0.6901 - val_accuracy: 0.5373 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 23/50\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.6957 - accuracy: 0.5376 - precision: 0.4715 - recall: 0.0899 - val_loss: 0.6909 - val_accuracy: 0.5263 - val_precision: 0.1429 - val_recall: 0.0047\n",
      "Epoch 24/50\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.6952 - accuracy: 0.5404 - precision: 0.4876 - recall: 0.0915 - val_loss: 0.6914 - val_accuracy: 0.5307 - val_precision: 0.3636 - val_recall: 0.0190\n",
      "Epoch 25/50\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.6970 - accuracy: 0.5404 - precision: 0.4912 - recall: 0.1302 - val_loss: 0.6913 - val_accuracy: 0.5285 - val_precision: 0.3333 - val_recall: 0.0190\n",
      "Epoch 26/50\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 0.6965 - accuracy: 0.5348 - precision: 0.4734 - recall: 0.1519 - val_loss: 0.6921 - val_accuracy: 0.5329 - val_precision: 0.4286 - val_recall: 0.0284\n",
      "Epoch 27/50\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.6967 - accuracy: 0.5454 - precision: 0.5078 - recall: 0.2016 - val_loss: 0.6927 - val_accuracy: 0.5351 - val_precision: 0.4815 - val_recall: 0.0616\n",
      "Epoch 28/50\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.6966 - accuracy: 0.5440 - precision: 0.5043 - recall: 0.1814 - val_loss: 0.6938 - val_accuracy: 0.5285 - val_precision: 0.4714 - val_recall: 0.1564\n",
      "Epoch 29/50\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.6963 - accuracy: 0.5426 - precision: 0.5000 - recall: 0.2868 - val_loss: 0.6888 - val_accuracy: 0.5439 - val_precision: 0.5231 - val_recall: 0.1611\n",
      "Epoch 30/50\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 0.6995 - accuracy: 0.5312 - precision: 0.4792 - recall: 0.2853 - val_loss: 0.6899 - val_accuracy: 0.5417 - val_precision: 0.5200 - val_recall: 0.1232\n",
      "Epoch 31/50\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.6982 - accuracy: 0.5376 - precision: 0.4914 - recall: 0.3101 - val_loss: 0.6907 - val_accuracy: 0.5461 - val_precision: 0.5625 - val_recall: 0.0853\n",
      "Epoch 32/50\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.7053 - accuracy: 0.5319 - precision: 0.4798 - recall: 0.2760 - val_loss: 0.6951 - val_accuracy: 0.5175 - val_precision: 0.4400 - val_recall: 0.1564\n",
      "Epoch 33/50\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.6961 - accuracy: 0.5206 - precision: 0.4693 - recall: 0.3674 - val_loss: 0.6926 - val_accuracy: 0.5241 - val_precision: 0.4625 - val_recall: 0.1754\n",
      "Epoch 34/50\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 0.7037 - accuracy: 0.5262 - precision: 0.4755 - recall: 0.3457 - val_loss: 0.6919 - val_accuracy: 0.5263 - val_precision: 0.4658 - val_recall: 0.1611\n",
      "Epoch 35/50\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.7007 - accuracy: 0.5255 - precision: 0.4751 - recall: 0.3550 - val_loss: 0.6961 - val_accuracy: 0.4846 - val_precision: 0.4277 - val_recall: 0.3365\n",
      "Epoch 36/50\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.6964 - accuracy: 0.5277 - precision: 0.4814 - recall: 0.4217 - val_loss: 0.6957 - val_accuracy: 0.5110 - val_precision: 0.4600 - val_recall: 0.3270\n",
      "Epoch 37/50\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.6975 - accuracy: 0.5362 - precision: 0.4899 - recall: 0.3380 - val_loss: 0.6954 - val_accuracy: 0.5154 - val_precision: 0.4457 - val_recall: 0.1943\n",
      "Epoch 38/50\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.8046 - accuracy: 0.5220 - precision: 0.4473 - recall: 0.1907 - val_loss: 0.6908 - val_accuracy: 0.5219 - val_precision: 0.4545 - val_recall: 0.1659\n",
      "Epoch 39/50\n",
      "11/12 [==========================>...] - ETA: 0s - loss: 0.6995 - accuracy: 0.5362 - precision: 0.4459 - recall: 0.0512Restoring model weights from the end of the best epoch: 29.\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 0.6992 - accuracy: 0.5369 - precision: 0.4459 - recall: 0.0512 - val_loss: 0.6925 - val_accuracy: 0.5197 - val_precision: 0.4661 - val_recall: 0.2607\n",
      "Epoch 39: early stopping\n",
      "Now fitting model: LSTM_model_arch_25\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Dense_start_1 (Dense)       (None, 21, 199)           39800     \n",
      "                                                                 \n",
      " Dense_start_2 (Dense)       (None, 21, 80)            16000     \n",
      "                                                                 \n",
      " Dense_start_3 (Dense)       (None, 21, 40)            3240      \n",
      "                                                                 \n",
      " LSTM1 (LSTM)                (None, 21, 20)            4880      \n",
      "                                                                 \n",
      " Dropout1 (Dropout)          (None, 21, 20)            0         \n",
      "                                                                 \n",
      " LSTM2 (LSTM)                (None, 21, 10)            1240      \n",
      "                                                                 \n",
      " Dropout2 (Dropout)          (None, 21, 10)            0         \n",
      "                                                                 \n",
      " LSTM3 (LSTM)                (None, 10)                840       \n",
      "                                                                 \n",
      " Dense_end_1 (Dense)         (None, 5)                 55        \n",
      "                                                                 \n",
      " Output (Dense)              (None, 1)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66061 (258.05 KB)\n",
      "Trainable params: 66061 (258.05 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 3s 62ms/step - loss: 0.8291 - accuracy: 0.5092 - precision: 0.4618 - recall: 0.4403 - val_loss: 0.7267 - val_accuracy: 0.5614 - val_precision: 0.5350 - val_recall: 0.3981\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 0.8228 - accuracy: 0.5092 - precision: 0.4594 - recall: 0.4124 - val_loss: 0.7090 - val_accuracy: 0.5132 - val_precision: 0.4667 - val_recall: 0.3649\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.7220 - accuracy: 0.5312 - precision: 0.4831 - recall: 0.3550 - val_loss: 0.7046 - val_accuracy: 0.5088 - val_precision: 0.4198 - val_recall: 0.1611\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.7319 - accuracy: 0.5113 - precision: 0.4191 - recall: 0.1767 - val_loss: 0.7000 - val_accuracy: 0.5219 - val_precision: 0.4690 - val_recall: 0.2512\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.6966 - accuracy: 0.5177 - precision: 0.4419 - recall: 0.2062 - val_loss: 0.7006 - val_accuracy: 0.4737 - val_precision: 0.4388 - val_recall: 0.4929\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 0.6921 - accuracy: 0.5326 - precision: 0.4676 - recall: 0.1566 - val_loss: 0.6945 - val_accuracy: 0.5154 - val_precision: 0.4432 - val_recall: 0.1848\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.6952 - accuracy: 0.5433 - precision: 0.5034 - recall: 0.1132 - val_loss: 0.6914 - val_accuracy: 0.5417 - val_precision: 0.5179 - val_recall: 0.1374\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.6958 - accuracy: 0.5369 - precision: 0.4677 - recall: 0.0899 - val_loss: 0.6946 - val_accuracy: 0.5110 - val_precision: 0.3966 - val_recall: 0.1090\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 0.6976 - accuracy: 0.5468 - precision: 0.5294 - recall: 0.0837 - val_loss: 0.6967 - val_accuracy: 0.5110 - val_precision: 0.4455 - val_recall: 0.2322\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 1s 44ms/step - loss: 0.6956 - accuracy: 0.5454 - precision: 0.5088 - recall: 0.1783 - val_loss: 0.6958 - val_accuracy: 0.5000 - val_precision: 0.4414 - val_recall: 0.3033\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 0.6972 - accuracy: 0.5440 - precision: 0.5043 - recall: 0.1798 - val_loss: 0.6975 - val_accuracy: 0.4934 - val_precision: 0.4231 - val_recall: 0.2607\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.6930 - accuracy: 0.5695 - precision: 0.5748 - recall: 0.2264 - val_loss: 0.7004 - val_accuracy: 0.4759 - val_precision: 0.4205 - val_recall: 0.3507\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 0.6966 - accuracy: 0.5362 - precision: 0.4871 - recall: 0.2636 - val_loss: 0.7001 - val_accuracy: 0.5110 - val_precision: 0.4651 - val_recall: 0.3791\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 0s 26ms/step - loss: 0.6975 - accuracy: 0.5383 - precision: 0.4928 - recall: 0.3163 - val_loss: 0.7005 - val_accuracy: 0.4934 - val_precision: 0.4425 - val_recall: 0.3649\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 0.7082 - accuracy: 0.5376 - precision: 0.4759 - recall: 0.1070 - val_loss: 0.6949 - val_accuracy: 0.5373 - val_precision: 0.5000 - val_recall: 0.0142\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 0.7261 - accuracy: 0.5277 - precision: 0.4456 - recall: 0.1333 - val_loss: 0.6934 - val_accuracy: 0.5373 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.6960 - accuracy: 0.5440 - precision: 0.5278 - recall: 0.0295      Restoring model weights from the end of the best epoch: 7.\n",
      "12/12 [==============================] - 1s 46ms/step - loss: 0.6960 - accuracy: 0.5440 - precision: 0.5278 - recall: 0.0295 - val_loss: 0.6953 - val_accuracy: 0.5000 - val_precision: 0.4220 - val_recall: 0.2180\n",
      "Epoch 17: early stopping\n",
      "Now fitting model: LSTM_model_arch_25\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Dense_start_1 (Dense)       (None, 21, 96)            9312      \n",
      "                                                                 \n",
      " Dense_start_2 (Dense)       (None, 21, 80)            7760      \n",
      "                                                                 \n",
      " Dense_start_3 (Dense)       (None, 21, 40)            3240      \n",
      "                                                                 \n",
      " LSTM1 (LSTM)                (None, 21, 20)            4880      \n",
      "                                                                 \n",
      " Dropout1 (Dropout)          (None, 21, 20)            0         \n",
      "                                                                 \n",
      " LSTM2 (LSTM)                (None, 21, 10)            1240      \n",
      "                                                                 \n",
      " Dropout2 (Dropout)          (None, 21, 10)            0         \n",
      "                                                                 \n",
      " LSTM3 (LSTM)                (None, 10)                840       \n",
      "                                                                 \n",
      " Dense_end_1 (Dense)         (None, 5)                 55        \n",
      "                                                                 \n",
      " Output (Dense)              (None, 1)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 27333 (106.77 KB)\n",
      "Trainable params: 27333 (106.77 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 2s 43ms/step - loss: 0.7070 - accuracy: 0.5099 - precision: 0.4504 - recall: 0.3240 - val_loss: 0.6963 - val_accuracy: 0.4868 - val_precision: 0.4703 - val_recall: 0.8626\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.6979 - accuracy: 0.4972 - precision: 0.4549 - recall: 0.5008 - val_loss: 0.6926 - val_accuracy: 0.5154 - val_precision: 0.4702 - val_recall: 0.3744\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 27ms/step - loss: 0.6921 - accuracy: 0.5468 - precision: 0.5192 - recall: 0.1256 - val_loss: 0.6907 - val_accuracy: 0.5175 - val_precision: 0.4554 - val_recall: 0.2180\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.7006 - accuracy: 0.5482 - precision: 0.5377 - recall: 0.0884 - val_loss: 0.6911 - val_accuracy: 0.5285 - val_precision: 0.4333 - val_recall: 0.0616\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.6948 - accuracy: 0.5447 - precision: 0.5246 - recall: 0.0496 - val_loss: 0.6902 - val_accuracy: 0.5526 - val_precision: 0.5614 - val_recall: 0.1517\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.6952 - accuracy: 0.5383 - precision: 0.4789 - recall: 0.1054 - val_loss: 0.6985 - val_accuracy: 0.5110 - val_precision: 0.4634 - val_recall: 0.3602\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 0.6962 - accuracy: 0.5184 - precision: 0.4647 - recall: 0.3473 - val_loss: 0.6970 - val_accuracy: 0.4868 - val_precision: 0.4343 - val_recall: 0.3602\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.6924 - accuracy: 0.5525 - precision: 0.5232 - recall: 0.2450 - val_loss: 0.7131 - val_accuracy: 0.4868 - val_precision: 0.4148 - val_recall: 0.2654\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.6920 - accuracy: 0.5624 - precision: 0.5310 - recall: 0.3721 - val_loss: 0.7096 - val_accuracy: 0.4846 - val_precision: 0.3776 - val_recall: 0.1754\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.6960 - accuracy: 0.5532 - precision: 0.5155 - recall: 0.3860 - val_loss: 0.7446 - val_accuracy: 0.4759 - val_precision: 0.4327 - val_recall: 0.4265\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.6932 - accuracy: 0.5730 - precision: 0.5523 - recall: 0.3519 - val_loss: 0.7235 - val_accuracy: 0.4978 - val_precision: 0.4338 - val_recall: 0.2796\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 0.6941 - accuracy: 0.5631 - precision: 0.5279 - recall: 0.4248 - val_loss: 0.7077 - val_accuracy: 0.5219 - val_precision: 0.4444 - val_recall: 0.1327\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.6880 - accuracy: 0.5695 - precision: 0.5401 - recall: 0.3969 - val_loss: 0.7263 - val_accuracy: 0.4846 - val_precision: 0.4333 - val_recall: 0.3697\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.6939 - accuracy: 0.5496 - precision: 0.5084 - recall: 0.4698 - val_loss: 0.7084 - val_accuracy: 0.5373 - val_precision: 0.5000 - val_recall: 0.1422\n",
      "Epoch 15/50\n",
      "10/12 [========================>.....] - ETA: 0s - loss: 0.6966 - accuracy: 0.5680 - precision: 0.5580 - recall: 0.3017Restoring model weights from the end of the best epoch: 5.\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 0.6929 - accuracy: 0.5752 - precision: 0.5665 - recall: 0.3039 - val_loss: 0.7370 - val_accuracy: 0.4956 - val_precision: 0.4457 - val_recall: 0.3697\n",
      "Epoch 15: early stopping\n",
      "Now fitting model: LSTM_model_arch_26\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Dense_start_1 (Dense)       (None, 21, 199)           39800     \n",
      "                                                                 \n",
      " Dense_start_2 (Dense)       (None, 21, 40)            8000      \n",
      "                                                                 \n",
      " LSTM1 (LSTM)                (None, 21, 20)            4880      \n",
      "                                                                 \n",
      " Dropout1 (Dropout)          (None, 21, 20)            0         \n",
      "                                                                 \n",
      " LSTM2 (LSTM)                (None, 21, 10)            1240      \n",
      "                                                                 \n",
      " Dropout2 (Dropout)          (None, 21, 10)            0         \n",
      "                                                                 \n",
      " LSTM3 (LSTM)                (None, 10)                840       \n",
      "                                                                 \n",
      " Dense_end_1 (Dense)         (None, 7)                 77        \n",
      "                                                                 \n",
      " Dense_end_2 (Dense)         (None, 5)                 40        \n",
      "                                                                 \n",
      " Output (Dense)              (None, 1)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 54883 (214.39 KB)\n",
      "Trainable params: 54883 (214.39 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 2s 52ms/step - loss: 0.9367 - accuracy: 0.5014 - precision: 0.4596 - recall: 0.5116 - val_loss: 0.7415 - val_accuracy: 0.5088 - val_precision: 0.4700 - val_recall: 0.4834\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 0.9277 - accuracy: 0.5007 - precision: 0.4564 - recall: 0.4791 - val_loss: 0.8905 - val_accuracy: 0.4737 - val_precision: 0.4142 - val_recall: 0.3318\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.8618 - accuracy: 0.5227 - precision: 0.4725 - recall: 0.3736 - val_loss: 0.7349 - val_accuracy: 0.5263 - val_precision: 0.4324 - val_recall: 0.0758\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.7655 - accuracy: 0.5213 - precision: 0.4595 - recall: 0.2636 - val_loss: 0.7456 - val_accuracy: 0.5307 - val_precision: 0.2000 - val_recall: 0.0047\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.7811 - accuracy: 0.5191 - precision: 0.4315 - recall: 0.1612 - val_loss: 0.7019 - val_accuracy: 0.5241 - val_precision: 0.4483 - val_recall: 0.1232\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.7111 - accuracy: 0.5333 - precision: 0.4824 - recall: 0.2760 - val_loss: 0.6999 - val_accuracy: 0.5154 - val_precision: 0.4444 - val_recall: 0.1896\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.7022 - accuracy: 0.5326 - precision: 0.4846 - recall: 0.3411 - val_loss: 0.6912 - val_accuracy: 0.5351 - val_precision: 0.4945 - val_recall: 0.2133\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.7111 - accuracy: 0.5085 - precision: 0.4476 - recall: 0.3178 - val_loss: 0.6881 - val_accuracy: 0.5504 - val_precision: 0.5455 - val_recall: 0.1706\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 0.7038 - accuracy: 0.5284 - precision: 0.4632 - recall: 0.1953 - val_loss: 0.6945 - val_accuracy: 0.5307 - val_precision: 0.4595 - val_recall: 0.0806\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 0.7022 - accuracy: 0.5142 - precision: 0.4432 - recall: 0.2419 - val_loss: 0.6950 - val_accuracy: 0.5285 - val_precision: 0.4792 - val_recall: 0.2180\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 0.7040 - accuracy: 0.5156 - precision: 0.4336 - recall: 0.1922 - val_loss: 0.6976 - val_accuracy: 0.5197 - val_precision: 0.4574 - val_recall: 0.2038\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 0.7133 - accuracy: 0.5007 - precision: 0.4423 - recall: 0.3504 - val_loss: 0.7125 - val_accuracy: 0.5044 - val_precision: 0.4611 - val_recall: 0.4218\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.7156 - accuracy: 0.5128 - precision: 0.4718 - recall: 0.5442 - val_loss: 0.6950 - val_accuracy: 0.5088 - val_precision: 0.4695 - val_recall: 0.4739\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 0.7133 - accuracy: 0.5206 - precision: 0.4397 - recall: 0.1752 - val_loss: 0.6917 - val_accuracy: 0.5395 - val_precision: 0.5102 - val_recall: 0.1185\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 0s 42ms/step - loss: 0.6995 - accuracy: 0.5376 - precision: 0.4857 - recall: 0.1845 - val_loss: 0.6879 - val_accuracy: 0.5373 - val_precision: 0.5000 - val_recall: 0.4882\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 0.7042 - accuracy: 0.5113 - precision: 0.4436 - recall: 0.2682 - val_loss: 0.6922 - val_accuracy: 0.5439 - val_precision: 0.5385 - val_recall: 0.0995\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 0.7029 - accuracy: 0.5511 - precision: 0.5682 - recall: 0.0775 - val_loss: 0.6929 - val_accuracy: 0.5329 - val_precision: 0.4615 - val_recall: 0.0569\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 0.6994 - accuracy: 0.5440 - precision: 0.5054 - recall: 0.1457 - val_loss: 0.6887 - val_accuracy: 0.5351 - val_precision: 0.4444 - val_recall: 0.0190\n",
      "Epoch 19/50\n",
      "12/12 [==============================] - 0s 42ms/step - loss: 0.7022 - accuracy: 0.5298 - precision: 0.4458 - recall: 0.1147 - val_loss: 0.6923 - val_accuracy: 0.5307 - val_precision: 0.4348 - val_recall: 0.0474\n",
      "Epoch 20/50\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 0.7017 - accuracy: 0.5262 - precision: 0.4094 - recall: 0.0806 - val_loss: 0.6939 - val_accuracy: 0.5241 - val_precision: 0.4062 - val_recall: 0.0616\n",
      "Epoch 21/50\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 0.6983 - accuracy: 0.5326 - precision: 0.4643 - recall: 0.1411 - val_loss: 0.6912 - val_accuracy: 0.5263 - val_precision: 0.4490 - val_recall: 0.1043\n",
      "Epoch 22/50\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 0.7010 - accuracy: 0.5213 - precision: 0.4440 - recall: 0.1845 - val_loss: 0.6945 - val_accuracy: 0.5307 - val_precision: 0.4516 - val_recall: 0.0664\n",
      "Epoch 23/50\n",
      "12/12 [==============================] - 0s 42ms/step - loss: 0.6993 - accuracy: 0.5270 - precision: 0.4553 - recall: 0.1736 - val_loss: 0.6939 - val_accuracy: 0.5175 - val_precision: 0.3636 - val_recall: 0.0569\n",
      "Epoch 24/50\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 0.6995 - accuracy: 0.5383 - precision: 0.4842 - recall: 0.1426 - val_loss: 0.6915 - val_accuracy: 0.5241 - val_precision: 0.1250 - val_recall: 0.0047\n",
      "Epoch 25/50\n",
      "10/12 [========================>.....] - ETA: 0s - loss: 0.6984 - accuracy: 0.5188 - precision: 0.4500 - recall: 0.1983Restoring model weights from the end of the best epoch: 15.\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 0.6973 - accuracy: 0.5234 - precision: 0.4520 - recall: 0.1969 - val_loss: 0.6915 - val_accuracy: 0.5307 - val_precision: 0.2000 - val_recall: 0.0047\n",
      "Epoch 25: early stopping\n",
      "Now fitting model: LSTM_model_arch_26\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Dense_start_1 (Dense)       (None, 21, 96)            9312      \n",
      "                                                                 \n",
      " Dense_start_2 (Dense)       (None, 21, 40)            3880      \n",
      "                                                                 \n",
      " LSTM1 (LSTM)                (None, 21, 20)            4880      \n",
      "                                                                 \n",
      " Dropout1 (Dropout)          (None, 21, 20)            0         \n",
      "                                                                 \n",
      " LSTM2 (LSTM)                (None, 21, 10)            1240      \n",
      "                                                                 \n",
      " Dropout2 (Dropout)          (None, 21, 10)            0         \n",
      "                                                                 \n",
      " LSTM3 (LSTM)                (None, 10)                840       \n",
      "                                                                 \n",
      " Dense_end_1 (Dense)         (None, 7)                 77        \n",
      "                                                                 \n",
      " Dense_end_2 (Dense)         (None, 5)                 40        \n",
      "                                                                 \n",
      " Output (Dense)              (None, 1)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20275 (79.20 KB)\n",
      "Trainable params: 20275 (79.20 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 2s 58ms/step - loss: 0.7394 - accuracy: 0.5000 - precision: 0.4486 - recall: 0.4062 - val_loss: 0.7024 - val_accuracy: 0.5022 - val_precision: 0.4429 - val_recall: 0.2938\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.8133 - accuracy: 0.5291 - precision: 0.4781 - recall: 0.3209 - val_loss: 0.7029 - val_accuracy: 0.4978 - val_precision: 0.3676 - val_recall: 0.1185\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.6955 - accuracy: 0.4957 - precision: 0.4240 - recall: 0.2853 - val_loss: 0.7013 - val_accuracy: 0.4912 - val_precision: 0.4432 - val_recall: 0.3886\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 0.7010 - accuracy: 0.5199 - precision: 0.4429 - recall: 0.1922 - val_loss: 0.6974 - val_accuracy: 0.5417 - val_precision: 0.5208 - val_recall: 0.1185\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.7144 - accuracy: 0.5220 - precision: 0.4413 - recall: 0.1690 - val_loss: 0.7019 - val_accuracy: 0.5219 - val_precision: 0.4685 - val_recall: 0.2464\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.7104 - accuracy: 0.5106 - precision: 0.4534 - recall: 0.3395 - val_loss: 0.6945 - val_accuracy: 0.4956 - val_precision: 0.4228 - val_recall: 0.2464\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.7297 - accuracy: 0.5326 - precision: 0.4765 - recall: 0.2202 - val_loss: 0.6946 - val_accuracy: 0.5044 - val_precision: 0.4211 - val_recall: 0.1896\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 0.6964 - accuracy: 0.5511 - precision: 0.5265 - recall: 0.1845 - val_loss: 0.6940 - val_accuracy: 0.5154 - val_precision: 0.4419 - val_recall: 0.1801\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.6974 - accuracy: 0.5383 - precision: 0.4828 - recall: 0.1302 - val_loss: 0.6918 - val_accuracy: 0.5154 - val_precision: 0.4342 - val_recall: 0.1564\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.6946 - accuracy: 0.5411 - precision: 0.4936 - recall: 0.1194 - val_loss: 0.6914 - val_accuracy: 0.5154 - val_precision: 0.4167 - val_recall: 0.1185\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.6985 - accuracy: 0.5326 - precision: 0.4514 - recall: 0.1008 - val_loss: 0.6911 - val_accuracy: 0.5329 - val_precision: 0.4872 - val_recall: 0.1801\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 0.6983 - accuracy: 0.5362 - precision: 0.4672 - recall: 0.0992 - val_loss: 0.6897 - val_accuracy: 0.5285 - val_precision: 0.4565 - val_recall: 0.0995\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.6959 - accuracy: 0.5362 - precision: 0.4694 - recall: 0.1070 - val_loss: 0.6916 - val_accuracy: 0.5132 - val_precision: 0.4179 - val_recall: 0.1327\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.6940 - accuracy: 0.5489 - precision: 0.5175 - recall: 0.2062 - val_loss: 0.6950 - val_accuracy: 0.5066 - val_precision: 0.4611 - val_recall: 0.3934\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.6957 - accuracy: 0.5213 - precision: 0.4617 - recall: 0.2806 - val_loss: 0.6901 - val_accuracy: 0.5241 - val_precision: 0.4815 - val_recall: 0.3697\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 0.6982 - accuracy: 0.5291 - precision: 0.4741 - recall: 0.2698 - val_loss: 0.6863 - val_accuracy: 0.5592 - val_precision: 0.5568 - val_recall: 0.2322\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.7006 - accuracy: 0.5284 - precision: 0.4702 - recall: 0.2450 - val_loss: 0.6891 - val_accuracy: 0.5329 - val_precision: 0.4848 - val_recall: 0.1517\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.7019 - accuracy: 0.5206 - precision: 0.4475 - recall: 0.2047 - val_loss: 0.6889 - val_accuracy: 0.5592 - val_precision: 0.5893 - val_recall: 0.1564\n",
      "Epoch 19/50\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.6966 - accuracy: 0.5270 - precision: 0.4643 - recall: 0.2217 - val_loss: 0.6864 - val_accuracy: 0.5482 - val_precision: 0.5316 - val_recall: 0.1991\n",
      "Epoch 20/50\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 0.6947 - accuracy: 0.5355 - precision: 0.4775 - recall: 0.1643 - val_loss: 0.6892 - val_accuracy: 0.5439 - val_precision: 0.5319 - val_recall: 0.1185\n",
      "Epoch 21/50\n",
      "12/12 [==============================] - 0s 26ms/step - loss: 0.7002 - accuracy: 0.5404 - precision: 0.4898 - recall: 0.1116 - val_loss: 0.6889 - val_accuracy: 0.5548 - val_precision: 0.5465 - val_recall: 0.2227\n",
      "Epoch 22/50\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.6984 - accuracy: 0.5397 - precision: 0.4853 - recall: 0.1023 - val_loss: 0.6891 - val_accuracy: 0.5395 - val_precision: 0.5091 - val_recall: 0.1327\n",
      "Epoch 23/50\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.6984 - accuracy: 0.5369 - precision: 0.4737 - recall: 0.1116 - val_loss: 0.6932 - val_accuracy: 0.5439 - val_precision: 0.5217 - val_recall: 0.1706\n",
      "Epoch 24/50\n",
      "12/12 [==============================] - 1s 37ms/step - loss: 0.6999 - accuracy: 0.5241 - precision: 0.3839 - recall: 0.0667 - val_loss: 0.6934 - val_accuracy: 0.5439 - val_precision: 0.5263 - val_recall: 0.1422\n",
      "Epoch 25/50\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 0.6989 - accuracy: 0.5340 - precision: 0.4691 - recall: 0.1411 - val_loss: 0.6945 - val_accuracy: 0.5154 - val_precision: 0.4734 - val_recall: 0.4218\n",
      "Epoch 26/50\n",
      " 9/12 [=====================>........] - ETA: 0s - loss: 0.6984 - accuracy: 0.4965 - precision: 0.4351 - recall: 0.3441Restoring model weights from the end of the best epoch: 16.\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.6973 - accuracy: 0.5014 - precision: 0.4442 - recall: 0.3581 - val_loss: 0.6944 - val_accuracy: 0.5000 - val_precision: 0.4691 - val_recall: 0.6114\n",
      "Epoch 26: early stopping\n",
      "Now fitting model: LSTM_model_arch_27\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Dense_start_1 (Dense)       (None, 21, 199)           39800     \n",
      "                                                                 \n",
      " Dense_start_2 (Dense)       (None, 21, 80)            16000     \n",
      "                                                                 \n",
      " Dense_start_3 (Dense)       (None, 21, 40)            3240      \n",
      "                                                                 \n",
      " LSTM1 (LSTM)                (None, 21, 20)            4880      \n",
      "                                                                 \n",
      " Dropout1 (Dropout)          (None, 21, 20)            0         \n",
      "                                                                 \n",
      " LSTM2 (LSTM)                (None, 21, 10)            1240      \n",
      "                                                                 \n",
      " Dropout2 (Dropout)          (None, 21, 10)            0         \n",
      "                                                                 \n",
      " LSTM3 (LSTM)                (None, 10)                840       \n",
      "                                                                 \n",
      " Dense_end_1 (Dense)         (None, 7)                 77        \n",
      "                                                                 \n",
      " Dense_end_2 (Dense)         (None, 5)                 40        \n",
      "                                                                 \n",
      " Output (Dense)              (None, 1)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66123 (258.29 KB)\n",
      "Trainable params: 66123 (258.29 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 2s 47ms/step - loss: 0.7213 - accuracy: 0.5078 - precision: 0.4707 - recall: 0.6093 - val_loss: 0.8034 - val_accuracy: 0.4211 - val_precision: 0.4297 - val_recall: 0.7678\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.8590 - accuracy: 0.4780 - precision: 0.4574 - recall: 0.7581 - val_loss: 0.8952 - val_accuracy: 0.4912 - val_precision: 0.4667 - val_recall: 0.6967\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.7852 - accuracy: 0.5064 - precision: 0.4677 - recall: 0.5721 - val_loss: 0.7084 - val_accuracy: 0.5285 - val_precision: 0.4873 - val_recall: 0.3649\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 0.7349 - accuracy: 0.5035 - precision: 0.4426 - recall: 0.3287 - val_loss: 0.7212 - val_accuracy: 0.4934 - val_precision: 0.4612 - val_recall: 0.5640\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.9838 - accuracy: 0.4830 - precision: 0.4417 - recall: 0.4930 - val_loss: 0.7010 - val_accuracy: 0.4956 - val_precision: 0.3827 - val_recall: 0.1469\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.7204 - accuracy: 0.5404 - precision: 0.4928 - recall: 0.1597 - val_loss: 0.6913 - val_accuracy: 0.5373 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 27ms/step - loss: 0.6993 - accuracy: 0.5433 - precision: 1.0000 - recall: 0.0016 - val_loss: 0.6910 - val_accuracy: 0.5373 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.6977 - accuracy: 0.5433 - precision: 0.6000 - recall: 0.0047 - val_loss: 0.6909 - val_accuracy: 0.5373 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 0.6968 - accuracy: 0.5397 - precision: 0.1667 - recall: 0.0016 - val_loss: 0.6910 - val_accuracy: 0.5373 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 0.6967 - accuracy: 0.5447 - precision: 0.6667 - recall: 0.0093 - val_loss: 0.6911 - val_accuracy: 0.5373 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 0.6969 - accuracy: 0.5418 - precision: 0.4286 - recall: 0.0047 - val_loss: 0.6912 - val_accuracy: 0.5373 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 0.6956 - accuracy: 0.5418 - precision: 0.4545 - recall: 0.0078 - val_loss: 0.6917 - val_accuracy: 0.5373 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 0.6943 - accuracy: 0.5553 - precision: 0.6250 - recall: 0.0698 - val_loss: 0.6923 - val_accuracy: 0.5307 - val_precision: 0.2000 - val_recall: 0.0047\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 0.6951 - accuracy: 0.5454 - precision: 0.5200 - recall: 0.0806 - val_loss: 0.6927 - val_accuracy: 0.5219 - val_precision: 0.2941 - val_recall: 0.0237\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.6964 - accuracy: 0.5319 - precision: 0.4272 - recall: 0.0682 - val_loss: 0.6929 - val_accuracy: 0.5219 - val_precision: 0.3600 - val_recall: 0.0427\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 0.6953 - accuracy: 0.5454 - precision: 0.5189 - recall: 0.0853 - val_loss: 0.6931 - val_accuracy: 0.5197 - val_precision: 0.3667 - val_recall: 0.0521\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 0.6965 - accuracy: 0.5340 - precision: 0.4524 - recall: 0.0884 - val_loss: 0.6932 - val_accuracy: 0.5219 - val_precision: 0.4054 - val_recall: 0.0711\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.6944 - accuracy: 0.5489 - precision: 0.5344 - recall: 0.1085Restoring model weights from the end of the best epoch: 8.\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 0.6944 - accuracy: 0.5489 - precision: 0.5344 - recall: 0.1085 - val_loss: 0.6936 - val_accuracy: 0.5307 - val_precision: 0.4667 - val_recall: 0.0995\n",
      "Epoch 18: early stopping\n",
      "Now fitting model: LSTM_model_arch_27\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Dense_start_1 (Dense)       (None, 21, 96)            9312      \n",
      "                                                                 \n",
      " Dense_start_2 (Dense)       (None, 21, 80)            7760      \n",
      "                                                                 \n",
      " Dense_start_3 (Dense)       (None, 21, 40)            3240      \n",
      "                                                                 \n",
      " LSTM1 (LSTM)                (None, 21, 20)            4880      \n",
      "                                                                 \n",
      " Dropout1 (Dropout)          (None, 21, 20)            0         \n",
      "                                                                 \n",
      " LSTM2 (LSTM)                (None, 21, 10)            1240      \n",
      "                                                                 \n",
      " Dropout2 (Dropout)          (None, 21, 10)            0         \n",
      "                                                                 \n",
      " LSTM3 (LSTM)                (None, 10)                840       \n",
      "                                                                 \n",
      " Dense_end_1 (Dense)         (None, 7)                 77        \n",
      "                                                                 \n",
      " Dense_end_2 (Dense)         (None, 5)                 40        \n",
      "                                                                 \n",
      " Output (Dense)              (None, 1)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 27395 (107.01 KB)\n",
      "Trainable params: 27395 (107.01 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 2s 43ms/step - loss: 0.6982 - accuracy: 0.5021 - precision: 0.4516 - recall: 0.4124 - val_loss: 0.6931 - val_accuracy: 0.5307 - val_precision: 0.4867 - val_recall: 0.2607\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.7623 - accuracy: 0.5000 - precision: 0.4032 - recall: 0.1938 - val_loss: 0.6922 - val_accuracy: 0.5197 - val_precision: 0.4355 - val_recall: 0.1280\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 0.7138 - accuracy: 0.5255 - precision: 0.4653 - recall: 0.2496 - val_loss: 0.7042 - val_accuracy: 0.4715 - val_precision: 0.4561 - val_recall: 0.7393\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.7038 - accuracy: 0.4745 - precision: 0.4294 - recall: 0.4527 - val_loss: 0.6975 - val_accuracy: 0.4912 - val_precision: 0.4644 - val_recall: 0.6493\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.7047 - accuracy: 0.5184 - precision: 0.4366 - recall: 0.1814 - val_loss: 0.6936 - val_accuracy: 0.5285 - val_precision: 0.4851 - val_recall: 0.3081\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.7004 - accuracy: 0.5262 - precision: 0.4228 - recall: 0.0977 - val_loss: 0.6940 - val_accuracy: 0.5132 - val_precision: 0.4545 - val_recall: 0.2607\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 1s 53ms/step - loss: 0.7019 - accuracy: 0.5362 - precision: 0.4536 - recall: 0.0682 - val_loss: 0.6924 - val_accuracy: 0.5263 - val_precision: 0.4797 - val_recall: 0.2796\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.7005 - accuracy: 0.5326 - precision: 0.4521 - recall: 0.1023 - val_loss: 0.6922 - val_accuracy: 0.5285 - val_precision: 0.4412 - val_recall: 0.0711\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.7111 - accuracy: 0.5376 - precision: 0.4660 - recall: 0.0744 - val_loss: 0.6976 - val_accuracy: 0.5241 - val_precision: 0.4286 - val_recall: 0.0853\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 0.7000 - accuracy: 0.5362 - precision: 0.4710 - recall: 0.1132 - val_loss: 0.6944 - val_accuracy: 0.5241 - val_precision: 0.4674 - val_recall: 0.2038\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.7187 - accuracy: 0.5043 - precision: 0.4250 - recall: 0.2372 - val_loss: 0.6946 - val_accuracy: 0.5307 - val_precision: 0.4910 - val_recall: 0.3886\n",
      "Epoch 12/50\n",
      "10/12 [========================>.....] - ETA: 0s - loss: 0.7112 - accuracy: 0.4930 - precision: 0.3919 - recall: 0.1814Restoring model weights from the end of the best epoch: 2.\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 0.7128 - accuracy: 0.4979 - precision: 0.3939 - recall: 0.1814 - val_loss: 0.6954 - val_accuracy: 0.5636 - val_precision: 0.5811 - val_recall: 0.2038\n",
      "Epoch 12: early stopping\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Model_Architecture</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Validation_Loss</th>\n",
       "      <th>Validation_Accuracy</th>\n",
       "      <th>Validation_Precision</th>\n",
       "      <th>Validation_Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>High-corr filtered</td>\n",
       "      <td>LSTM_model_arch_11</td>\n",
       "      <td>0.685495</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.500775</td>\n",
       "      <td>0.695222</td>\n",
       "      <td>0.504386</td>\n",
       "      <td>0.461929</td>\n",
       "      <td>0.431280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>High-corr filtered</td>\n",
       "      <td>LSTM_model_arch_12</td>\n",
       "      <td>0.621878</td>\n",
       "      <td>0.643972</td>\n",
       "      <td>0.667447</td>\n",
       "      <td>0.441860</td>\n",
       "      <td>0.680536</td>\n",
       "      <td>0.574561</td>\n",
       "      <td>0.545946</td>\n",
       "      <td>0.478673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>High-corr filtered</td>\n",
       "      <td>LSTM_model_arch_13</td>\n",
       "      <td>0.685344</td>\n",
       "      <td>0.567376</td>\n",
       "      <td>0.597765</td>\n",
       "      <td>0.165891</td>\n",
       "      <td>0.705010</td>\n",
       "      <td>0.543860</td>\n",
       "      <td>0.527273</td>\n",
       "      <td>0.137441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>High-corr filtered</td>\n",
       "      <td>LSTM_model_arch_14</td>\n",
       "      <td>0.615444</td>\n",
       "      <td>0.653901</td>\n",
       "      <td>0.689157</td>\n",
       "      <td>0.443411</td>\n",
       "      <td>0.773789</td>\n",
       "      <td>0.543860</td>\n",
       "      <td>0.505415</td>\n",
       "      <td>0.663507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>High-corr filtered</td>\n",
       "      <td>LSTM_model_arch_15</td>\n",
       "      <td>0.695336</td>\n",
       "      <td>0.542553</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.689996</td>\n",
       "      <td>0.537281</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>High-corr filtered</td>\n",
       "      <td>LSTM_model_arch_16</td>\n",
       "      <td>0.679260</td>\n",
       "      <td>0.578723</td>\n",
       "      <td>0.545617</td>\n",
       "      <td>0.472868</td>\n",
       "      <td>0.691410</td>\n",
       "      <td>0.567982</td>\n",
       "      <td>0.570000</td>\n",
       "      <td>0.270142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>High-corr filtered</td>\n",
       "      <td>LSTM_model_arch_17</td>\n",
       "      <td>0.696753</td>\n",
       "      <td>0.539007</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.007752</td>\n",
       "      <td>0.691212</td>\n",
       "      <td>0.537281</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>High-corr filtered</td>\n",
       "      <td>LSTM_model_arch_18</td>\n",
       "      <td>0.694631</td>\n",
       "      <td>0.536170</td>\n",
       "      <td>0.493506</td>\n",
       "      <td>0.530233</td>\n",
       "      <td>0.712441</td>\n",
       "      <td>0.497807</td>\n",
       "      <td>0.452632</td>\n",
       "      <td>0.407583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>High-corr filtered</td>\n",
       "      <td>LSTM_model_arch_19</td>\n",
       "      <td>0.702665</td>\n",
       "      <td>0.536170</td>\n",
       "      <td>0.480519</td>\n",
       "      <td>0.172093</td>\n",
       "      <td>0.690207</td>\n",
       "      <td>0.535088</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.009479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>High-corr filtered</td>\n",
       "      <td>LSTM_model_arch_20</td>\n",
       "      <td>0.696449</td>\n",
       "      <td>0.572340</td>\n",
       "      <td>0.552239</td>\n",
       "      <td>0.344186</td>\n",
       "      <td>0.717235</td>\n",
       "      <td>0.519737</td>\n",
       "      <td>0.463636</td>\n",
       "      <td>0.241706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>High-corr filtered</td>\n",
       "      <td>LSTM_model_arch_21</td>\n",
       "      <td>0.694377</td>\n",
       "      <td>0.508511</td>\n",
       "      <td>0.455882</td>\n",
       "      <td>0.384496</td>\n",
       "      <td>0.695336</td>\n",
       "      <td>0.484649</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.379147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>High-corr filtered</td>\n",
       "      <td>LSTM_model_arch_22</td>\n",
       "      <td>0.691395</td>\n",
       "      <td>0.548936</td>\n",
       "      <td>0.508704</td>\n",
       "      <td>0.407752</td>\n",
       "      <td>0.746992</td>\n",
       "      <td>0.482456</td>\n",
       "      <td>0.459283</td>\n",
       "      <td>0.668246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>High-corr filtered</td>\n",
       "      <td>LSTM_model_arch_23</td>\n",
       "      <td>0.697571</td>\n",
       "      <td>0.532624</td>\n",
       "      <td>0.464646</td>\n",
       "      <td>0.142636</td>\n",
       "      <td>0.691109</td>\n",
       "      <td>0.528509</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.004739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>High-corr filtered</td>\n",
       "      <td>LSTM_model_arch_24</td>\n",
       "      <td>0.697391</td>\n",
       "      <td>0.545390</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.080620</td>\n",
       "      <td>0.690161</td>\n",
       "      <td>0.539474</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.004739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>High-corr filtered</td>\n",
       "      <td>LSTM_model_arch_25</td>\n",
       "      <td>0.696029</td>\n",
       "      <td>0.543972</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.029457</td>\n",
       "      <td>0.695324</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.422018</td>\n",
       "      <td>0.218009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>High-corr filtered</td>\n",
       "      <td>LSTM_model_arch_26</td>\n",
       "      <td>0.697277</td>\n",
       "      <td>0.523404</td>\n",
       "      <td>0.451957</td>\n",
       "      <td>0.196899</td>\n",
       "      <td>0.691518</td>\n",
       "      <td>0.530702</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.004739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>High-corr filtered</td>\n",
       "      <td>LSTM_model_arch_27</td>\n",
       "      <td>0.694365</td>\n",
       "      <td>0.548936</td>\n",
       "      <td>0.534351</td>\n",
       "      <td>0.108527</td>\n",
       "      <td>0.693570</td>\n",
       "      <td>0.530702</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.099526</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Dataset  Model_Architecture      Loss  Accuracy  Precision  \\\n",
       "0   High-corr filtered  LSTM_model_arch_11  0.685495  0.566667   0.527778   \n",
       "1   High-corr filtered  LSTM_model_arch_12  0.621878  0.643972   0.667447   \n",
       "2   High-corr filtered  LSTM_model_arch_13  0.685344  0.567376   0.597765   \n",
       "3   High-corr filtered  LSTM_model_arch_14  0.615444  0.653901   0.689157   \n",
       "4   High-corr filtered  LSTM_model_arch_15  0.695336  0.542553   0.000000   \n",
       "5   High-corr filtered  LSTM_model_arch_16  0.679260  0.578723   0.545617   \n",
       "6   High-corr filtered  LSTM_model_arch_17  0.696753  0.539007   0.333333   \n",
       "7   High-corr filtered  LSTM_model_arch_18  0.694631  0.536170   0.493506   \n",
       "8   High-corr filtered  LSTM_model_arch_19  0.702665  0.536170   0.480519   \n",
       "9   High-corr filtered  LSTM_model_arch_20  0.696449  0.572340   0.552239   \n",
       "10  High-corr filtered  LSTM_model_arch_21  0.694377  0.508511   0.455882   \n",
       "11  High-corr filtered  LSTM_model_arch_22  0.691395  0.548936   0.508704   \n",
       "12  High-corr filtered  LSTM_model_arch_23  0.697571  0.532624   0.464646   \n",
       "13  High-corr filtered  LSTM_model_arch_24  0.697391  0.545390   0.520000   \n",
       "14  High-corr filtered  LSTM_model_arch_25  0.696029  0.543972   0.527778   \n",
       "15  High-corr filtered  LSTM_model_arch_26  0.697277  0.523404   0.451957   \n",
       "16  High-corr filtered  LSTM_model_arch_27  0.694365  0.548936   0.534351   \n",
       "\n",
       "      Recall  Validation_Loss  Validation_Accuracy  Validation_Precision  \\\n",
       "0   0.500775         0.695222             0.504386              0.461929   \n",
       "1   0.441860         0.680536             0.574561              0.545946   \n",
       "2   0.165891         0.705010             0.543860              0.527273   \n",
       "3   0.443411         0.773789             0.543860              0.505415   \n",
       "4   0.000000         0.689996             0.537281              0.000000   \n",
       "5   0.472868         0.691410             0.567982              0.570000   \n",
       "6   0.007752         0.691212             0.537281              0.000000   \n",
       "7   0.530233         0.712441             0.497807              0.452632   \n",
       "8   0.172093         0.690207             0.535088              0.400000   \n",
       "9   0.344186         0.717235             0.519737              0.463636   \n",
       "10  0.384496         0.695336             0.484649              0.434783   \n",
       "11  0.407752         0.746992             0.482456              0.459283   \n",
       "12  0.142636         0.691109             0.528509              0.166667   \n",
       "13  0.080620         0.690161             0.539474              1.000000   \n",
       "14  0.029457         0.695324             0.500000              0.422018   \n",
       "15  0.196899         0.691518             0.530702              0.200000   \n",
       "16  0.108527         0.693570             0.530702              0.466667   \n",
       "\n",
       "    Validation_Recall  \n",
       "0            0.431280  \n",
       "1            0.478673  \n",
       "2            0.137441  \n",
       "3            0.663507  \n",
       "4            0.000000  \n",
       "5            0.270142  \n",
       "6            0.000000  \n",
       "7            0.407583  \n",
       "8            0.009479  \n",
       "9            0.241706  \n",
       "10           0.379147  \n",
       "11           0.668246  \n",
       "12           0.004739  \n",
       "13           0.004739  \n",
       "14           0.218009  \n",
       "15           0.004739  \n",
       "16           0.099526  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create dataframe for global best model results\n",
    "LSTM_global_results_som_kmeans_data = pd.DataFrame(columns=['Dataset','Model_Architecture', 'Loss', 'Accuracy', 'Precision', 'Recall', \n",
    "                                            'Validation_Loss', \n",
    "                                            'Validation_Accuracy', 'Validation_Precision', 'Validation_Recall'])\n",
    "\n",
    "LSTM_global_results_filtered_data = pd.DataFrame(columns=['Dataset','Model_Architecture', 'Loss', 'Accuracy', 'Precision', 'Recall', \n",
    "                                            'Validation_Loss', \n",
    "                                            'Validation_Accuracy', 'Validation_Precision', 'Validation_Recall'])\n",
    "LSTM_global_results_xg_data = pd.DataFrame(columns=['Dataset','Model_Architecture', 'Loss', 'Accuracy', 'Precision', 'Recall', \n",
    "                                            'Validation_Loss', \n",
    "                                            'Validation_Accuracy', 'Validation_Precision', 'Validation_Recall'])\n",
    "# get a list of all model architectures\n",
    "LSTM_models = [ \\\n",
    "              LSTM_model_arch_1, LSTM_model_arch_2, LSTM_model_arch_3, \\\n",
    "              LSTM_model_arch_4, LSTM_model_arch_5, LSTM_model_arch_6, \\\n",
    "              LSTM_model_arch_7, LSTM_model_arch_8, LSTM_model_arch_9, \\\n",
    "              LSTM_model_arch_10, LSTM_model_arch_11, LSTM_model_arch_12, \\\n",
    "              LSTM_model_arch_13, LSTM_model_arch_14, LSTM_model_arch_15, \\\n",
    "              LSTM_model_arch_16, LSTM_model_arch_17, LSTM_model_arch_18, \\\n",
    "              LSTM_model_arch_19, LSTM_model_arch_20, LSTM_model_arch_21, \\\n",
    "              LSTM_model_arch_22, LSTM_model_arch_23, LSTM_model_arch_24, \\\n",
    "              LSTM_model_arch_25, LSTM_model_arch_26, LSTM_model_arch_27 \\\n",
    "              ]\n",
    "# Train each model architecture and append local results to global table\n",
    "for index, model in enumerate(LSTM_models):\n",
    "    if index in range(10, 28):\n",
    "        model_arch, fit_history = model(g_train_corr_filtered, g_dev_corr_filtered, features=num_features_corr_filtered, lookback=seqlen, class_weights=class_weight, hu=10, data=\"hc_trialrun_jan9_7\")\n",
    "        LSTM_global_results_filtered_data = LSTM_global_results_filtered_data.append({\n",
    "            'Dataset': \"High-corr filtered\",\n",
    "            'Model_Architecture': model.__name__,\n",
    "            'Loss': fit_history.history['loss'][-1], \n",
    "            'Accuracy': fit_history.history['accuracy'][-1], \n",
    "            'Precision': fit_history.history['precision'][-1], \n",
    "            'Recall': fit_history.history['recall'][-1], \n",
    "            'Validation_Loss': fit_history.history['val_loss'][-1], \n",
    "            'Validation_Accuracy': fit_history.history['val_accuracy'][-1], \n",
    "            'Validation_Precision': fit_history.history['val_precision'][-1], \n",
    "            'Validation_Recall': fit_history.history['val_recall'][-1]\n",
    "        },ignore_index=True)\n",
    "        \n",
    "        model_arch, fit_history = model(g_train_kmeans_som, g_dev_kmeans_som, features=num_features_kmeans_som, lookback=seqlen, class_weights=class_weight, hu=10, data=\"sk_trialrun_jan9_6\")\n",
    "        LSTM_global_results_som_kmeans_data = LSTM_global_results_som_kmeans_data.append({\n",
    "            'Dataset': \"SOM K-means dimentionally reduced\",\n",
    "            'Model_Architecture': model.__name__,\n",
    "            'Loss': fit_history.history['loss'][-1], \n",
    "            'Accuracy': fit_history.history['accuracy'][-1], \n",
    "            'Precision': fit_history.history['precision'][-1], \n",
    "            'Recall': fit_history.history['recall'][-1], \n",
    "            'Validation_Loss': fit_history.history['val_loss'][-1], \n",
    "            'Validation_Accuracy': fit_history.history['val_accuracy'][-1], \n",
    "            'Validation_Precision': fit_history.history['val_precision'][-1], \n",
    "            'Validation_Recall': fit_history.history['val_recall'][-1]\n",
    "        },ignore_index=True)\n",
    "    \n",
    "    if index in range(0, 10):\n",
    "        model_arch, fit_history = model(g_train_kmeans_som, g_dev_kmeans_som, features=num_features_kmeans_som, lookback=seqlen, class_weights=class_weight, hu=10, data=\"sk_trialrun_jan9_7\")\n",
    "        LSTM_global_results_som_kmeans_data = LSTM_global_results_som_kmeans_data.append({\n",
    "            'Dataset': \"SOM K-means dimentionally reduced\",\n",
    "            'Model_Architecture': model.__name__,\n",
    "            'Loss': fit_history.history['loss'][-1], \n",
    "            'Accuracy': fit_history.history['accuracy'][-1], \n",
    "            'Precision': fit_history.history['precision'][-1], \n",
    "            'Recall': fit_history.history['recall'][-1], \n",
    "            'Validation_Loss': fit_history.history['val_loss'][-1], \n",
    "            'Validation_Accuracy': fit_history.history['val_accuracy'][-1], \n",
    "            'Validation_Precision': fit_history.history['val_precision'][-1], \n",
    "            'Validation_Recall': fit_history.history['val_recall'][-1]\n",
    "        },ignore_index=True)\n",
    "\n",
    "        model_arch, fit_history = model(g_train_xg, g_dev_xg, features=num_features_xg, lookback=seqlen, class_weights=class_weight, hu=10, data=\"xg_trialrun_jan9_7\")\n",
    "        LSTM_global_results_xg_data = LSTM_global_results_xg_data.append({\n",
    "            'Dataset': \"XGBoost\",\n",
    "            'Model_Architecture': model.__name__,\n",
    "            'Loss': fit_history.history['loss'][-1], \n",
    "            'Accuracy': fit_history.history['accuracy'][-1], \n",
    "            'Precision': fit_history.history['precision'][-1], \n",
    "            'Recall': fit_history.history['recall'][-1], \n",
    "            'Validation_Loss': fit_history.history['val_loss'][-1], \n",
    "            'Validation_Accuracy': fit_history.history['val_accuracy'][-1], \n",
    "            'Validation_Precision': fit_history.history['val_precision'][-1], \n",
    "            'Validation_Recall': fit_history.history['val_recall'][-1]\n",
    "        },ignore_index=True)\n",
    "\n",
    "        \n",
    "# # view global results dataframe\n",
    "LSTM_global_results_filtered_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ba55f0-e94a-494e-b83e-9a5d5d75931f",
   "metadata": {},
   "source": [
    "### Initial run: View results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e6a21c0d-0b87-4bbf-a312-59d8844e2e43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Model_Architecture</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Validation_Loss</th>\n",
       "      <th>Validation_Accuracy</th>\n",
       "      <th>Validation_Precision</th>\n",
       "      <th>Validation_Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>SOM K-means dimentionally reduced</td>\n",
       "      <td>LSTM_model_arch_24</td>\n",
       "      <td>0.699207</td>\n",
       "      <td>0.536879</td>\n",
       "      <td>0.445946</td>\n",
       "      <td>0.051163</td>\n",
       "      <td>0.692527</td>\n",
       "      <td>0.519737</td>\n",
       "      <td>0.466102</td>\n",
       "      <td>0.260664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>SOM K-means dimentionally reduced</td>\n",
       "      <td>LSTM_model_arch_21</td>\n",
       "      <td>0.697844</td>\n",
       "      <td>0.530496</td>\n",
       "      <td>0.478372</td>\n",
       "      <td>0.291473</td>\n",
       "      <td>0.694225</td>\n",
       "      <td>0.513158</td>\n",
       "      <td>0.465839</td>\n",
       "      <td>0.355450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>SOM K-means dimentionally reduced</td>\n",
       "      <td>LSTM_model_arch_26</td>\n",
       "      <td>0.697293</td>\n",
       "      <td>0.501418</td>\n",
       "      <td>0.444231</td>\n",
       "      <td>0.358140</td>\n",
       "      <td>0.694361</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.469091</td>\n",
       "      <td>0.611374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>SOM K-means dimentionally reduced</td>\n",
       "      <td>LSTM_model_arch_23</td>\n",
       "      <td>0.716011</td>\n",
       "      <td>0.553901</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.235659</td>\n",
       "      <td>0.694394</td>\n",
       "      <td>0.519737</td>\n",
       "      <td>0.484252</td>\n",
       "      <td>0.582938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>SOM K-means dimentionally reduced</td>\n",
       "      <td>LSTM_model_arch_27</td>\n",
       "      <td>0.712774</td>\n",
       "      <td>0.497872</td>\n",
       "      <td>0.393939</td>\n",
       "      <td>0.181395</td>\n",
       "      <td>0.695358</td>\n",
       "      <td>0.563596</td>\n",
       "      <td>0.581081</td>\n",
       "      <td>0.203791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>SOM K-means dimentionally reduced</td>\n",
       "      <td>LSTM_model_arch_20</td>\n",
       "      <td>0.687325</td>\n",
       "      <td>0.549645</td>\n",
       "      <td>0.506887</td>\n",
       "      <td>0.570543</td>\n",
       "      <td>0.697345</td>\n",
       "      <td>0.524123</td>\n",
       "      <td>0.487179</td>\n",
       "      <td>0.540284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>SOM K-means dimentionally reduced</td>\n",
       "      <td>LSTM_model_arch_17</td>\n",
       "      <td>0.699650</td>\n",
       "      <td>0.509929</td>\n",
       "      <td>0.471178</td>\n",
       "      <td>0.582946</td>\n",
       "      <td>0.699502</td>\n",
       "      <td>0.495614</td>\n",
       "      <td>0.425197</td>\n",
       "      <td>0.255924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>SOM K-means dimentionally reduced</td>\n",
       "      <td>LSTM_model_arch_22</td>\n",
       "      <td>0.698798</td>\n",
       "      <td>0.545390</td>\n",
       "      <td>0.505376</td>\n",
       "      <td>0.291473</td>\n",
       "      <td>0.702117</td>\n",
       "      <td>0.489035</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.521327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SOM K-means dimentionally reduced</td>\n",
       "      <td>LSTM_model_arch_5</td>\n",
       "      <td>0.667673</td>\n",
       "      <td>0.591489</td>\n",
       "      <td>0.561279</td>\n",
       "      <td>0.489922</td>\n",
       "      <td>0.710798</td>\n",
       "      <td>0.519737</td>\n",
       "      <td>0.468750</td>\n",
       "      <td>0.284360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>SOM K-means dimentionally reduced</td>\n",
       "      <td>LSTM_model_arch_19</td>\n",
       "      <td>0.675467</td>\n",
       "      <td>0.565957</td>\n",
       "      <td>0.517205</td>\n",
       "      <td>0.768992</td>\n",
       "      <td>0.711360</td>\n",
       "      <td>0.508772</td>\n",
       "      <td>0.479624</td>\n",
       "      <td>0.725118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>SOM K-means dimentionally reduced</td>\n",
       "      <td>LSTM_model_arch_13</td>\n",
       "      <td>0.671277</td>\n",
       "      <td>0.590780</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>0.395349</td>\n",
       "      <td>0.713394</td>\n",
       "      <td>0.532895</td>\n",
       "      <td>0.492857</td>\n",
       "      <td>0.327014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SOM K-means dimentionally reduced</td>\n",
       "      <td>LSTM_model_arch_11</td>\n",
       "      <td>0.683867</td>\n",
       "      <td>0.563830</td>\n",
       "      <td>0.568182</td>\n",
       "      <td>0.193798</td>\n",
       "      <td>0.714000</td>\n",
       "      <td>0.559211</td>\n",
       "      <td>0.546296</td>\n",
       "      <td>0.279621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SOM K-means dimentionally reduced</td>\n",
       "      <td>LSTM_model_arch_8</td>\n",
       "      <td>0.683186</td>\n",
       "      <td>0.561702</td>\n",
       "      <td>0.517555</td>\n",
       "      <td>0.617054</td>\n",
       "      <td>0.714685</td>\n",
       "      <td>0.467105</td>\n",
       "      <td>0.451807</td>\n",
       "      <td>0.710900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>SOM K-means dimentionally reduced</td>\n",
       "      <td>LSTM_model_arch_16</td>\n",
       "      <td>0.677467</td>\n",
       "      <td>0.579433</td>\n",
       "      <td>0.546429</td>\n",
       "      <td>0.474419</td>\n",
       "      <td>0.729417</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.436123</td>\n",
       "      <td>0.469194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SOM K-means dimentionally reduced</td>\n",
       "      <td>LSTM_model_arch_12</td>\n",
       "      <td>0.669606</td>\n",
       "      <td>0.604965</td>\n",
       "      <td>0.579422</td>\n",
       "      <td>0.497674</td>\n",
       "      <td>0.732153</td>\n",
       "      <td>0.521930</td>\n",
       "      <td>0.484018</td>\n",
       "      <td>0.502370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>SOM K-means dimentionally reduced</td>\n",
       "      <td>LSTM_model_arch_25</td>\n",
       "      <td>0.692867</td>\n",
       "      <td>0.575177</td>\n",
       "      <td>0.566474</td>\n",
       "      <td>0.303876</td>\n",
       "      <td>0.737006</td>\n",
       "      <td>0.495614</td>\n",
       "      <td>0.445714</td>\n",
       "      <td>0.369668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>SOM K-means dimentionally reduced</td>\n",
       "      <td>LSTM_model_arch_18</td>\n",
       "      <td>0.676085</td>\n",
       "      <td>0.563121</td>\n",
       "      <td>0.519104</td>\n",
       "      <td>0.610853</td>\n",
       "      <td>0.744365</td>\n",
       "      <td>0.464912</td>\n",
       "      <td>0.447619</td>\n",
       "      <td>0.668246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SOM K-means dimentionally reduced</td>\n",
       "      <td>LSTM_model_arch_6</td>\n",
       "      <td>0.660812</td>\n",
       "      <td>0.604255</td>\n",
       "      <td>0.563877</td>\n",
       "      <td>0.595349</td>\n",
       "      <td>0.746138</td>\n",
       "      <td>0.504386</td>\n",
       "      <td>0.475884</td>\n",
       "      <td>0.701422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SOM K-means dimentionally reduced</td>\n",
       "      <td>LSTM_model_arch_9</td>\n",
       "      <td>0.671927</td>\n",
       "      <td>0.570213</td>\n",
       "      <td>0.522491</td>\n",
       "      <td>0.702326</td>\n",
       "      <td>0.748040</td>\n",
       "      <td>0.480263</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.554502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SOM K-means dimentionally reduced</td>\n",
       "      <td>LSTM_model_arch_2</td>\n",
       "      <td>0.652791</td>\n",
       "      <td>0.622695</td>\n",
       "      <td>0.603670</td>\n",
       "      <td>0.510078</td>\n",
       "      <td>0.755914</td>\n",
       "      <td>0.486842</td>\n",
       "      <td>0.449782</td>\n",
       "      <td>0.488152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SOM K-means dimentionally reduced</td>\n",
       "      <td>LSTM_model_arch_10</td>\n",
       "      <td>0.653206</td>\n",
       "      <td>0.613475</td>\n",
       "      <td>0.569252</td>\n",
       "      <td>0.637209</td>\n",
       "      <td>0.773238</td>\n",
       "      <td>0.504386</td>\n",
       "      <td>0.475083</td>\n",
       "      <td>0.677725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SOM K-means dimentionally reduced</td>\n",
       "      <td>LSTM_model_arch_1</td>\n",
       "      <td>0.582817</td>\n",
       "      <td>0.667376</td>\n",
       "      <td>0.620879</td>\n",
       "      <td>0.700775</td>\n",
       "      <td>0.782809</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.487805</td>\n",
       "      <td>0.473934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SOM K-means dimentionally reduced</td>\n",
       "      <td>LSTM_model_arch_4</td>\n",
       "      <td>0.628550</td>\n",
       "      <td>0.622695</td>\n",
       "      <td>0.566237</td>\n",
       "      <td>0.748837</td>\n",
       "      <td>0.802761</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.454829</td>\n",
       "      <td>0.691943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SOM K-means dimentionally reduced</td>\n",
       "      <td>LSTM_model_arch_7</td>\n",
       "      <td>0.668463</td>\n",
       "      <td>0.595035</td>\n",
       "      <td>0.554094</td>\n",
       "      <td>0.587597</td>\n",
       "      <td>0.813724</td>\n",
       "      <td>0.469298</td>\n",
       "      <td>0.449180</td>\n",
       "      <td>0.649289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>SOM K-means dimentionally reduced</td>\n",
       "      <td>LSTM_model_arch_15</td>\n",
       "      <td>0.570491</td>\n",
       "      <td>0.695745</td>\n",
       "      <td>0.711765</td>\n",
       "      <td>0.562791</td>\n",
       "      <td>0.922974</td>\n",
       "      <td>0.502193</td>\n",
       "      <td>0.467480</td>\n",
       "      <td>0.545024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>SOM K-means dimentionally reduced</td>\n",
       "      <td>LSTM_model_arch_14</td>\n",
       "      <td>0.562447</td>\n",
       "      <td>0.704965</td>\n",
       "      <td>0.665224</td>\n",
       "      <td>0.714729</td>\n",
       "      <td>1.084482</td>\n",
       "      <td>0.495614</td>\n",
       "      <td>0.463602</td>\n",
       "      <td>0.573460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SOM K-means dimentionally reduced</td>\n",
       "      <td>LSTM_model_arch_3</td>\n",
       "      <td>0.236687</td>\n",
       "      <td>0.898582</td>\n",
       "      <td>0.900958</td>\n",
       "      <td>0.874419</td>\n",
       "      <td>1.848139</td>\n",
       "      <td>0.489035</td>\n",
       "      <td>0.453390</td>\n",
       "      <td>0.507109</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Dataset  Model_Architecture      Loss  Accuracy  \\\n",
       "23  SOM K-means dimentionally reduced  LSTM_model_arch_24  0.699207  0.536879   \n",
       "20  SOM K-means dimentionally reduced  LSTM_model_arch_21  0.697844  0.530496   \n",
       "25  SOM K-means dimentionally reduced  LSTM_model_arch_26  0.697293  0.501418   \n",
       "22  SOM K-means dimentionally reduced  LSTM_model_arch_23  0.716011  0.553901   \n",
       "26  SOM K-means dimentionally reduced  LSTM_model_arch_27  0.712774  0.497872   \n",
       "19  SOM K-means dimentionally reduced  LSTM_model_arch_20  0.687325  0.549645   \n",
       "16  SOM K-means dimentionally reduced  LSTM_model_arch_17  0.699650  0.509929   \n",
       "21  SOM K-means dimentionally reduced  LSTM_model_arch_22  0.698798  0.545390   \n",
       "4   SOM K-means dimentionally reduced   LSTM_model_arch_5  0.667673  0.591489   \n",
       "18  SOM K-means dimentionally reduced  LSTM_model_arch_19  0.675467  0.565957   \n",
       "12  SOM K-means dimentionally reduced  LSTM_model_arch_13  0.671277  0.590780   \n",
       "10  SOM K-means dimentionally reduced  LSTM_model_arch_11  0.683867  0.563830   \n",
       "7   SOM K-means dimentionally reduced   LSTM_model_arch_8  0.683186  0.561702   \n",
       "15  SOM K-means dimentionally reduced  LSTM_model_arch_16  0.677467  0.579433   \n",
       "11  SOM K-means dimentionally reduced  LSTM_model_arch_12  0.669606  0.604965   \n",
       "24  SOM K-means dimentionally reduced  LSTM_model_arch_25  0.692867  0.575177   \n",
       "17  SOM K-means dimentionally reduced  LSTM_model_arch_18  0.676085  0.563121   \n",
       "5   SOM K-means dimentionally reduced   LSTM_model_arch_6  0.660812  0.604255   \n",
       "8   SOM K-means dimentionally reduced   LSTM_model_arch_9  0.671927  0.570213   \n",
       "1   SOM K-means dimentionally reduced   LSTM_model_arch_2  0.652791  0.622695   \n",
       "9   SOM K-means dimentionally reduced  LSTM_model_arch_10  0.653206  0.613475   \n",
       "0   SOM K-means dimentionally reduced   LSTM_model_arch_1  0.582817  0.667376   \n",
       "3   SOM K-means dimentionally reduced   LSTM_model_arch_4  0.628550  0.622695   \n",
       "6   SOM K-means dimentionally reduced   LSTM_model_arch_7  0.668463  0.595035   \n",
       "14  SOM K-means dimentionally reduced  LSTM_model_arch_15  0.570491  0.695745   \n",
       "13  SOM K-means dimentionally reduced  LSTM_model_arch_14  0.562447  0.704965   \n",
       "2   SOM K-means dimentionally reduced   LSTM_model_arch_3  0.236687  0.898582   \n",
       "\n",
       "    Precision    Recall  Validation_Loss  Validation_Accuracy  \\\n",
       "23   0.445946  0.051163         0.692527             0.519737   \n",
       "20   0.478372  0.291473         0.694225             0.513158   \n",
       "25   0.444231  0.358140         0.694361             0.500000   \n",
       "22   0.527778  0.235659         0.694394             0.519737   \n",
       "26   0.393939  0.181395         0.695358             0.563596   \n",
       "19   0.506887  0.570543         0.697345             0.524123   \n",
       "16   0.471178  0.582946         0.699502             0.495614   \n",
       "21   0.505376  0.291473         0.702117             0.489035   \n",
       "4    0.561279  0.489922         0.710798             0.519737   \n",
       "18   0.517205  0.768992         0.711360             0.508772   \n",
       "12   0.576923  0.395349         0.713394             0.532895   \n",
       "10   0.568182  0.193798         0.714000             0.559211   \n",
       "7    0.517555  0.617054         0.714685             0.467105   \n",
       "15   0.546429  0.474419         0.729417             0.473684   \n",
       "11   0.579422  0.497674         0.732153             0.521930   \n",
       "24   0.566474  0.303876         0.737006             0.495614   \n",
       "17   0.519104  0.610853         0.744365             0.464912   \n",
       "5    0.563877  0.595349         0.746138             0.504386   \n",
       "8    0.522491  0.702326         0.748040             0.480263   \n",
       "1    0.603670  0.510078         0.755914             0.486842   \n",
       "9    0.569252  0.637209         0.773238             0.504386   \n",
       "0    0.620879  0.700775         0.782809             0.526316   \n",
       "3    0.566237  0.748837         0.802761             0.473684   \n",
       "6    0.554094  0.587597         0.813724             0.469298   \n",
       "14   0.711765  0.562791         0.922974             0.502193   \n",
       "13   0.665224  0.714729         1.084482             0.495614   \n",
       "2    0.900958  0.874419         1.848139             0.489035   \n",
       "\n",
       "    Validation_Precision  Validation_Recall  \n",
       "23              0.466102           0.260664  \n",
       "20              0.465839           0.355450  \n",
       "25              0.469091           0.611374  \n",
       "22              0.484252           0.582938  \n",
       "26              0.581081           0.203791  \n",
       "19              0.487179           0.540284  \n",
       "16              0.425197           0.255924  \n",
       "21              0.454545           0.521327  \n",
       "4               0.468750           0.284360  \n",
       "18              0.479624           0.725118  \n",
       "12              0.492857           0.327014  \n",
       "10              0.546296           0.279621  \n",
       "7               0.451807           0.710900  \n",
       "15              0.436123           0.469194  \n",
       "11              0.484018           0.502370  \n",
       "24              0.445714           0.369668  \n",
       "17              0.447619           0.668246  \n",
       "5               0.475884           0.701422  \n",
       "8               0.450000           0.554502  \n",
       "1               0.449782           0.488152  \n",
       "9               0.475083           0.677725  \n",
       "0               0.487805           0.473934  \n",
       "3               0.454829           0.691943  \n",
       "6               0.449180           0.649289  \n",
       "14              0.467480           0.545024  \n",
       "13              0.463602           0.573460  \n",
       "2               0.453390           0.507109  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rank model architecture results in ascending order of Validation Loss\n",
    "best_models_filtered_data = LSTM_global_results_filtered_data.sort_values(by='Validation_Loss', ascending=True)\n",
    "best_models_som_kmeans_data = LSTM_global_results_som_kmeans_data.sort_values(by='Validation_Loss', ascending=True)\n",
    "best_models_xg_data = LSTM_global_results_xg_data.sort_values(by='Validation_Loss', ascending=True)\n",
    "\n",
    "# view model result dataset for som and kmeans reduced data\n",
    "best_models_som_kmeans_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "027620cd-0c59-4c6e-a383-dd58c7753428",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Model_Architecture</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Validation_Loss</th>\n",
       "      <th>Validation_Accuracy</th>\n",
       "      <th>Validation_Precision</th>\n",
       "      <th>Validation_Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>High-corr filtered</td>\n",
       "      <td>LSTM_model_arch_12</td>\n",
       "      <td>0.621878</td>\n",
       "      <td>0.643972</td>\n",
       "      <td>0.667447</td>\n",
       "      <td>0.441860</td>\n",
       "      <td>0.680536</td>\n",
       "      <td>0.574561</td>\n",
       "      <td>0.545946</td>\n",
       "      <td>0.478673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>High-corr filtered</td>\n",
       "      <td>LSTM_model_arch_15</td>\n",
       "      <td>0.695336</td>\n",
       "      <td>0.542553</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.689996</td>\n",
       "      <td>0.537281</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>High-corr filtered</td>\n",
       "      <td>LSTM_model_arch_24</td>\n",
       "      <td>0.697391</td>\n",
       "      <td>0.545390</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.080620</td>\n",
       "      <td>0.690161</td>\n",
       "      <td>0.539474</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.004739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>High-corr filtered</td>\n",
       "      <td>LSTM_model_arch_19</td>\n",
       "      <td>0.702665</td>\n",
       "      <td>0.536170</td>\n",
       "      <td>0.480519</td>\n",
       "      <td>0.172093</td>\n",
       "      <td>0.690207</td>\n",
       "      <td>0.535088</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.009479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>High-corr filtered</td>\n",
       "      <td>LSTM_model_arch_23</td>\n",
       "      <td>0.697571</td>\n",
       "      <td>0.532624</td>\n",
       "      <td>0.464646</td>\n",
       "      <td>0.142636</td>\n",
       "      <td>0.691109</td>\n",
       "      <td>0.528509</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.004739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>High-corr filtered</td>\n",
       "      <td>LSTM_model_arch_17</td>\n",
       "      <td>0.696753</td>\n",
       "      <td>0.539007</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.007752</td>\n",
       "      <td>0.691212</td>\n",
       "      <td>0.537281</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>High-corr filtered</td>\n",
       "      <td>LSTM_model_arch_16</td>\n",
       "      <td>0.679260</td>\n",
       "      <td>0.578723</td>\n",
       "      <td>0.545617</td>\n",
       "      <td>0.472868</td>\n",
       "      <td>0.691410</td>\n",
       "      <td>0.567982</td>\n",
       "      <td>0.570000</td>\n",
       "      <td>0.270142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>High-corr filtered</td>\n",
       "      <td>LSTM_model_arch_26</td>\n",
       "      <td>0.697277</td>\n",
       "      <td>0.523404</td>\n",
       "      <td>0.451957</td>\n",
       "      <td>0.196899</td>\n",
       "      <td>0.691518</td>\n",
       "      <td>0.530702</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.004739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>High-corr filtered</td>\n",
       "      <td>LSTM_model_arch_27</td>\n",
       "      <td>0.694365</td>\n",
       "      <td>0.548936</td>\n",
       "      <td>0.534351</td>\n",
       "      <td>0.108527</td>\n",
       "      <td>0.693570</td>\n",
       "      <td>0.530702</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.099526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>High-corr filtered</td>\n",
       "      <td>LSTM_model_arch_11</td>\n",
       "      <td>0.685495</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.500775</td>\n",
       "      <td>0.695222</td>\n",
       "      <td>0.504386</td>\n",
       "      <td>0.461929</td>\n",
       "      <td>0.431280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>High-corr filtered</td>\n",
       "      <td>LSTM_model_arch_25</td>\n",
       "      <td>0.696029</td>\n",
       "      <td>0.543972</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.029457</td>\n",
       "      <td>0.695324</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.422018</td>\n",
       "      <td>0.218009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>High-corr filtered</td>\n",
       "      <td>LSTM_model_arch_21</td>\n",
       "      <td>0.694377</td>\n",
       "      <td>0.508511</td>\n",
       "      <td>0.455882</td>\n",
       "      <td>0.384496</td>\n",
       "      <td>0.695336</td>\n",
       "      <td>0.484649</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.379147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>High-corr filtered</td>\n",
       "      <td>LSTM_model_arch_13</td>\n",
       "      <td>0.685344</td>\n",
       "      <td>0.567376</td>\n",
       "      <td>0.597765</td>\n",
       "      <td>0.165891</td>\n",
       "      <td>0.705010</td>\n",
       "      <td>0.543860</td>\n",
       "      <td>0.527273</td>\n",
       "      <td>0.137441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>High-corr filtered</td>\n",
       "      <td>LSTM_model_arch_18</td>\n",
       "      <td>0.694631</td>\n",
       "      <td>0.536170</td>\n",
       "      <td>0.493506</td>\n",
       "      <td>0.530233</td>\n",
       "      <td>0.712441</td>\n",
       "      <td>0.497807</td>\n",
       "      <td>0.452632</td>\n",
       "      <td>0.407583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>High-corr filtered</td>\n",
       "      <td>LSTM_model_arch_20</td>\n",
       "      <td>0.696449</td>\n",
       "      <td>0.572340</td>\n",
       "      <td>0.552239</td>\n",
       "      <td>0.344186</td>\n",
       "      <td>0.717235</td>\n",
       "      <td>0.519737</td>\n",
       "      <td>0.463636</td>\n",
       "      <td>0.241706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>High-corr filtered</td>\n",
       "      <td>LSTM_model_arch_22</td>\n",
       "      <td>0.691395</td>\n",
       "      <td>0.548936</td>\n",
       "      <td>0.508704</td>\n",
       "      <td>0.407752</td>\n",
       "      <td>0.746992</td>\n",
       "      <td>0.482456</td>\n",
       "      <td>0.459283</td>\n",
       "      <td>0.668246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>High-corr filtered</td>\n",
       "      <td>LSTM_model_arch_14</td>\n",
       "      <td>0.615444</td>\n",
       "      <td>0.653901</td>\n",
       "      <td>0.689157</td>\n",
       "      <td>0.443411</td>\n",
       "      <td>0.773789</td>\n",
       "      <td>0.543860</td>\n",
       "      <td>0.505415</td>\n",
       "      <td>0.663507</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Dataset  Model_Architecture      Loss  Accuracy  Precision  \\\n",
       "1   High-corr filtered  LSTM_model_arch_12  0.621878  0.643972   0.667447   \n",
       "4   High-corr filtered  LSTM_model_arch_15  0.695336  0.542553   0.000000   \n",
       "13  High-corr filtered  LSTM_model_arch_24  0.697391  0.545390   0.520000   \n",
       "8   High-corr filtered  LSTM_model_arch_19  0.702665  0.536170   0.480519   \n",
       "12  High-corr filtered  LSTM_model_arch_23  0.697571  0.532624   0.464646   \n",
       "6   High-corr filtered  LSTM_model_arch_17  0.696753  0.539007   0.333333   \n",
       "5   High-corr filtered  LSTM_model_arch_16  0.679260  0.578723   0.545617   \n",
       "15  High-corr filtered  LSTM_model_arch_26  0.697277  0.523404   0.451957   \n",
       "16  High-corr filtered  LSTM_model_arch_27  0.694365  0.548936   0.534351   \n",
       "0   High-corr filtered  LSTM_model_arch_11  0.685495  0.566667   0.527778   \n",
       "14  High-corr filtered  LSTM_model_arch_25  0.696029  0.543972   0.527778   \n",
       "10  High-corr filtered  LSTM_model_arch_21  0.694377  0.508511   0.455882   \n",
       "2   High-corr filtered  LSTM_model_arch_13  0.685344  0.567376   0.597765   \n",
       "7   High-corr filtered  LSTM_model_arch_18  0.694631  0.536170   0.493506   \n",
       "9   High-corr filtered  LSTM_model_arch_20  0.696449  0.572340   0.552239   \n",
       "11  High-corr filtered  LSTM_model_arch_22  0.691395  0.548936   0.508704   \n",
       "3   High-corr filtered  LSTM_model_arch_14  0.615444  0.653901   0.689157   \n",
       "\n",
       "      Recall  Validation_Loss  Validation_Accuracy  Validation_Precision  \\\n",
       "1   0.441860         0.680536             0.574561              0.545946   \n",
       "4   0.000000         0.689996             0.537281              0.000000   \n",
       "13  0.080620         0.690161             0.539474              1.000000   \n",
       "8   0.172093         0.690207             0.535088              0.400000   \n",
       "12  0.142636         0.691109             0.528509              0.166667   \n",
       "6   0.007752         0.691212             0.537281              0.000000   \n",
       "5   0.472868         0.691410             0.567982              0.570000   \n",
       "15  0.196899         0.691518             0.530702              0.200000   \n",
       "16  0.108527         0.693570             0.530702              0.466667   \n",
       "0   0.500775         0.695222             0.504386              0.461929   \n",
       "14  0.029457         0.695324             0.500000              0.422018   \n",
       "10  0.384496         0.695336             0.484649              0.434783   \n",
       "2   0.165891         0.705010             0.543860              0.527273   \n",
       "7   0.530233         0.712441             0.497807              0.452632   \n",
       "9   0.344186         0.717235             0.519737              0.463636   \n",
       "11  0.407752         0.746992             0.482456              0.459283   \n",
       "3   0.443411         0.773789             0.543860              0.505415   \n",
       "\n",
       "    Validation_Recall  \n",
       "1            0.478673  \n",
       "4            0.000000  \n",
       "13           0.004739  \n",
       "8            0.009479  \n",
       "12           0.004739  \n",
       "6            0.000000  \n",
       "5            0.270142  \n",
       "15           0.004739  \n",
       "16           0.099526  \n",
       "0            0.431280  \n",
       "14           0.218009  \n",
       "10           0.379147  \n",
       "2            0.137441  \n",
       "7            0.407583  \n",
       "9            0.241706  \n",
       "11           0.668246  \n",
       "3            0.663507  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view model result dataset for high correlation filtered\n",
    "best_models_filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "96c38601-3a55-4274-bdb8-97abaefd2f87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Model_Architecture</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Validation_Loss</th>\n",
       "      <th>Validation_Accuracy</th>\n",
       "      <th>Validation_Precision</th>\n",
       "      <th>Validation_Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>LSTM_model_arch_4</td>\n",
       "      <td>0.658053</td>\n",
       "      <td>0.613475</td>\n",
       "      <td>0.580906</td>\n",
       "      <td>0.556589</td>\n",
       "      <td>0.718918</td>\n",
       "      <td>0.506579</td>\n",
       "      <td>0.465686</td>\n",
       "      <td>0.450237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>LSTM_model_arch_7</td>\n",
       "      <td>0.666759</td>\n",
       "      <td>0.606383</td>\n",
       "      <td>0.576792</td>\n",
       "      <td>0.524031</td>\n",
       "      <td>0.733486</td>\n",
       "      <td>0.497807</td>\n",
       "      <td>0.471519</td>\n",
       "      <td>0.706161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>LSTM_model_arch_5</td>\n",
       "      <td>0.719356</td>\n",
       "      <td>0.579433</td>\n",
       "      <td>0.589655</td>\n",
       "      <td>0.265116</td>\n",
       "      <td>0.748150</td>\n",
       "      <td>0.491228</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.331754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>LSTM_model_arch_2</td>\n",
       "      <td>0.673665</td>\n",
       "      <td>0.583688</td>\n",
       "      <td>0.542398</td>\n",
       "      <td>0.575194</td>\n",
       "      <td>0.756880</td>\n",
       "      <td>0.502193</td>\n",
       "      <td>0.472222</td>\n",
       "      <td>0.644550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>LSTM_model_arch_9</td>\n",
       "      <td>0.662511</td>\n",
       "      <td>0.602837</td>\n",
       "      <td>0.565891</td>\n",
       "      <td>0.565891</td>\n",
       "      <td>0.767336</td>\n",
       "      <td>0.467105</td>\n",
       "      <td>0.459596</td>\n",
       "      <td>0.862559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>LSTM_model_arch_8</td>\n",
       "      <td>0.647282</td>\n",
       "      <td>0.621277</td>\n",
       "      <td>0.583710</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.786677</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.461126</td>\n",
       "      <td>0.815166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>LSTM_model_arch_10</td>\n",
       "      <td>0.677223</td>\n",
       "      <td>0.556028</td>\n",
       "      <td>0.513828</td>\n",
       "      <td>0.547287</td>\n",
       "      <td>0.813225</td>\n",
       "      <td>0.489035</td>\n",
       "      <td>0.465625</td>\n",
       "      <td>0.706161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>LSTM_model_arch_6</td>\n",
       "      <td>0.659748</td>\n",
       "      <td>0.620567</td>\n",
       "      <td>0.591362</td>\n",
       "      <td>0.551938</td>\n",
       "      <td>0.830245</td>\n",
       "      <td>0.475877</td>\n",
       "      <td>0.455128</td>\n",
       "      <td>0.672986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>LSTM_model_arch_1</td>\n",
       "      <td>0.634198</td>\n",
       "      <td>0.634752</td>\n",
       "      <td>0.589532</td>\n",
       "      <td>0.663566</td>\n",
       "      <td>1.022237</td>\n",
       "      <td>0.506579</td>\n",
       "      <td>0.468750</td>\n",
       "      <td>0.497630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>LSTM_model_arch_3</td>\n",
       "      <td>0.412617</td>\n",
       "      <td>0.788652</td>\n",
       "      <td>0.740638</td>\n",
       "      <td>0.827907</td>\n",
       "      <td>1.158542</td>\n",
       "      <td>0.480263</td>\n",
       "      <td>0.453901</td>\n",
       "      <td>0.606635</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Dataset  Model_Architecture      Loss  Accuracy  Precision    Recall  \\\n",
       "3  XGBoost   LSTM_model_arch_4  0.658053  0.613475   0.580906  0.556589   \n",
       "6  XGBoost   LSTM_model_arch_7  0.666759  0.606383   0.576792  0.524031   \n",
       "4  XGBoost   LSTM_model_arch_5  0.719356  0.579433   0.589655  0.265116   \n",
       "1  XGBoost   LSTM_model_arch_2  0.673665  0.583688   0.542398  0.575194   \n",
       "8  XGBoost   LSTM_model_arch_9  0.662511  0.602837   0.565891  0.565891   \n",
       "7  XGBoost   LSTM_model_arch_8  0.647282  0.621277   0.583710  0.600000   \n",
       "9  XGBoost  LSTM_model_arch_10  0.677223  0.556028   0.513828  0.547287   \n",
       "5  XGBoost   LSTM_model_arch_6  0.659748  0.620567   0.591362  0.551938   \n",
       "0  XGBoost   LSTM_model_arch_1  0.634198  0.634752   0.589532  0.663566   \n",
       "2  XGBoost   LSTM_model_arch_3  0.412617  0.788652   0.740638  0.827907   \n",
       "\n",
       "   Validation_Loss  Validation_Accuracy  Validation_Precision  \\\n",
       "3         0.718918             0.506579              0.465686   \n",
       "6         0.733486             0.497807              0.471519   \n",
       "4         0.748150             0.491228              0.434783   \n",
       "1         0.756880             0.502193              0.472222   \n",
       "8         0.767336             0.467105              0.459596   \n",
       "7         0.786677             0.473684              0.461126   \n",
       "9         0.813225             0.489035              0.465625   \n",
       "5         0.830245             0.475877              0.455128   \n",
       "0         1.022237             0.506579              0.468750   \n",
       "2         1.158542             0.480263              0.453901   \n",
       "\n",
       "   Validation_Recall  \n",
       "3           0.450237  \n",
       "6           0.706161  \n",
       "4           0.331754  \n",
       "1           0.644550  \n",
       "8           0.862559  \n",
       "7           0.815166  \n",
       "9           0.706161  \n",
       "5           0.672986  \n",
       "0           0.497630  \n",
       "2           0.606635  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view model result dataset for XGBoost reduced data\n",
    "best_models_xg_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
